## Flow Straight and Fast:

## Learning to Generate and Transfer Data with Rectiﬁed Flow

Xingchao Liu* University of Texas at Austin xcliu@utexas.edu

Chengyue Gong* University of Texas at Austin cygong@c s.utexas.edu

Qiang Liu University of Texas at Austin lqiang@c s.utexas.edu

## Abstract

We present rectiﬁed ﬂow, a surprisingly simple approach to learning (neural) ordinary differential equation (ODE) models to transport between two empirically observed distributions π0 and π1, hence providing a uniﬁed solution to generative modeling and domain transfer, among various other tasks involving distribution transport. The idea of rectiﬁed ﬂow is to learn the ODE to follow the straight paths connecting the points drawn from π0 and π1 as much as possible. This is achieved by solving a straightforward nonlinear least squares optimization problem, which can be easily scaled to large models without introducing extra parameters beyond standard supervised learning. The straight paths are special and preferred because they are the shortest paths between two points, and can be simulated exactly without time discretization and hence yield computationally efﬁcient models. We show that the procedure of learning a rectiﬁed ﬂow from data, called rectiﬁcation, turns an arbitrary coupling of π0 and π1 to a new deterministic coupling with provably non-increasing convex transport costs. In addition, recursively applying rectiﬁcation allows us to obtain a sequence of ﬂows with increasingly straight paths, which can be simulated accurately with coarse time discretization in the inference phase. In empirical studies, we show that rectiﬁed ﬂow performs superbly on image generation, image-t o-image translation, and domain adaptation. In particular, on image generation and translation, our method yields nearly straight ﬂows that give high quality results even with a single Euler discretization step.

## 1 Introduction

Compared with supervised learning, the shared difﬁculty of various forms of unsupervised learning is the lack of paired input/output data with which standard regression or classiﬁcation tasks can be invoked. The gist of most unsupervised methods is to ﬁnd, in one way or another, meaningful correspondences between points from two distributions. For example, generative models such as generative adversarial networks (GAN) and variational autoencoders (VAE) [e.g., 19, 32, 14] seek to map data points to latent codes following a simple elementary (Gaussian) distribution with which the data can be generated and manipulated. Representation learning rests on the idea that if a sufﬁciently smooth function can map a structured data*XL and CG contributed equally to this work.

## 1arXiv:2209.03003v1  [c s.LG]  7 Sep 2022

distribution to an elementary distribution, it can (likely) be endowed with certain semantically meaningful interpretation and useful for various downstream learning tasks. On the other hand, domain transfer methods ﬁnd mappings to transfer points from two different data distributions, both observed empirically, for the purpose of image-t o-image translation, style transfer, and domain adaption [e.g., 100, 16, 79, 59]. All these tasks can be framed uniﬁedly as ﬁnding a transport map between two distributions:

The Transport Mapping Problem Given empirical observations of two distributions X0 ∼ π0, X1 ∼ π1 on Rd, ﬁnd a transport map T : Rd → Rd (hopefully nice or optimal in certain sense), such that Z1 := T (Z0) ∼ π1 when Z0 ∼ π0, that i s, (Z0, Z1) is a coupling (a.k.a transport plan) of π0 and π1.

Several lines of techniques have been developed depending on how to represent and train the map T . In traditional generative models, T is parameterized as a neural network, and trained with either GAN-type minimax algorithms or (approximate) maximum likelihood estimation (MLE). However, GANs are known to suffer from numerically instability and mode collapse issues, and require substantial engineering efforts and human tuning, which often do not transfer well across different model architecture and datasets. On the other hand, MLE tends to be intractable for complex models, and hence requires approximate variational or Monte Carlo inference techniques such as those used in variational auto-encoders (VAE), or special model structures such as normalizing ﬂow and auto-regressive models, to yield tractable likelihood, causing difﬁcult trade-offs between expressive power and computational cost.

Recently, advances have been made by representing the transport plan implicitly as a continuous time process, such as ﬂow models with neural ordinary differential equations (ODEs) [e.g., 6, 56] and diffusion models by stochastic differential equations (SDEs) [e.g., 73, 23, 80, 11, 82]; in these models, a neural network is trained to represent the drift force of the processes and a numerical ODE/SDE solver is used to simulate the process during inference. The key idea is that, by leveraging the mathematical structures of ODEs/SDEs, the continuous-time models can be trained efﬁciently without resorting to minimax or traditional approximate inference techniques. The most notable examples are the recent score-based generative models [71–73] and denoising diffusion probabilistic models (DDPM) [23], which we call denoising diffusion methods collectively. These methods allow us to train large-scale diffusion/SDE-based generative models that surpass GANs on image generation in both image quality and diversity, without the instability and mode collapse issues [e.g., 12, 53, 61, 64]. The learned SDEs can be converted into deterministic ODE models for faster inference with the method of probability ﬂow ODEs [73] and DDIM [70].

However, compared with the traditional one-step models like GAN and VAE, a key drawback of continuoustimes models is the high computational cost in inference time: drawing a single point (e.g., image) requires to solve the ODE/SDE with a numerical solver that needs to repeatedly call the expensive neural drift function. In addition, the existing denoising diffusion techniques require substantial hyper-parameter search in an involved design space and are still poorly understood both empirically and theoretically [29].

In existing approaches, generative modeling and domain transfer are typically treated separately. It often requires to extend or customize a generative learning techniques to solve domain transfer problems; see e.g., Cycle GAN [100] and diffusion-based image-t o-image translation [e.g., 75, 97]. One framework that naturally uniﬁes both domains is optimal transport (OT) [e.g., 85, 2, 15, 59], which endows a collection of techniques for ﬁnding optimal couplings with minimum transport costs of form E[c(Z1 − Z0)] w.r.t. a cost function c : Rd → R, yielding natural applications to both generative and transfer learning. However, the existing OT techniques are slow for problems with high dimensional and large volumes of data [59]. Furthermore, as the transport costs do not perfectly align with the actual learning performance, methods that faithfully ﬁnd the optimal transport maps do not necessarily have better learning performance [34].



Figure 1: The trajectories of rectiﬁed ﬂows for image generation (π0: standard Gaussian noise, π1: cat faces, top two rows), and image transfer between human and cat faces (π0: human faces, π1: cat faces, bottom two rows), when simulated using Euler method with step size 1/N for N steps. The ﬁrst rectiﬁed ﬂow induced from the training data (1-rectiﬁed ﬂow) yields good results with a very small number (e.g., ≥ 2) of steps; the straightened reﬂow induced from 1-rectiﬁed ﬂow (denoted as 2-rectiﬁed ﬂow) has nearly straight line trajectories and yield good results even with one discretization step.

ContributionWe introduce rectiﬁed ﬂow, a surprisingly simple approach to the transport mapping problem, which uniﬁedly solves both generative modeling and domain transfer. The rectiﬁed ﬂow is an ODE model that transport distribution π0 to π1 by following straight line paths as much as possible. The straight paths are preferred both theoretically because it is the shortest path between two end points, and computationally because it can be exactly simulated without time discretization. Hence, ﬂows with straight paths bridge the gap between one-step and continuous-time models.

Algorithmically, the rectiﬁed ﬂow is trained with a simple and scalable unconstrained least squares optimization procedure, which avoids the instability issues of GANs, the intractable likelihood of MLE methods, and the subtle hyper-parameter decisions of denoising diffusion models. The procedure of obtaining the rectiﬁed ﬂow from the training data has the attractive theoretical property of 1) yielding a coupling with non-increasing transport cost jointly for all convex cost c, and 2) making the paths of ﬂow increasingly straight and hence incurring lower error with numerical solvers. Therefore, with a reﬂow procedure that iteratively trains new rectiﬁed ﬂows with the data simulated from the previously obtained rectiﬁed ﬂow, we obtain nearly straight ﬂows that yield good results even with the coarsest time discretization, i.e., one Euler step. Our method is purely ODE-based, and is both conceptually simpler and practically faster in inference time than the SDE-based approaches of [23, 73, 70]. 3(a) Linear interpolationXt = tX1 + (1 − t)X0 (b) Rectiﬁed ﬂow Ztinduced by (X0, X1) (c) Linear interpolationZt = tZ1 + (1 − t)Z0 (d) Rectiﬁed ﬂow Z′ t induced by (Z0, Z1)Figure 2: (a) Linear interpolation of data input (X0, X1) ∼ π0 × π1. (b) The rectiﬁed ﬂow Zt induced by (X0, X1); the trajectories are “rewired” at the intersection points to avoid the crossing. (c) The linear interpolation of the end points (Z0, Z1) of ﬂow Zt. (d) The rectiﬁed ﬂow induced from (Z0, Z1), which follows straight paths.

Empirically, rectiﬁed ﬂow can yield high-quality results for image generation when simulated with a very few number of Euler steps (see Figure 1, top row). Moreover, with just one step of reﬂow, the ﬂow becomes nearly straight and hence yield good results with a single Euler discretization step (Figure 1, the second row). This substantially improves over the standard denoising diffusion methods. Quantitatively, we claim a state-o f-the-art result of FID (4.85) and recall (0.51) on CIFAR10 for one-step fast diffusion/ﬂow models [5, 48, 91, 99, 47]. The same algorithm also achieves superb result on domain transfer tasks such as image-toimage translation (see the bottom two rows of Figure 1) and transfer learning.

## 2 Method

We provide a quick overview of the method in Section 2.1, followed with some discussion and remarks in Section 2.2. We introduce a nonlinear extension of our method in Section 2.3, with which we clarify the connection and advantages of our method with the method of probability ﬂow ODEs [73] and DDIM [70].

## 2.1 Overview

Rectiﬁed ﬂow Given empirical observations of X0 ∼ π0, X1 ∼ π1, the rectiﬁed ﬂow induced from (X0, X1) is an ordinary differentiable model (ODE) on time t ∈ [0, 1],dZt = v(Zt, t)d t,which converts Z0 from π0 to a Z1 following π1. The drift force v : Rd → Rd is set to drive the ﬂow to follow the direction (X1 − X0) of the linear path pointing from X0 to X1 as much as possible, by solving a simple least squares regression problem:

min v ∫ 1

## 0 E [∥

∥(X1 − X0) − v(Xt, t )∥ ∥2] d t, with Xt = tX1 + (1 − t)X0, (1)where Xt is the linear interpolation of X0 and X1. Naviely, Xt follows the ODE of dXt = (X1 − X0)d t, which is non-causal (o r anticipating) as the update of Xt requires the information of the ﬁnal point X1. By ﬁtting the drift v with X1 − X0, the rectiﬁed ﬂow causalizes the paths of linear interpolation Xt, yielding an ODE ﬂow that can be simulated without seeing the future.

In practice, we parameterize v with a neural network or other nonlinear models and solve (1) with any offthe-shelf stochastic optimizer, such as stochastic gradient descent, with empirical draws of (X0, X1). See4Algorithm 1. After we get v, we solve the ODE starting from Z0 ∼ π0 to transfer π0 to π1, backwardly starting from Z1 ∼ π1 to transfer π1 to π0. Speciﬁcally, for backward sampling, we simply solve d ˜Xt = −v( ˜Xt, t)d t initialized from ˜X0 ∼ π1 and set Xt = ˜X1−t. The forward and backward sampling are equally favored by the training algorithm, because the objective in (1) is time-symmetric in that it yields the equivalent problem if we exchange X0 and X1 and ﬂip the sign of v.

Flows avoid crossing A key to understanding the method is the non-crossing property of ﬂows: the different paths following a well deﬁned ODE dZt = v(Zt, t)d t, whose solution exists and is unique, cannot cross each other at any time t ∈ [0, 1). Speciﬁcally, there exists no location z ∈ Rd and time t ∈ [0, 1), such that two paths go across za t time t along different directions, because otherwise the solution of the ODE would be non-unique. On the other hand, the paths of the interpolation process Xt may intersect with each other (Figure 2a), which makes it non-causal. Hence, as shown in Figure 2b, the rectiﬁed ﬂow rewires the individual trajectories passing through the intersection points to avoid crossing, while tracing out the same density map as the linear interpolation paths due to the optimization of (1). We can view the linear interpolation Xt as building roads (o r tunnels) to connect π0 and π1, and the rectiﬁed ﬂow as trafﬁcs of particles passing through the roads in a myopic, memoryless, non-crossing way, which allows them to ignore the global path information of how X0 and X1 are paired, and rebuild a more deterministic pairing of (Z0, Z1).

Rectiﬁed ﬂows reduce transport costs If (1) is solved exactly, the pair (Z0, Z1) of the rectiﬁed ﬂow is guaranteed to b ea valid coupling of π0, π1 (Theorem 3.3), that i s, Z1 follows π1 if Z0 ∼ π0. Moreover, (Z0, Z1) guarantees to yield no larger transport cost than the data pair (X0, X1) simultaneously for all convex cost functions c (Theorem 3.5). The data pair (X0, X1) can be an arbitrary coupling of π0, π1, typically independent (i.e., (X0, X1) ∼ π0 × π1) as dictated by the lack of meaningfully paired observations in practical problems. In comparison, the rectiﬁed coupling (Z0, Z1) has a deterministic dependency as i ti s constructed from an ODE model. Denote by (Z0, Z1) = Rectify((X0, X1)) the mapping from (X0, X1) to (Z0, Z1). Hence, Rectify(·) converts an arbitrary coupling into a deterministic coupling with lower convex transport costs.

Straight line ﬂows yield fast simulation Following Algorithm 1, denote by Z = RectFlow((X0, X1)) the rectiﬁed ﬂow induced from (X0, X1). Applying this operator recursively yields a sequence of rectiﬁed ﬂows Zk+1 = RectFlow((Zk

## 0 , Zk

## 1 )) with (Z0

## 0 , Z0

## 1 ) = (X0, X1), where Zk is the k-t h rectiﬁed ﬂow, o r

simply k-rectiﬁed ﬂow, induced from (X0, X1).

This reﬂow procedure not only decreases transport cost, but also has the important effect of straightening paths of rectiﬁed ﬂows, that i s, making the paths of the ﬂow more straight. This is highly attractive computationally as ﬂows with nearly straight paths incur small time-discretization error in numerical simulation. Indeed, perfectly straight paths can be simulated exactly with a single Euler step and is effectively a onestep model. This addresses the very bottleneck of high inference cost in existing continuous-time ODE/SDE models.

## 2.2 Main Results and Properties

We provide more i n-depth discussions on the main properties of rectiﬁed ﬂow. We keep the discussion informal to highlight the intuitions in this section and defer the full course theoretical analysis to Section 3.

5Algorithm 1 Rectiﬁed Flow: Main AlgorithmProcedure: Z = RectFlow((X0, X1)): Inputs: Draws from a coupling (X0, X1) of π0 and π1; velocity model vθ : Rd → Rd with parameter θ.

Training: ˆθ = arg min θ E [ ∥X1 − X0 − v( tX1 + (1 − t)X0, t)∥2] , with t ∼ Uniform([0, 1]).

Sampling: Draw (Z0, Z1) following dZt = vˆθ(Zt, t)d t starting from Z0 ∼ π0 (o r backwardly Z1 ∼ π1). Return: Z = {Zt : t ∈ [0, 1]}.

Reﬂow (optional): Zk+1 = RectFlow((Zk

## 0 , Zk

## 1 )), starting from (Z0

## 0 , Z0

## 1 ) = (X0, X1).

Distill (optional): Learn a neural network ˆT to distill the k-rectiﬁed ﬂow, such that Zk

## 1 ≈ ˆT (Zk

## 0 ).

First, for a given input coupling (X0, X1), it is easy to see that the exact minimum of (1) is achieved ifvX (x, t) = E[X1 − X0 | Xt = x], (2)which is the expectation of the line directions X1 − X0 that pass through xa t time t. We discuss below the property of rectiﬁed ﬂow dZt = vX (Zt, t)d t with Z0 ∼ π0, assuming that the ODE has an unique solution.

Marginal preserving property [Theorem 3.3] The pair (Z0, Z1) is a coupling of π0 and π1. In fact, the marginal law of Zt equals that of Xt at every time t, that i s, Law(Zt) = Law(Xt), ∀t ∈ [0, 1].

Intuitively, this is because, by the deﬁnition of vX in (2), the expected amount of mass that passes through every inﬁnitesmal volume at all location and time are equal under the dynamics of Xt and Zt, which ensures that they trace out the same marginal distributions:

Flow in & out ( )= Flow in & out ( ), ∀time & location =⇒ Law(Zt) = Law(Xt), ∀t.

On the other hand, the joint distributions of the whole trajectory of Zt and that of Xt are different in general. In particular, Xt is in general a non-causal, non-Markov process, with (X0, X1) a stochastic coupling, and Zt causalizes, Markovianizes and derandomizes Xt, while preserving the marginal distributions at all time.

Reducing transport costs [Theorem 3.5] The coupling (Z0, Z1) yields lower or equal convex transport costs than the input (X0, X1) in that E[c(Z1 − Z0)] ≤ E[c(X1 − X0)] for any convex cost c : Rd → R.

The transport costs measure the expense of transporting the mass of one distribution to another following the assignment relation speciﬁed by the coupling and is a central topic in optimal transport [e.g., 84, 85,

## 65, 59, 15]. Typical examples are c(·) = ∥·∥

α with α ≥ 1. Hence, Rectify(·) yields a Pareto descent on the collection of all convex transport costs, without targeting any speciﬁc c. This distinguishes it from the typical optimal transport optimization methods, which are explicitly framed to optimize a given c. As a result, recursive application of Rectify(·) does not guarantee to attain the c-optimal coupling for any given c, with the exception in the one-dimensional case when the ﬁxed point of Rectify(·) coincides with the unique monotonic coupling that simultaneously minimizes all non-negative convex costs c; see Section 3.4.

Intuitively, the convex transport costs are guaranteed to decrease because the paths of the rectiﬁed ﬂow Zt is a rewiring of the straight paths connecting (X0, X1). To give an illustration, consider the simple case of6c(·) = ∥·∥ when transport costs E[∥X0 − X1∥] and E[∥Z0 − Z1∥] are the expected length of the straight lines connecting the end points. The inequality can be proved graphically as follows:

E[∥Z0 − Z1∥] = Length( ) (∗) ≤ Length( ) (∗∗) = Length( ) = E[∥X0 − X1∥] ,where (∗) ≤ uses the triangle inequality, and (∗∗) = holds because the paths of Zt is a rewiring of the straight paths of Xt, following the construction of vX in (2). For general convex c, a similar proof using Jensen’s inequality is shown in Section 3.2.

Reﬂow, straightening, fast simulation As shown in Figure 3, when we recursively apply the procedure Zk+1 = RectFlow((Zk

## 0 , Zk

## 1 )), the paths of the k-rectiﬁed ﬂow Zk are increasingly straight, and hence

easier to simulate numerically, as k increases. This straightening tendency can be guaranteed theoretically.

(a)The 1st rectiﬁed ﬂow Z1Z1 = RectFlow((X0, X1)) (b) Reﬂow Z2Z2 = RectFlow((Z1

## 0 , Z1

## 1 )) (c) Reﬂow Z3

Z3 = RectFlow((Z2

## 0 , Z2

## 1 )) (d) Transport cost,

StraightnessFigure 3: (a)-(c) Samples of trajectories drawn from the reﬂows on a toy example (π0: purple dots, π1: red dots; the green and blue lines are trajectories connecting different modes of π0, π1). (d) The straightness and the relative L2 transport cost v.s. the reﬂow steps; the values are scaled into [0, 1], so 0 corresponds to straight lines and L2 optimal transport; see Section 5.1 for more information. We use the non-parametric model in (5) with bandwidth h = 0.1.

Speciﬁcally, we say that a ﬂow dZt = v(Zt, t)d ti s straight if we have almost surely that Zt = tZ1 + (1 − t)Z0 for ∀t ∈ [0, 1], or equivalently v(Zt, t) = Z1 − Z0 = const following each path. (More precisely, “straight” here refers to straight with a constant speed.) Such straight ﬂows are highly attractive computationally as i ti s effective a one-step model: a single Euler step update Z1 = Z0 + v(Z0, 0) calculates the exact Z1 from Z0. Note that the linear interpolation X = {Xt} is straight by this deﬁnition but it is not a (causal) ﬂow and hence can not be simulated without an oracle assess to draws of both π0 and π1. In comparison, it is non-trivial to make a ﬂow dZt = v(Zt, t)d t straight, because if s ov must satisfy the inviscid Burgers’ equation ∂t v + (∂z v)v = 0:

d dt v(Zt, t) = ∂z v(Zt, t) ˙Zt + ∂t v(Zt, t) = ∂z v(Zt, t)v(Zt, t) + ∂t v(Zt, t) = 0.

More generally, we can measure the straightness of any continuously differentiable process Z = {Zt} byS(Z) = ∫ 1

## 0 E [∥

∥ ∥(Z1 − Z0) − ˙Zt∥ ∥ ∥

## 2] d t. (3)

S(Z) = 0 means exact straightness. A ﬂow whose S(Z) is small has nearly straight paths and hence can be simulated accurately using numerical solvers with a small number of discretization steps. Section 3.3 shows that applying rectiﬁcation recursively provably decreases S(Z) towards zero.

7[Theorem 3.7] Let Zk be the k-t h rectiﬁed ﬂow induced from (X0, X1). Thenmin k∈{0···K} S(Zk) ≤ E[∥X1 − X0∥2] K .

As shown Figure 1, applying one step of reﬂow can already provide nearly straight ﬂows that yield good performance when simulated with a single Euler step. It is not recommended to apply too many reﬂow steps as it may accumulate estimation error on vX .

Distillation After obtaining the k-t h rectiﬁed ﬂow Zk, we can further improve the inference speed by distilling the relation of (Zk

## 0 , Zk

## 1 ) into a neural network ˆT to directly predict Zk

## 1 from Zk

## 0 without simulating

the ﬂow. Given that the ﬂow is already nearly straight (and hence well approximated by the one-step update), and the distillation can be done efﬁciently. In particular, if we take ˆT (z 0) = z 0 + v( z 0, 0), then the loss function for distilling Zk is E [∥ ∥(Zk

## 1 − Zk

## 0 ) − v(Zk

## 0 , 0)

∥ ∥2] , which is the term in (1) when t = 0.

We should highlight the difference between distillation and rectiﬁcation: distillation attempts to faithfully approximate the coupling (Zk

## 0 , Zk

## 1 ) while rectiﬁcation yields a different coupling (Zk+1

## 0 , Zk+1

## 1 ) with lower

transport cost and more straight ﬂow. Hence, distillation should be applied only in the ﬁnal stage when we want to ﬁne-tune the model for fast one-step inference.

On the velocity ﬁeld vX If X0 yields a conditional density function ρ(x 0 | x 1) when conditioned on X1 = x 1, then the optimal velocity ﬁeld vX (z, t) = E[X1 − X0|Xt = z] can be represented byvX (z, t) = E [ X1 − z

## 1 − t ηt(X1, z)

] , ηt(X1, z) = ρ ( z − tX1

## 1 − t

∣ ∣ ∣ ∣ X1 )∕E [ ρ ( z − tX1

## 1 − t

∣ ∣ ∣ ∣ X1 )] , (4)where the expectation E [·] is taken w.r.t. X1 ∼ π1. This can be seen by noting that X0 = z−tX1

## 1−t and

X1 − X0 = X1−z

## 1−t , when conditioned on Xt = z. Hence, if ρ is positive and continuous everywhere, then

vX is well deﬁned and continuous on Rd × [0, 1). Further, if log ηt is continuously differentiable w.r.t. z, we can show that ∇zvX (z, t) = 1

## 1 − t E [((X1 − z)∇z log ηt(X1, z) − 1) ηt(X1, z)] .

Note that dZt = vX (Zt, t)d ti s guaranteed to have a unique solution if vX is uniformly Lipschitz continuous on [0, a] for any a < 1.

If X0|X1 = x 1 does not yield a conditional density function, vX (z, t) may be undeﬁned or discontinuous, making the ODE dZt = vX (Zt, t)d t ill-behaved. A simple ﬁx is to add X0 with a Gaussian noise ξ ∼ N (0, σ2I) independent of (X0, X1) to yield a smoothed variable ˜X0 = X0 + ξ, and transfer ˜X0 to X1 using rectiﬁed ﬂow. This would effectively give a randomized mapping of form T (X0 + ξ) transporting π0 to π1.

Smooth function approximation Following (4), we can exactly calculate vX if the conditional density function ρ(·|x 1) exists and is known, and π1 is the empirical measure of a ﬁnite number of points (whose expectation can be evaluated exactly). In this case, running the rectiﬁed ﬂow forwardly would precisely recover the points in π1. This, however, is not practically useful in most cases as it completely overﬁts the8data. Hence, it is both necessary and beneﬁcial to ﬁt vX with a smooth function approximator such as neural network or non-parametric models, to obtain smoothed distributions with novel samples that are practically useful.

Deep neural networks are no doubt the best function approximators for large scale problems. For low dimensional problems, the following simple Nadaraya–Watson style non-parametric estimator of vX can yield a good approximation to the exact rectiﬁed ﬂow without knowing the conditional density ρ:

vX,h( z, t) = E [ X1 − z

## 1 − t ωh(Xt, z)

] , (5)where ωh(Xt, z) = κh(Xt,z) E[κh(Xt,z)] , and κh( x, z) is a smoothing kernel with a bandwith parameter h > 0 thatmeasures the similarity between z and x. Taking the Gaussian RBF kernel κh( x, z) = exp(− ∥x − z∥2 /2h2), then when h → 0+, it can be shown that vX,h( z, t) converges to vX (z, t) = E [ X1−z

## 1−t | Xt = z] on points

z that can be attained by Xt (i.e., the conditional expectation E [· | Xt = z] exists. ). On points z that Xt can not attain, vX,h( z, t) extrapolates the value by ﬁnding the Xt that is close to z. In practice, we replace the expectations in (5) with empirical averaging. We ﬁnd that vX,h performs well in practice because it i sa mixture of linear functions that always point to a point in the support of π1.

## 2.3 A Nonlinear Extension

We present a nonlinear extension of rectiﬁed ﬂow in which the linear interpolation Xt is replaced by any time-differentiable curve connecting X0 and X1. Such generalized rectiﬁed ﬂows can still transport π0 to π1 (Theorem 3.3), but no longer guarantee to decrease convex transport costs, or have the straightening effect. Importantly, the method of probability ﬂows [73] and DDIM [70] can be viewed (approximately) as special cases of this framework, allows us to clarify the connection with and the advantages over these methods.

Let X = {Xt : t ∈ [0, 1]} be any time-differentiable random process that connects X0 and X1. Let ˙Xt be the time derivative of Xt. The (nonlinear) rectiﬁed ﬂow induced from X is deﬁned asdZt = vX (Zt, t)d t, with Z0 = X0, and vX (z, t) = E [ ˙Xt | Xt = t ] .

We can estimate vX by solving min v ∫ 1

## 0 E [w t ∥

∥ ∥v(Xt, t) − ˙Xt∥ ∥ ∥

## 2] d t, (6)

where wt : (0, 1) → (0, +∞) is a positive weighting sequence (w t = 1 by default). When using the linear interpolation Xt = tX1 + (1 − t)X0, we have ˙Xt = X1 − X0 and (6) with wt = 1 reduces to (1). As we show in Theorem 3.3, the ﬂow Z given by this method still preserves the marginal laws of X, that i s, Law(Zt) = Law(Xt), ∀t ∈ [0, 1], and hence (Z0, Z1) remains to b ea coupling of π0, π1. However, if X is not straight, (Z0, Z1) no longer guarantees to decrease the convex transport costs over (X0, X1). More importantly, the reﬂow procedure no longer straightens the paths of Zt.

A simple class of interpolation processes is Xt = αtX1 + βtX0 where αt and βt are two differentiable sequences that satisfy α1 = β0 = 1 and α0 = β1 = 0 to ensure that the process equals X0, X1 at the starting and end points. In this case, we have ˙Xt = ˙αtX1 + ˙βtX0 in (6) where ˙αt and ˙βt are the time derivatives of αt and βt. The shape of the curve is controlled by the relation of αt and βt. If we take9βt = 1 − αt for all t, then Xt have straight paths but does not travel at a constant speed; it can be viewed as a time-changed variant of the canonical case Xt = tX1 + (1 − t)X0 when ti s reparameterized to αt. When βt ̸= 1 − αt, the paths of Xt are not straight lines except some special cases (e.g., ˙αtX1 = 0 or ˙βtX0 = 0, or X1 = aX1 for some a ∈ R).

## 2.3.1 Probability Flow ODEs and DDIM

The probability ﬂow ODEs (PF-ODEs) [73] and denoising diffusion implicit models (DDIM) [70] are methods for learning ODE-based generative models of π1 from a spherical Gaussian initial distribution π0, derived by converting a SDE learned by denoising diffusion methods to an ODE with equivalent marginal laws. In [73], three types of PF-ODEs are derived from three types of SDEs learned as score-based generative models, including variance-exploding (VE) SDE, variance-preserving (VP) SDE, and sub-VP SDE, which we denote by VE ODE, VP ODE, and sub-VP ODE, respectively. VP ODE is equivalent to the continuous time limit of DDIM, which is derived from the denoising diffusion probability model (DDPM) [23]. As the derivations of PF-ODEs and DDIM require advanced tools in stochastic calculus, we limit our discussion on the ﬁnal algorithmic procedures suggested in [73, 23], which we summarize in Section 3.5. The readers are referred to [73, 70] for the details.

[Proposition 3.11] All variants of PF-ODEs can be viewed as instances of (6) when using Xt = αtX1 + βtξ for some αt, βt with α1 = 1, β1 = 0, where ξ ∼ N (0, I) is a standard Gaussian random variable.

Here we need to use introduce ξ to replace X0 because the choices of αt and βt suggested in [73, 70, 23] do not satisfy the boundary condition of α0 = 0 and β0 = 1 at t = 0, and hence X0 ̸= ξ. Instead, in these methods, the initial distribution X0 ∼ π0 is implicitly deﬁned as X0 = α0X1 + β0ξ, which is approximated by X0 ≈ β0ξ by making α0X1 ≪ β0ξ. Hence, π0 is set to be N (0, β2

## 0I) in these methods. Viewed through

our framework, there is no reason to restrict ξ to be N (0, β2

## 0I), or not set α0 = 0, β0 = 1 to avoid the

approximation.

Rectiﬁed ﬂow VP ODE sub-VP ODE (αt = t, βt = 1 − t) (αt in (7), βt = √1 − α2 t ) (αt in (7), βt = 1 − α2 t )1-Rectiﬁed Flow 2-Rectiﬁed Flow 1-Rectiﬁed Flow 2-Rectiﬁed Flow 1-Rectiﬁed Flow 2-Rectiﬁed FlowFigure 4: Comparing rectiﬁed ﬂow with VP ODE and sub-VP ODE when π0 = N (0, I) (purple dots) and π1 is a low variance Gaussian mixture shown as the red dots. The linear rectiﬁed ﬂow yields nearly straight trajectories with one step of reﬂow. But the trajectories of VP ODE and sub-VP ODE are curved and can not be straightened by reﬂowing.

VP ODE and sub-VP ODE The VP ODE and sub-VP ODE of [73] use the following shared αt:

(sub-)VP ODE: αt = exp ( − 1

## 4 a(1 − t)

## 2 − 1

## 2 b(1 − t)

) ; default values: a = 19.9, b = 0.1, (7)10Time-Discretization Rectiﬁed Flow VP ODE sub-VP ODE VP ODE (const speed) Steps N αt = t, βt = 1 − t αt in (7), βt = √1 − α2 t αt in (7), βt = 1 − α2 t αt = t, βt = √1 − α2 tN = 1N = 2N = 5N = 

Figure 5: Trajectories of different methods when varying the number of discretization steps N (purple dots: π0; red dots: π1; orangle dots: intermediate steps; blue curves: ﬂow trajectories). The rectiﬁed ﬂow travels in straight lines and progresses uniformly in time; it generates the mean of π1 when simulated with a single Euler step, and quickly covers the whole distribution π1 with more steps (i n this case N = 2 is sufﬁcient). In comparison, VP ODE and sub-VP ODE travel in curves with non-uniform speed: they tend to be slow in the beginning and speed up in the later phase (much of the update happens when t⪆0.5). The non-uniform speed can be avoided by setting αt = t (see the last column).

where the default values of a, b are chosen to match the continuous time limit of the shared training procedure of DDIM and DDPM. The difference of VP ODE and sub-VP ODE is on the choice of βt, given as follows:

VP ODE: βt = √

## 1 − α2

t , sub-VP ODE: βt = 1 − α2 t . (8)As β0 ≈ 1 in both VP and sub-VP ODE, the π0 in both cases are taken as N (0, I).

The choices of αt, βt above are the consequence of the SDE-based derivation in [73]. However, they are not well-motivated when we exam the path properties of the induced ODEs:

• Non-straight paths: Due to choices of βt in (8), the trajectories of VP ODE and sub-VP ODE are curved in general, and can not be straightened by the reﬂow procedure. We should choose βt = 1 − αt to induce straight paths. Figure 6: tv s. αt, βt of different methods.

• Non-uniform speed: The exponential form of αt in (7) is a consequence of using Ornstein–Uhlenbeck processes in the derivation of SDE models [73, 23]. However, there is no clear advantage of using (7) for ODEs. As shown in Figure 5, the αt and βt of VP and sub-VP ODE change slowly in the early phase (t⪅0.5). As a result, the ﬂow also moves slowly in beginning and hence most of the updates are concentrated in the later phase. Such non-uniform update speed, in addition to the non-straight paths, make VP ODE and sub-VP ODE perform sub-optimally when using large step sizes, even for transport between simple spherical Gaussian distributions (see Figure 5). As we show in the last column of Figure 5, changing the exponential αt to the linear function αt = ti n VP ODE allows us to get a uniform update speed while preserving the same continuoustime trajectories. 11VE ODE The VE ODE of [73] uses αt = 1 and βt = σmin√ r 2(1−t) − 1 where σmin = 0.01 by default ri s set such that σmax := rσmin is as large as the maximum Euclidean distance between all pairs of training data points from π1 (Technique 1 of [72]). Assume that σ2 max is much larger than both σ2 min and the variance of X1, then X0 = X1 + β0ξ ≈ σmaxξ, and we can set the initial distribution to be π0 ∼ N (0, σ2 maxI), which has much larger variance than π1. Hence, VE ODE can not be applied to (and not shown i n) the toys in Figure 4 and Figure 5. As the case of (sub-)VP ODE, the restriction on ξ is in fact unnecessary and requirement that σmax is unnatural viewed from our framework. On the other hand, the trajectories of Xt in VE ODE are indeed straight lines, because the direction of ˙Xt = ˙βtξ is always the same as ξ. However, the choice of βt causes a non-uniform speed issue similar to that of (sub-)VP ODE.

Following [73, 23], a line of works have been proposed to improve the choices of αt, βt, but remain to be constrained by the basic design space from the SDE-t o-ODE derivation; see for example [54, 29, 95].

To summarize, the simple nonlinear rectiﬁed ﬂow framework in (6) both simpliﬁes and extends the existing framework, and sheds a number of importance insights:

• Learning ODEs can be considered directly and independently without resorting to diffusion/SDE methods;• The paths of the learned ODEs can be speciﬁed by any smooth interpolation curve Xt of X0 and X1;• The initial distribution π0 can be chosen arbitrarily, independent with the choice of the interpolation Xt.

• The canonical linear interpolation Xt = tX1 + (1 − t)X0 should be recommended as a default choice.

On the other hand, non-linear choices of Xt can be useful when we want to incorporate certain non-Euclidan geometry structure of the variable, or want to place certain constraints on the trajectories of the ODEs. We leave this for future works.

## 3 Theoretical Analysis

We present the theoretical analysis for rectiﬁed ﬂow. The results are summarized as follows.

• [Section 3.1] All nonlinear rectiﬁed ﬂows with any interpolation Xt preserve the marginal laws.

• [Section 3.2] The rectiﬁed ﬂow (with the canonical linear interpolation) reduces convex transport costs.

• [Section 3.3] Reﬂow guarantees to straighten the (linear) rectiﬁed ﬂows.

• [Section 3.4] We clarify the relation between straight couplings and c-optimal couplings.

• [Section 3.5] We establish PF-ODEs as instances of nonlinear rectiﬁed ﬂows.

## 3.1 The Marginal Preserving Property

The marginal preserving property that Law(Zt) = Law(Xt) for ∀t is a general property of the nonlinear rectiﬁed ﬂows in (6), regardless whether the interpolation Xt is straight or not.

Deﬁnition 3.1. For a path-wise continuously differentiable random process X = {Xt : t ∈ [0, 1]}, its expected velocity vX is deﬁned asvX (x, t) = E[ ˙Xt | Xt = x], ∀x ∈ supp(Xt).

For x ̸∈ supp(Xt), the conditional expectation is not deﬁned and we set vX arbitrarily, say vX (x, t) = 0.

12Deﬁnition 3.2. We call that X is rectiﬁable if vX is locally bounded and the solution of the integral equation below exists and is unique:

Zt = Z0 + ∫ t

## 0 vX (Zt, t)d t, ∀t ∈ [0, 1], Z0 = X0. (9)

In this case, Z = {Zt : t ∈ [0, 1]} is called the rectiﬁed ﬂow induced from X.

Theorem 3.3. Assume X is rectiﬁable and Z is its rectiﬁed ﬂow. Then Law(Zt) = Law(Xt) for ∀t ∈ [0, 1].

Proof. For any compactly supported continuously differentiable test function h : Rd → R, we haved dt E[h(Xt)] = E[∇h(Xt) ⊤ ˙Xt] = E[∇h(Xt)⊤vX (Xt, t)], (10)where we used vX (Xt, t) = E[ ˙Xt|Xt]. By deﬁnition, this is equivalent to that πt := Law(Xt) solves in the sense of distributions the continuity equation with drift vX t := vX (·, t):

˙πt + ∇ · (vX t πt) = 0. (11)To see the equivalence of (10) and (11), we can multiply (11) with h and integrate both sides:

## 0 = ∫ h( ˙πt + ∇ · (vX

t πt)) = ∫ h ˙πt − ∇h ⊤vX t πt = dd t E[h(Xt)] − E[∇h(Xt) ⊤vX (Xt, t)],where we use integration by parts that ∫ h∇ · (vX t πt) = − ∫ ∇h⊤(vX t πt).

Because Zt is driven by the same velocity ﬁeld vX , its marginal law Law(Zt) solves the very same equation with the same initial condition (Z0 = X0). Hence, the equivalence of Law(Zt) and Law(Xt) follows if the solution of (11) is unique, which is equivalent to the uniqueness of the solution of dZt = vX (Zt, t) following Corollary 1.3 of Kurtz [37] (see also Theorem 4.1 of Ambrosio and Crippa [1]).

## 3.2 Reducing Convex Transport Costs

The fact that (Z0, Z1) yields no larger convex transport costs than (X0, X1) is a consequence of using the special linear interpolation Xt = tX1 + (1 − t)X0 as the geodesic of Euclidean space.

Deﬁnition 3.4. A coupling (X0, X1) is called rectiﬁable if its linear interpolation process X = {tX1 + (1 − t)X0 : t ∈ [0, 1]} is rectiﬁable. In this case, the Z = {Zt : t ∈ [0, 1]} in (9) is called the rectiﬁed ﬂow of coupling (X0, X1), denoted as Z = RectFlow((X0, X1)), and (Z0, Z1) is called the rectiﬁed coupling of (X0, X1), denoted as (Z0, Z1) = Rectify((X0, X1)).

Theorem 3.5. Assume (X0, X1) is rectiﬁable and (Z0, Z1) = Rectify((X0, X1)). Then for any convex function c : Rd → R, we have E[c(Z1 − Z0)] ≤ E[c(X1 − X0)].

13Proof. The proof is based on elementary applications of Jensen’s inequality.

E [c(Z1 − Z0)] = E [c (∫ 1

## 0 vX (Zt, t)d t)] //a s dZt = vX (Zt, t)d t

≤ E [∫ 1

## 0 c (vX (Zt, t)

) d t] //convexity of c, Jensen’s inequality= E [∫ 1

## 0 c (vX (Xt, t)

) dt ] //Xt and Zt shares the same marginals= E [∫ 1

## 0 c (E [(X1 − X0) | Xt]) d t

] //deﬁnition of vX≤ E [∫ 1

## 0 E [c (X1 − X0) | Xt] d t

] //convexity of c, Jensen’s inequality= ∫ 1

## 0 E [c (X1 − X0)] dt //E[E[(X1 − X0)|Xt]] = E[(X1 − X0)]

= E [c (X1 − X0)] .

If Xt is straight but with positive non-constant speed, that i s, Xt = αtX1 + βtX0 with βt = 1 − αt and ˙αt ≥ 0, then we still have E[c(Z1 − Z0)] ≤ E[c(X1 − X0)] if c is convex and m-homogeneous in that c( a x) = |a|m c( x) for ∀a ∈ R, x ∈ Rd, with some constant m ∈ (0, 1].

## 3.3 The Straightening Effect

A coupling (X0, X1) is said to be straight (o r fully rectiﬁed) if i ti sa ﬁxed point of the Rectify(·) mapping. It is desirable to obtain a straight coupling because its rectiﬁed ﬂow is straight and hence can be simulated exactly with one step using numerical solvers. In this section, we ﬁrst characterize the basic properties of straight couplings, showing that a coupling is straight iff its linear interpolation paths do not intersect with each other. Then, we prove that recursive rectiﬁcation straightens the coupling and its related ﬂow with a O(1/k) rate, where ki s the number of rectiﬁcation steps.

Theorem 3.6. Assume (X0, X1) is rectiﬁable. Let Xt = tX1 + (1 − t)X0 and Z = RectFlow((X0, X1)). Then (X0, X1) is a straight coupling iff the following equivalent statements hold.

1. There exists a strictly convex function c : Rd → R, such that E[c(Z1 − Z0)] = E[c(X1 − X0)].

## 2. (X0, X1) is a ﬁxed point of Rectify(·), that i s, (X0, X1) = (Z0, Z1).

## 3. The rectiﬁed ﬂow coincides with the linear interpolation process: X = Z.

## 4. The paths of the linear interpolation X do not intersect:

V ((X0, X1)) := ∫ 1

## 0 E [∥X1 − X0 − E [X1 − X0 | Xt]∥2] dt = 0, (12)

where V ((X0, X1)) = 0 indicates that X1 − X0 = E[X1 − X0|Xt] almost surely when t ∼ Uniform([0, 1]), meaning that the lines passing through each Xt is unique, and hence no linear interpolation paths intersect. 14Proof. 3 → 2 → 1: Obvious.

1 → 4: If E[c(Z1 − Z0)] = E[c(X1 − X0)], the two applications of Jensen’s inequality in the proof of Theorem 3.5 are tight. Because ci s strictly convex, the second Jensen’s inequality in the proof implies that X1 −X0 = E[X1 −X0 | Xt] almost surely w.r.t. X and t ∼ Uniform([0, 1]), which implies that V (X) = 0.

## 4 → 3: If V (X) = 0, we have ∫ s

## 0 (X1 − X0)d t = ∫ s

## 0 E[X1 − X0|Xt]d t = ∫ s

## 0 vX (Xt, t)d t for s ∈ (0, 1].

Hence Xt = X0 + ∫ t

## 0 (X1 − X0)d t = X0 + ∫ t

## 0 vX (Xt, t)d t.

Because Z satisﬁes the same equation (9), we have X = Z by the uniqueness of the solution.

O(1/K) convergence rate We now show that as we apply rectiﬁcation recursively, the rectiﬁed ﬂows become increasingly straight and the linear interpolation of the couplings becomes increasingly non-intersecting.

Theorem 3.7. Let Zk the k-t h rectiﬁed ﬂow of (X0, X1), that i s, Zk+1 = RectFlow((Zk

## 0 , Zk

## 1 )) and

(Z0

## 0 , Z0

## 1 ) = (X0, X1). Assume each (Zk

## 0 , Zk

## 1 ) is rectiﬁable for k = 0, . . . , K.

Then K∑k=0 S(Zk+1) + V ((Zk

## 0 , Zk

## 1 )) ≤ E [

∥X1 − X0∥2] .

Hence, E[∥X1 − X0∥2] < +∞, we have mink≤K(S(Zk) + V ((Zk

## 0 , Zk

## 1 )) = O(1/K).

Proof. Taking c( x) = ∥x∥

## 2 in the proof of Theorem 3.5, we can obtain that

E [∥X1 − X0∥] − E [∥Z1 − Z0∥] = S(Z) + V ((X0, X1)). (13)Applying it to each rectiﬁcation step yieldsE [∥ ∥ ∥Zk

## 1 − Zk

## 0 ∥

∥ ∥

## 2] − E [∥

∥ ∥Zk+1

## 1 − Zk+1

## 0 ∥

∥ ∥

## 2] = S(Zk+1) + V ((Zk

## 0 , Zk

## 1 )).

A telescoping sum on k = 0, . . . , K gives the result.

## 3.4 Straight v s. Optimal Couplings

A coupling (X0, X1) is called c-optimal if it achieves the minimum of E[c(X1 − X0)] among all couplings that share the same marginals. Understanding and computing the optimal couplings have been the main focus of optimal transport [e.g., 84, 2, 15, 59]. Straight couplings is a different desirable property. In the following, we show that straightness is a necessary but not sufﬁcient condition of being c-optimal for a strictly convex function c, except in the one dimensional case when the two concepts coincides. Hence, it is “easier” to ﬁnd a straight coupling than a c-optimal couplings.

15Theorem 3.8. If a rectiﬁable coupling (X0, X1) is c-optimal for some strictly convex cost function c, then (X0, X1) is a straight coupling.

Proof. Let (Z0, Z1) = Rectify((X0, X1)). If (X0, X1) is c-optimal, we must have E[c(Z1 − Z0)] = E[c(X1 − X0)]. This implies Statement 1 in Theorem 3.6 and hence that (X0, X1) is straight.

## 1D Case For any π0, π1 on R, there exists an unique coupling (X ∗

## 0 , X ∗

## 1 ) that is simultaneously optimal for

all non-negative convex cost functions c. This coupling is uniquely characterized by a monotonic property: for every (x 0, x 1) and (x′

## 0, x′

## 1) in the support of (X ∗

## 0 , X ∗

## 1 ), if x 0 < x′

## 0, then x 1 ≤ x′

## 1. Furthermore, if π0

i s absolutely continuously w.r.t. the Lebesgue measure, then (X ∗

## 0 , X ∗

## 1 ) must be deterministic in that there

exists a mapping T : R → R such that X ∗

## 1 = T (X ∗

## 0 ). See [65].

In the following, we show that straight couplings on R coincides with the deterministic monotonic coupling (X ∗

## 0 , X ∗

## 1 ) and hence is unique and simultaneously optimal for all convex c when π0 is absolutely contin-

uous. The idea is that, in R, a coupling is monotonic iff its linear interpolation paths do not intersect, a characteristic feature of straight couplings.

Lemma 3.9. A coupling on R is straight iff it is deterministic and monotonic.

Theorem 3.10. For any π0, π1 on R, there exists either no straight coupling, or a unique straight coupling. Further, if exists, the unique straight coupling is deterministic and monotonic, and jointly optimal w.r.t. all convex cost functions c : Rd → [0, +∞) for which the minimum value of E [c(X1 − X0)] exists and is ﬁnite.

Proof of Lemma 3.9. If (X0, X1) on R is straight, then it coincides with its rectiﬁed coupling (Z0, Z1) = Rectify((X0, X1)). But because (Z0, Z1) is induced from the rectiﬁed ﬂow dZt = vX (Zt, t)d t, it is obviously deterministic. It is also monotonic due to the non-crossing property of ﬂows. Speciﬁcally, if (Z0, Z1) is not monotonic, there exists (z 0, z 1) and (z′

## 0, z′

## 1) in the support of (Z0, Z1) such that z 0 < z′

## 0 and

z 1 > z′

## 1. If this happens, there must exists t 0 ∈ (0, 1), such that zt0 = z′

t 0. But by the uniqueness of the solution, we have zt = zt for t ≥ t 0, which is conﬂicting with z 1 > z′ 1.

Assume (X0, X1) is deterministic and monotonic. Due to the monotonicity, there exists no x 0 and x′

## 0 i n

the support of π0, such that x 0 ̸= x′

## 0 and xt0 = x′

t 0 for some t 0 < 1. This suggests that X1 − X0 = E[X1 − X0 | Xt] = vX (Xt, t) for t ∈ (0, 1), and hence dXt = (X1 − X0)d t = vX (Xt)d t, which is the ODE of the rectiﬁed ﬂow. In addition, Xt is obviously the unique solution of this ODE. Hence (X0, X1) is rectiﬁable and straight following Statement 3 of Theorem 3.6.

Proof of Theorem 3.10. This is the result of Lemma 3.9 combined with the fact that the monotonic coupling is unique and jointly optimal for all convex c for which the optimal coupling exists, following Lemma 2.8 and Theorem 2.9 of [65].

Multi-dimensional cases On the other hand, on Rd with d ≥ 2, the different cost functions cd o not share a common optimal coupling in general, and a straight coupling is not guaranteed to optimize a speciﬁc c; this is expected because the Rectify(·) procedure does not depend on a particular choice of c. Hence, one must modify the Rectify(·) procedure to tailor it t oa speciﬁc co f interest.

In a recent work [30], it was conjectured that the couplings (Z0, Z1) induced from VP ODE (equivalently DDIM) yields an optimal coupling w.r.t. the quadratic loss, which was proved to be false in [39, 78]. Here16we show that even straight couplings are not guaranteed to be optimal, not to mention that VP ODE does not follow straight paths by design.

We explore this in a separate work [42] that is devoted to modifying rectiﬁed ﬂow to ﬁnd c-optimal couplings; a result from [42] that can be easily stated is that the optimal coupling w.r.t. the quadratic cost c(·) = ∥·∥ 2 can be achieved as the ﬁxed point of Rectify(·) if v is restricted to b ea gradient ﬁeld of form v( x, t) = ∇f (x, t) when solving (1). Restricting vt o be a gradient ﬁeld removes the rotational component of the velocity ﬁeld vX that causes sub-optimal transport cost.

## 3.5 Denoising Diffusion Models and Probability Flow ODEs

We prove that the probability ﬂow ODEs (PF-ODEs) of [73] can be viewed as nonlinear rectiﬁed ﬂows in (6) with Xt = αtX1 + βtξ. We start with introducing the algorithmic procedures of the denoising diffusion models and PF-ODEs, and refer the readers to the original works [73, 23, 70] for the theoretical derivations.

The denoising diffusion methods learn to generative models by constructing an SDE model driven by a standard Brownian motion Wt: dUt = b(Ut, t)d t + σtdWt, U0 ∼ π0, (14)where σt : [0, 1] → [0, +∞) is a (typically) ﬁxed diffusion coefﬁcient, bi sa trainable neural network, and the initial distribution π0 is restricted to a spherical Gaussian distribution determined by hyper-parameter setting of the algorithm. The idea is to ﬁrst collapse the data into an (approximate) Gaussian distribution using a diffusion process, mostly an Ornstein-Uhlenbeck (OU) process, and then estimate the generative diffusion process (14) as the time reversal [e.g., 3] of the collapsing process.

Without diving into the derivations, the training loss of the VE, VP, sub-VP SDEs for bi n [73] can be summarized as follows:

min v ∫ 1

## 0 E [

w t ∥v(Vt, t) − Yt∥ 2

## 2] d t, Vt = αtX1 + βtξt, Yt = −ηtVt − σ2

t βt ξt, (15)where ξt is a diffusion process satisfying ξt ∼ N (0, I), and ηt, σt are the hyper-parameter sequences of the algorithm, and αt, βt are determined by ηt, σt viaαt = exp (∫ 1t ηsds ) , β2 t = ∫ 1t exp (

## 2 ∫ s

t ηrdr) σ2 sd s. (16)The relation in (16) is derived to make ˜Vt = V1−t = α1−tX1 + β1−tξt follow the Ornstein-Uhlenbeck (OU) processes d ˜Vt = η1−t ˜Vtdt + σ1−tdWt.

VE SDE, which is equivalent to SMLD in [71, 72], takes ηt = 0 and hence has αt = 1. (sub-)VP SDE takes ηs to b ea linear function of s, yielding the exponential αt in (7). VP SDE (which is equivalent to DDPM [23]) takes ηt = − 1

## 2 σ2

t which yields that α2 t + β2 t = 1 as shown in (8). In DDPM, it was suggested to writeb( x, t) = −ηtx − σ2 t βt ϵ(x, t) , and estimate ϵ as a neural network that predicts ξt from (Vt, t).

Theoretically, the SDE in (14) with b solving (15) is ensured to yield Law(U1) = Law(X1) = π1 when initialized from U0 = α0X1 + β0ξ0, which can be approximated by U0 ≈ βξ0 when α0X1 ≪ β0ξ0.

17By using the properties of Fokker-Planck equations, it was observed in [73, 70] that the SDE in (14) with b trained in (15) can be converted into an ODE that share the same marginal laws:

dZt = ˜b(Zt, t)d t, with ˜b( z, t) = 1

## 2 (b( z, t) − ηtz), starting from Z0 = U0 = α0X1 + β0ξ0. (17)

Equivalently, we can regard ˜b as the solution ofmin v ∫ 1

## 0 E [

w t ∥ ∥ ∥v(Vt, t) − ˜Yt∥ ∥ ∥ 22 ] d t, Vt = αtX1 + βtξt, ˜Yt = −ηtVt − σ2 t

## 2βt ξt, (18)

which defers from (14) only by a factor of 1/2 in the second term of Yt. This simple equivalence holds only when (14) and (17) use the special initialization of Z0 = U0 = α0X1 + β0ξ0.

In the following, we are ready to prove that (18) is can be viewed as the nonlinear rectiﬁed ﬂow objective in (6) using Xt = αtX1 + βtξ with ξ ∼ N (0, I). We mainly need to show that ˜Yt is equivalent to ˙Xt by eliminating ηt and σt using the relation in (16).

Proposition 3.11. Assume (16) hold. Then (18) is equivalent to (6) with Xt = αtX1 + βtξ.

Proof. First, note that we can take ξt = ξ for all time t, as the correlation structure of ξt does not impact the result. Hence, we have Vt = Xt = αtX1 + βtξ. To show the equivalence of (18) and (6), we just need to verify that ˙Xt = ˜Yt. ˜Yt = −ηtXt + σ2 t 2β2 t (αtX1 − Xt)= − ˙ηt (αtX1 + βtξ) + σ2 t

## 2βt ξ

= − ˙ηαtX1 + (− ˙ηtβt + σ2 t 2βt ) ξ(∗) = ˙αtX1 + ˙βtξ= ˙Xt.

where in (∗) = we used that ηt = − ˙αt αt and σ2 t = 2β2 t ( ˙αt αt − ˙βt βt ) which can be derived from (16).

## 4 Related Works and Discussion

Learning one-step models GANs [19, 4, 43], VAEs [32], and (discrete-time) normalizing ﬂows [62, 13, 14] have been three classical approaches for learning deep generative models. GANs have been most successful in terms of generation qualities (for images in particular), but suffer from the notorious training instability and mode collapse issues due to use of minimax updates. VAEs and normalizing ﬂows are both trained based on the principle of maximum likelihood estimation (MLE) and need to introduce constraints on the model architecture and/o r special approximation techniques to ensure tractable likelihood computation: VAEs typically use a conditional Gaussian distribution in addition to the variational approximation of the likelihood; normalizing ﬂows require to use specially designed invertible architectures and need to copy with calculating expensive Jacobian matrices.

The reﬂow+distillation approach in this work provides another promising approach to training one-step models, avoiding the minimax issues of GANs and the intractability issues of the likelihood-based methods.

18Learning ODEs: MLE and PF-ODEs There are two major approaches for learning neural ODEs: the PF-ODEs/DDIM approach discussed in Section 2.3, and the more classical MLE based approach of [6].

• The MLE approach. In [6], neural ODEs are trained for learning generative models by maximizing the likelihood of the distribution of the ODE outcome Z1 at time t = 1 under the data distribution π1. Speciﬁcally, with observations from π1, it estimates a neural drift vo f an ODE dZt = v(Zt, t)d t bymax v D(π1; ρ v,π0), (19)where D(·; ·) denotes KL divergence (o r other discrepancy measures), and ρv,π0 is the density of Z1 following dZt = v(Zt, t)d t from Z0 ∼ π0; the density of π0 should be known and tractable to calculate.

By using an instantaneous change of variables formula, it was observed in [6] that the likelihood of neural ODEs are easier to compute than the discrete-time normalizing ﬂow without constraints on the model structures. However, this MLE approach is still computationally expensive for large scale models as it requires repeated simulation of the ODE during each training step. In addition, as the optimization procedure of MLE requires to backpropagate through time, it can easily suffer the gradient vanishing/exploding problem unless proper regularization is added.

Another fundamental problem is that the MLE (19) of neural ODEs is theoretically under-speciﬁed, because MLE only concerns matching the law of the ﬁnal outcome Z1 with the data distribution π1, and there are inﬁnitely many ODEs to achieve the same output law of Z1 while traveling through different paths. A number of works have been proposed to remedy this by adding regularization terms, such as these based on transport costs, to favor shorter paths; see [54, 55]. With a regularization term, the ODE learned by MLE would be implicitly determined by the initialization and other hyper-parameters of the optimizer used to solve (19).

• Probability Flow ODEs. The method of PF-ODEs [73] and DDIM [70] provides a different approach to learning ODEs that avoids the main disadvantages of the MLE approach, including the expensive likelihood calculation, training-time simulation of the ODE models, and the need of backpropagation through time. However, because PF-ODEs and DDIM were derived as the side product of learning the mathematically more involved diffusion/SDE models, their theories and algorithm forms were made unnecessarily restrictive and complicated. The nonlinear rectiﬁed ﬂow framework shows that the learning of ODEs can be approached directly in a very simple way, allowing us to identify the canonical case of linear rectiﬁed ﬂow and open the door of further improvements with ﬂexible and decoupled choices of the interpolation curves Xt and initial distributions π0.

Viewed through the general non-linear rectiﬁed ﬂow framework, the computational and theoretical drawbacks of MLE can be avoided because we can simply pre-determines the “roads” that the ODEs should travel through by specifying the interpolation curve Xt, rather than leaving it for the algorithm to ﬁgure out implicitly. It is theoretically valid to pre-specify any interpolation Xt because the neural ODE is highly over-parameterized as a generative model: when vi sa universal approximator and π0 is absolutely continuous, the distribution of Z1 can approximate any distribution given any ﬁxed interpolation curve Xt. The idea of rectiﬁed ﬂow is to the simplest geodesic paths for Xt.

Learning SDEs with denoising diffusion Although the scope of this work is limited to learning ODEs, the score-based generative models [71–74] and denoising diffusion probability models (DDPM) [23] are of high relevance as the basis of PF-ODEs and DDIM. The diffusion/SDE models trained with these methods19have been found outperforming GANs in image synthesis in both quality and diversity [12]. Notably, thanks to the stable and scalable optimization-based training procedure, the diffusion models have successfully used in huge text-t o-image generation models with astonishing results [e.g., 53, 61, 64]. It has been quickly popularized in other domains, such as video [e.g., 24, 92, 21], music [51], audio [e.g., 33, 40, 60], and text [41, 88], and more tasks such as image editing [97, 50]. A growing literature has been developed for improving the inference speed of denoising diffusion models, an example of which is the PF-ODEs/DDIM approach which gains speedup by turning SDEs into ODEs. We provide below some examples of recent works, which is b yn o mean exhaustive.

• Improved training and inference. A line of works focus on improving the inference and sampling procedure of denoising diffusion models. For example, [54] presents a few simple modiﬁcations of DDPM to improve the likelihood, sampling speed, and generation quality. [29] systematic exams the design space of diffusion generative models with empirical studies and identiﬁes a number of training and inference recipes for better generative quality with fewer sampling steps. [94] proposes a diffusion exponential integrator sampler for fast sampling of diffusion models. [46] provides a customized high order solver for PF-ODEs. [5] provides an analytic estimate of the optimal diffusion coefﬁcient.

• Combination with other methods. Another direction is to speed up diffusion models by combining them with GANs and other generative models. DDPM Distillation [47] accelerates the inference speed by distilling the trajectories of a diffusion model into a series of conditional GANs. The truncated diffusion probabilistic model (TDPM) of [99] trains a GAN model as π0 so that the diffusion process can be truncated to improve the speed; the similar idea was explored in [48, 18], and [18] provides an analysis on the optimal truncation time. [68, 89, 81] learns a denoising diffusion model in the latent spaces and combines it with variational auto-encoders. These methods can be potentially applied to rectiﬁed ﬂow to gain similar speedups for learning neural ODEs.

• Unpaired Image-t o-Image translation. The standard denoising diffusion and PF-ODEs methods focus on the generative task of transferring a Gaussian noise (π0) to the data (π1). A number of works have been proposed to adapt it to transferring data between arbitrary pairs of source-target domains. For example, SDEdit [50] synthesizes realistic images guided by an input image by ﬁrst adding noising to the input and then denoising the resulting image through a pre-trained SDE model. [8] proposes a method to guide the generative process of DDPM to generate realistic images based on a given reference image. [75] leverages two two PF-ODEs for image translation, one translating source images to a latent variable, and the other constructing the target images from the latent variable. [97] proposes an energy-guided approach that employs an energy function pre-trained on the source and target domains to guide the inference process of a pretrained SDE for better image translation. In comparison, our framework shows that domain transfer can be achieved by essentially the same algorithm as generative modeling, by simply setting π0 to be the source domain.

• Diffusion bridges. Some recent works [57, 44] show that the design space of denoising diffusion models can be made highly ﬂexible with the assistant of diffusion bridge processes that are pinned to a ﬁxed data point at the end time. This reduces the design of denoising diffusion methods to constructing a proper bridge processes. The bridges in Song et a l. [73] are constructed by a time-reversal technique, which can be equivalently achieved by Doob’s h-transform as shown in [57, 44], and more general construction techniques are discussed in [44, 90]. Despite the signiﬁcantly extended design spaces, an unanswered question is what type of diffusion bridge processes should be preferred. This question is made challenging because the presence of diffusion noise and the need of advanced stochastic calculus tools make it hard to intuit how20the methods work. By removing the diffusion noise, our work makes it clear that straight paths should be preferred. We expect that the idea can be extended to provide guidance on designing optimal bridge processes for learning SDEs.

• Schrodinger bridges. Another body of works [87, 11, 7, 82] leverages Schrodinger bridges (SB) as an alternative approach to learning diffusion generative models. These approaches are attractive theoretically, but casts signiﬁcant computational challenges for solving the Schrodinger bridge problem.

Re-thinking the role of diffusion noise The introduction of diffusion noise was consider essential due to the key role it plays in the derivations of the successful methods [73, 23]. However, as rectiﬁed ﬂow can achieve better or comparable results with a ODE-only framework, the role of diffusion mechanisms should be r e-examed and clearly decoupled from the other merits of denoising diffusion models. The success of the denoising diffusion models may be mainly attributed to the simple and stable optimization-based training procedure that allows us to avoid the instability issues and the need of case-b y-case tuning of GANs, rather than the presence of diffusion noises.

Because our work shows that there is no need to invoke SDE tools if the goal is to learn ODEs, the remaining question is whether we should learn an ODE or an SDE for a given problem. As already argued by a number of works [73, 70, 29], ODEs should be preferred over SDEs in general. Below is a detailed comparison between ODEs and SDEs.

• Conceptual simplicity and numerical speed. SDEs are more mathematically involved and are more difﬁcult to understand. Numerical simulation of ODEs are simpler and faster than SDEs.

• Time reversibility. It is equally easy to solve the ODEs forwardly and backwardly. In comparison, the time reversal of SDEs [e.g., 3, 22, 17] is more involved theoretically and may not be computationally tractable.

• Latent spaces. The couplings (Z0, Z1) of ODEs are deterministic and yield low transport cost in the case of rectiﬁed ﬂows, hence providing a good latent space for representing and manipulating outputs. Introducing diffusion noises make (Z0, Z1) more stochastic and hence less useful. In fact, the (Z0, Z1) given by DDPM [23] and the SDEs of [73] and hence useless for latent presentation.

• Training difﬁculty. There is no reason to believe that training an ODE is harder, if not easier, than training an SDE sharing the same marginal laws: the training loss of both cases would share the distributions of covariant and differ only on the targets. In the setting of [73], the two loss functions (15) and (18) are equivalent upto a linear reparameterization.

• Expressive power. As every SDE can be converted into an ODE that has the same marginal distribution using the techniques in [70, 73] (see also [84]), ODEs are as powerful as SDEs for representing marginal distributions, which is what needed for the transport mapping problems considered in this work. On the other hand, SDEs may be preferred if we need to capture richer time-correlation structures.

• Manifold data. When equipped with neural network drifts, the outputs of ODEs tend to fall into a smooth low dimensional manifold, a key inductive for structured data in AI such as images and text. In comparison, when using SDEs to model manifold data, one has to carefully anneal the diffusion noise to obtain smooth outcomes, which causes slow computation and a burden of hyperparameter tuning. SDEs might be more useful in for modeling highly noisy data in areas like ﬁnance and economics, and in areas that involve diffusion processes physically, such as molecule simulation.

21Optimal v s. straight transport Optimal transport has been extensively explored in machine learning as a powerful way to compare and transfer between probability measures. For the transport mapping problem considered in this work, a natural approach is to ﬁnding the optimal coupling (Z0, Z1) that minimizes a transport cost E[c(Z1 − Z0)] for a given c. The most common choice of c is the quadratic cost c(·) = ∥·∥ 2.

However, ﬁnding the optimal couplings, especially for high dimensional continuous measures, is highly challenging computationally and is the subject of active research; see for example [67, 34, 35, 49, 63, 10]. In addition, although the optimal couplings are known to have nice smoothness and other regularity properties, it is not necessary to accurately ﬁnd the optimal coupling because the transport cost do not exactly align with the learning performance of individual problems; see e.g., [34].

In comparison, our reﬂow procedure ﬁnds a straight coupling, which is not optimal w.r.t. a given c (see Section 3.4). From the perspective of fast inference, all straight couplings are equally good because they all yield straight rectiﬁed ﬂows and hence can be simulated with one Euler step.

## 5 Experiments

We start by studying the impact of reﬂow on toy examples. After that, we demonstrate that with multiple times of reﬂow, rectiﬁed ﬂow achieves state-o f-the-art performance on CIFAR-10. Moreover, it can also generate high-quality images on high-resolution image datasets. Going beyond unconditioned image generation, we apply our method to unpaired image-t o-image translation tasks to generate visually high-quality image pairs.

Algorithm We follow the procedure in Algorithm 1. We start with drawing (X0, X1) ∼ π0 × π1 and use it to get the ﬁrst rectiﬁed ﬂow Z1 by minimizing (1). The second rectiﬁed ﬂow Z2 is obtained by the same procedure except with the data replaced by the draws from (Z1

## 0 , Z1

## 1 ), obtained by simulating the ﬁrst

rectiﬁed ﬂow Z1. This process is repeated for k times to get the k-rectiﬁed ﬂow Zk. Finally, we can further distill the k-rectiﬁed ﬂow Zk into a one step model z 1 = z 0 + v( z 0, 0) by ﬁtting it on draws from (Zk

## 0 , Zk

## 1 ).

By default, the ODEs are simulated using the vanilla Euler method with constant step size 1/N for N steps, that i s, ˆZt+1/N = ˆZt + v( ˆZt, t)/N for t ∈ {0, . . . , N }/N . We use the Runge-Kutta method of order 5(4) from Scipy [86], denoted as RK45, which adaptively decide the step size and number of steps N based on user-speciﬁed relative and absolute tolerances. In our experiments, we stick to the same parameters as [73].

## 5.1 Toy Examples

To accurately illustrate the theoretical properties, we use the non-parametric estimator vX,h( z, t) in (5) in the toy examples in Figure 2, 3, 4, 5. In practice, we approximate the expectation in (5) an nearest neighbor estimator: given a sample {x (i)

## 0 , x

(i)

## 1 }i drawn from (X0, X1), we estimate vX b y

vX,h( z, t) ≈ ∑i∈knn( z,m)x( i)

## 1 − z

## 1 − t ωh( x(i)

t , z) / ∑i∈knn( z,m) ωh( x(i) t , z), x( i) t = t x( i)

## 1 + (1 − t)x( i)

## 0 ,

where knn( z, m) denotes the top m nearest neighbors of z in {x (i) t }i. We ﬁnd that the results are not sensitive to the choice of m and the bandwidth h (see Figure 7). We use h = 1 and m = 100 by default. The ﬂows are simulated using Euler method with a constant step size of 1/N for N steps. We use N = 100 steps unless otherwise speciﬁed. 22Alternatively, vX can be parameterized as a neural network and trained with stochastic gradient descent or Adam. Figure 7 shows an example of when vX is parameterized as an 2-hidden-layer fully connected neural network with 64 neurons in both hidden layers. We see that the neural networks ﬁt less perfectly with the linear interpolation trajectories (which should be piece-wise linear in this toy example). As shown in Figure 7, we ﬁnd that enhancing the smoothness of the neural networks (b y increasing the L2 regularization coefﬁcient during training) can help straighten the ﬂow, in addition to the rectiﬁcation effect.

1-Rectiﬁed Flow 2-Rectiﬁed Flow 3-Rectiﬁed Flow 1-Rectiﬁed Flow 2-Rectiﬁed Flow 3-Rectiﬁed FlowL2Penalty=0h=0.01L2Penalty=0.01h=1 Figure 7: Rectiﬁed ﬂows ﬁtted with neural networks trained with different L2 penalty (left), and kernel estimator with different bandwidth h (right). π0: red dots; π1: purple dots.

In Figure 3 of Section 2.2, the straightness is calculated as the empirical estimation of (3) based on the simulated trajectories. The relative transport cost is calculated based on {z( i)

## 0 , z( i)

## 1 }n

i=1 drawn from (Z0, Z1)b y simulating the ﬂow, as 1 n ∑n i=1 ∥ ∥ ∥z( i)

## 1 − z( i)

## 0 ∥

∥ ∥

## 2 − ∥

∥ ∥z( i ∗)

## 1 − z( i)

## 0 ∥

∥ ∥

## 2, where z( i ∗)

## 1 is the optimal L2 assignment

o f z( i)

## 0 obtained by solving the discrete L2 optimal transport problem between {z( i)

## 0 } and {z( i)

## 1 }. We should

note that this metric is only useful in low dimensions, as it tends to be identically zero in high dimensional cases even vX is set to b ea random neural network. This misleading phenomenon is what causes [30] to make the false hypothesis that DDIM yields L2 optimal transport.

## 5.2 Unconditioned Image Generation

We test rectiﬁed ﬂow for unconditioned image generation on CIAFR-10 and a number of high resolution datasets. The methods are evaluated by the quality of generated images by Fr´echet inception distance (FID) and inception score (IS), and the diversity of the generated images by the recall score following [38].

Experiment settings For the purpose of generative modeling, we set π0 to be the standard Gaussian distribution and π1 the data distribution. Our implementation of rectiﬁed ﬂow is modiﬁed upon the opensource code of [73]. We adopt the U-Net architecture of DDPM++ [73] for representing the drift vX , and report in Table 1 (a) and Figure 8 the results of our method and the (sub)-VP ODE from [73] using the same architecture. Other recent results using different network architectures are shown in Table 1 (b) for reference. More detailed settings can be found in the Appendix.

Results • Results of fully solved ODEs. As shown in Table 1 (a), the 1-rectiﬁed ﬂow trained on the DDPM++ architecture, solved with RK45, yields the lowest FID (2.58) and highest recall (0.57) among all the ODE-based methods. In particular, the recall of 0.57 yields a substantial improvement over existing ODE23Method NFE(↓) IS (↑) FID (↓) Recall (↑) ODE One-Step Generation (Euler solver, N=1)

## 1-Rectiﬁed Flow (+Distill) 1 1.13 (9.08) 378 (6.18) 0.0 (0.45)

## 2-Rectiﬁed Flow (+Distill) 1 8.08 (9.01) 12.21 (4.85) 0.34 (0.50)

## 3-Rectiﬁed Flow (+Distill) 1 8.47 (8.79) 8.15 (5.21) 0.41 (0.51)

VP ODE [73] (+Distill) 1 1.20 (8.73) 451 (16.23) 0.0 (0.29) sub-VP ODE [73] (+Distill) 1 1.21 (8.80) 451 (14.32) 0.0 (0.35) ODE Full Simulation (Runge–Kutta (RK45), Adaptive N )

## 1-Rectiﬁed Flow 127 9.60 2.58 0.57

## 2-Rectiﬁed Flow 110 9.24 3.36 0.54

## 3-Rectiﬁed Flow 104 9.01 3.96 0.53

VP ODE [73] 140 9.37 3.93 0.51 sub-VP ODE [73] 146 9.46 3.16 0.55 SDE Full Simulation (Euler solver, N=2000) VP SDE [73] 2000 9.58 2.55 0.58 sub-VP SDE [73] 2000 9.56 2.61 0.58 Method NFE(↓) IS (↑) FID (↓) Recall (↑) GAN One-Step Generation SNGAN [52] 1 8.22 21.7 0.44 StyleGAN2 [28] 1 9.18 8.32 0.41 StyleGAN-XL [66] 1 - 1.85 0.47 StyleGAN2 + ADA [28] 1 9.40 2.92 0.49 StyleGAN2 + DiffAug [98] 1 9.40 5.79 0.42 TransGAN + DiffAug [26] 1 9.02 9.26 0.41 GAN with U-Net One-step Generation TDPM (T=1) [99] 1 8.65 8.91 0.46 Denoising Diffusion GAN (T=1) [91] 1 8.93 14.6 0.19 ODE One Step Generation (Euler solver, N=1) DDIM Distillation [47] 1 8.36 9.36 0.51 NCSN++ (VE ODE) [73] (+Distill) 1 1.18 (2.57) 461 (254) 0.0 (0.0) ODE Full Simulation (Runge–Kutta (RK45), Adaptive N ) NCSN++ (VE ODE) [73] 176 9.35 5.38 0.56 SDE Full Simulation (Euler solver) DDPM [23] 1000 9.46 3.21 0.57 NCSN++ (VE SDE) [73] 2000 9.83 2.38 0.59(a) Results using the DDPM++ architecture. (b) Recent results with different architectures reported in literature.

Table 1: Results on CIFAR10 unconditioned image generation. Fr´echet Inception Distance (FID) and Inception Score (IS) measure the quality of the generated images, and recall score [38] measures diversity. The number of function evaluation (NFE) denotes the number of times we need to call the main neural network during inference. It coincides with the number of discretization steps N for ODE and SDE models.

## 1-Rectified Flow 2-Rectified Flow 3-Rectified Flow 1-Distilled 2-Distilled 3-Distilled

sub-VP ODE VP ODE VE ODE sub-VP SDE VP SDE2-Rectified Flow 3-Rectified FlowReflow Reflow Reflow ReflowN = 1 N = 2 N = 3(a) FID and Recall v s. Number of Euler discretization steps N (b) FID and Recall v s. Training IterationsFigure 8: (a) Results of rectiﬁed ﬂows and (sub-)VP ODE on CIFAR10 with different number N of Euler discretization steps. (b) The FID and recall during different reﬂow and training steps. In (a), k-Distilled refers to the one-step model distilled from k-Rectiﬁed Flow for k = 1, 2, 3.

and GAN methods. Using the same RK45 ODE solver, rectiﬁed ﬂows require fewer steps to generate the images compared with VE, VP, sub-VP ODEs. The results are comparable to the fully simulated (sub-)VP SDE, which yields simulation cost.

Reflow Reflow

## 1-Rectified Flow

## 2-Rectified Flow 3-Rectified Flow

## 1-Rectified Flow 2-Rectified FlowPixel  Value

Figure 9: The straightening effect on CIFAR10. Left: the straightness measure on different reﬂow steps and training iterations. Right: trajectories of randomly sampled pixels following 1- and 2-rectiﬁed ﬂow.

• Results on few and single step generation. As shown in Figure 8, the reﬂow procedure substantially improves both FID and recall in the small step regime (e.g., N ⪅80), even though it worsens the results in the large step regime due to the accumulation of error on estimating v x. Figure 8 (b) show that each reﬂow leads to a noticeable improvement in FID and recall. For one-step generation (N = 1), the results are further boosted by distillation (see the stars in Figure 8 (a)). Overall, the distilled k-Rectiﬁed Flow with k = 1, 2, 3 yield one-step generative models beating all previous ODEs with distillation; they also beat the reported results of one-step24models with similar U-net type architectures trained using GANs (see the GAN with U-Net in Table 1 (b)).

In particular, the distilled 2-rectiﬁed ﬂow achieves an FID of 4.85, beating the best known one-step generative model with U-net architecture, 8.91 (TDPM, Table 1 (b)). The recalls of both 2-rectiﬁed ﬂow (0.50) and 3-rectiﬁed ﬂow (0.51) outperform the best known results of GANs (0.49 from StyleGAN2+ADA) showing an advantage in diversity. We should note that the reported results of GANs have been carefully optimized with special techniques such as adaptive discriminator augmentation (ADA) [28], while our results are based on the vanilla implementation of rectiﬁed ﬂow. It is likely to further improve rectiﬁed ﬂow with proper data augmentation techniques, or the combination of GANs such as those proposed by TDPM [99] and denoising diffusion GAN [91].

• Reﬂow straightens the ﬂow. Figure 9 shows the reﬂow procedure decreases improves the straightness of the ﬂow on CIFAR10. In Figure 10 visualizes the trajectories of 1-rectiﬁed ﬂow and 2-rectiﬁed ﬂow on the AFHQ cat dataset: at each point z t, we extrapolate the terminal value at t = 1 by ˆzt

## 1 = zt + (1 − t)v( z t, t);

i f the trajectory of ODE follows a straight line, ˆzt

## 1 should not change as we vary t when following the

same path. We observe that ˆzt

## 1 is almost independent with t for 2-rectiﬁed ﬂow, showing the path is almost

straight. Moreover, even though 1-rectiﬁed ﬂow is not straight with ˆzt

## 1 over time, it still yields recognizable

and clear images very early (t ≈ 0.1). In comparison, it is need t ≈ 0.6 to get a clear image from the extrapolation of sub-VP ODE.

High-resolution image generation Figure 11 shows the result of 1-rectiﬁed ﬂow on image generation on high-resolution (256 × 256) datasets, including LSUN Bedroom [93], LSUN Church [93], CelebA HQ [27] to AFHQ Cat [9]. We can see that it can generate high quality results across the different datasets. Figure 1 & 10 show that 1-(2-)rectiﬁed ﬂow yields good results within one or few Euler steps.

Figure 12 shows a simple example of image editing using 1-rectiﬁed ﬂow: We ﬁrst obtain an unnatural image z 1 by stitching the upper and lower parts of two natural images, and then run 1-rectiﬁed ﬂow backwards to get a latent code z 0. We then modify z 0 to increase its likelihood under π0 (which is N (0, I)) to get more naturally looking variants of the stitched image.

## 5.3 Image-t o-Image Translation

Assume we are given two sets of images of different styles (a.k.a. domains), whose distributions are denoted by π0, π1, respectively. We are interested in transferring the style (o r other key characteristics) of the images in one domain to the other domain, in the absence of paired examples. A classical approach to achieving this is cycle-consistent adversarial networks (a.k.a. CycleGAN) [100, 25], which jointly learns a forward and backward mapping F, G by minimizing the sum of adversarial losses on the two domains, regularized by a cycle consistency loss to enforce F (G( x)) ≈ x for all image x.

By constructing the rectiﬁed ﬂow of π0 and π1, we obtain a simple approach to image translation that requires no adversarial optimization and cycle-consistency regularization: training the rectiﬁed ﬂow requires a simple optimization procedure and the cycle consistency is automatically in ﬂow models satisﬁed due to reversibility of ODEs.

As the main goal here is to obtain good visual results, we are not interested in faithfully transferring X0 ∼ π0 to an X1 that exactly follows π1. Rather, we are interested in transferring the image styles while preserving the identity of the main object in the image. For example, when transferring a human face image to a cat

Figure 10: Sample trajectories zt of different ﬂows on the AFHQ Cat dataset, and the extrapolation ˆzt

## 1 = zt + (1 −

t)v( z t, t) from different z t. The same random seed is adopted for all three methods. The ˆzt

## 1 of 2-rectiﬁed ﬂow i s

almost independent with t, indicating that its trajectory is almost straight.

Figure 11: Examples of 256 × 256 images generated by 1-rectiﬁed ﬂow.



Figure 12: An example of image editing using 1-rectiﬁed ﬂow. Here, we stitch the images of a white cat and a black cat into an unnatural image (denoted as z 1). We simulate the ODE reversely from z 1 to get the latent code z 0. Because z 1 is not a natural image, z 0 should have low likelihood under π0 = N (0, I). Hence, we move z 0 towards the high probability region of π0 to get z′

## 0 and solve the ODE forwardly to get a more realistically looking image

z′

## 1. The modiﬁcation can be done deterministically by improving the π0-likelihood via z′

## 0 = αz0 with α ∈ (0, 1), o r

stochastically by Langevin dynamics, which yields a formula of z′

## 0 = αz0 + √1 − α2ξ with ξ ∼ N (0, I).

face, we are interested in getting a unrealistic face of human-cat hybrid that still “looks like” the original human face.

To achieve this, let h( x) be a feature mapping of image x representing the styles that we are interested in transferring. Let Xt = tX1 + (1 − t)X0. Then Ht = h(Xt) follows an ODE of dHt = ∇h(Xt)⊤(X1 − X0)d t. Hence, to ensure that the style is transferred correctly, we propose to learn v such that H ′ t = h(Zt) with dZt = v(Zt, t)d t approximates Ht as much as possible. Because dH ′ t = ∇h(Zt)⊤v(Zt, t)d t, we propose to minimize the following loss:

min v ∫ 1

## 0 E [∥

∥ ∥∇h(Xt)⊤(X1 − X0 − v(Xt, t)) ∥ ∥ ∥ 22 ] d t, Xt = tX1 + (1 − t)X0. (20)In practice, we set h( x) to be latent representation of a classiﬁer trained to distinguish the images from the two domains π0, π1, ﬁne-tuned from a pre-trained ImageNet [77] model. Intuitively, ∇x h( x) serves as a saliency score and r e-weights coordinates so that the loss in (20) focuses on penalizing the error that causes signiﬁcant changes on h.

Experiment settings We set the domains π0, π1 to be pairs of the AFHQ [9], MetFace [28] and CelebAHQ [27] dataset. For each dataset, we randomly select 80% as the training data and regard the rest as the test data; and the results are shown by initializing the trained ﬂows from the test data. We resize the image to 512 × 512. The training and network conﬁgurations generally follow the experiment settings in Section 5.2. See the appendix for detailed descriptions.

Results Figure 1, 13, 14, 15 show examples of results of 1- and 2-rectiﬁed ﬂow simulated with Euler method with different number of steps N . We can see that rectiﬁed ﬂows can successfully transfer the styles27(A) Cat → Wild Animals (B) Wild Animals → Cat (C) MetFace → CelebA Face (D) CelebA Face → MetFaceFigure 13: Samples of 1-rectiﬁed ﬂow simulated with N = 100 Euler steps between different domains.

Initialization 1-Rectiﬁed Flow 2-Rectiﬁed Flow 1-Rectiﬁed Flow 2-Rectiﬁed Flow N = 100 N = 100 N = 1 N = 

Figure 14: Samples of results of 1- and 2-rectiﬁed ﬂow simulated with N = 1 and N = 100 Euler steps.

and generate high quality images. For example, when transferring cats to wild animals, we can generate diverse images with different animal faces, e.g., fox, lion, tiger and cheetah. Moreover, with one step of reﬂow, 2-rectiﬁed ﬂow returns good results with a single Euler step (N = 1). See more examples in Appendix.

## 5.4 Domain Adaptation

A key challenge of applying machine learning to real-world problems is the domain shift between the training and test datasets: the performance of machine learning models may degrade signiﬁcantly when tested on a novel domain different from the training set. Rectiﬁed ﬂow can be applied to transfer the novel domain (π0) to the training domain (π1) to mitigate the impact of domain shift.

Experiment settings We test the rectiﬁed ﬂow for domain adaptation on a number of datasets. DomainNet [58] is a dataset of common objects in six different domain taken from DomainBed [20]. All domains from DomainNet include 345 categories (classes) of objects such as Bracelet, plane, bird and cello. Ofﬁce-Home [83] is a benchmark dataset for domain adaptation which contains 4 domains where each domain consists of 65 categories. To apply our method, ﬁrst we map both the training and testing data to the latent representation from ﬁnal hidden layer of the pre-trained model, and construct the rectiﬁed ﬂow on the latent representation.

28

## 1-Rectiﬁed Flow

## 2-Rectiﬁed Flow

## 1-Rectiﬁed Flow

## 2-Rectiﬁed Flow

(a) 1-rectiﬁed ﬂow between different domains (b) 1- and 2-rectiﬁed ﬂow for MetFace → Cat.

Figure 15: (a) Samples of trajectories zt of 1- and 2-rectiﬁed ﬂow for transferring between different domains.

Method ERM IRM ARM Mixup MLDG CORAL Ours OfﬁceHome 66.5 ± 0.3 64.3 ± 2.2 64.8 ± 0.3 68.1 ± 0.3 66.8 ± 0.6 68.7 ± 0.3 69.2 ± 0.5 DomainNet 40.9 ± 0.1 33.9 ± 2.8 35.5 ± 0.2 39.2 ± 0.1 41.2 ± 0.1 41.5 ± 0.2 41.4 ± 0.

Table 2: The accuracy of the transferred testing data using different methods, on the OfﬁceHome and DomainNet dataset. Higher accuracy means the better performance.

We use the same DDPM++ model architecture for training. For inference, we set the number of steps of our ﬂow model as 100 using uniform discretization. The methods are evaluated by the prediction accuracy of the transferred testing data on the classiﬁcation model trained on the training data.

Results As demonstrated in Table 2, the 1-rectiﬁed ﬂow shows state-o f-the-art performance on both DomainNet and OfﬁceHome. It is better or on par with the previous best approach (Deep CORAL [76]), while sustainably improve over all other methods. 29

## References

[1] Luigi Ambrosio and Gianluca Crippa. Existence, uniqueness, stability and differentiability properties of the ﬂow associated to weakly differentiable vector ﬁelds. In Transport equations and multi-D hyperbolic conservation laws, pages 3–57. Springer, 2008.

[2] Luigi Ambrosio, Elia Bru´e, and Daniele Semola. Lectures on optimal transport. Springer, 2021.

[3] Brian DO Anderson. Reverse-time diffusion equation models. Stochastic Processes and their Applications, 12(3):313–326, 1982.

[4] Martin Arjovsky, Soumith Chintala, and L´eon Bottou. Wasserstein generative adversarial networks. In International conference on machine learning, pages 214–223. PMLR, 2017.

[5] Fan Bao, Chongxuan Li, Jun Zhu, and Bo Zhang. Analytic-DPM: an analytic estimate of the optimal reverse variance in diffusion probabilistic models. arXiv preprint arXiv:2201.06503, 2022.

[6] Ricky TQ Chen, Yulia Rubanova, Jesse Bettencourt, and David K Duvenaud. Neural ordinary differential equations. Advances in neural information processing systems, 31, 2018.

[7] Tianrong Chen, Guan-Horng Liu, and Evangelos A Theodorou. Likelihood training of Schr¨odinger bridge using forward-backward sdes theory. arXiv preprint arXiv:2110.11291, 2021.

[8] Jooyoung Choi, Sungwon Kim, Yonghyun Jeong, Youngjune Gwon, and Sungroh Yoon. Ilvr: Conditioning method for denoising diffusion probabilistic models. arXiv preprint arXiv:2108.02938, 2021.

[9] Yunjey Choi, Youngjung Uh, Jaejun Yoo, and Jung-Woo Ha. StarGAN v 2: Diverse image synthesis for multiple domains. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pages 8188–8197, 2020.

[10] Max Daniels, Tyler Maunu, and Paul Hand. Score-based generative neural networks for large-scale optimal transport. Advances in neural information processing systems, 34:12955–12965, 2021.

[11] Valentin De Bortoli, James Thornton, Jeremy Heng, and Arnaud Doucet. Diffusion Schr¨odinger bridge with applications to score-based generative modeling. Advances in Neural Information Processing Systems, 34, 2021.

[12] Prafulla Dhariwal and Alexander Nichol. Diffusion models beat GANs on image synthesis. Advances in Neural Information Processing Systems, 34, 2021.

[13] Laurent Dinh, David Krueger, and Yoshua Bengio. Nice: Non-linear independent components estimation. arXiv preprint arXiv:1410.8516, 2014.

[14] Laurent Dinh, Jascha Sohl-Dickstein, and Samy Bengio. Density estimation using real nvp. arXiv preprint arXiv:1605.08803, 2016.

[15] Alessio Figalli and Federico Glaudo. An Invitation to Optimal Transport, Wasserstein Distances, and Gradient Flows. 2021.

[16] R Flamary, N Courty, D Tuia, and A Rakotomamonjy. Optimal transport for domain adaptation. IEEE Trans. Pattern Anal. Mach. Intell, 1, 2016. 30[17] Hans F¨ollmer. An entropy approach to the time reversal of diffusion processes. In Stochastic Differential Systems Filtering and Control, pages 156–163. Springer, 1985.

[18] Giulio Franzese, Simone Rossi, Lixuan Yang, Alessandro Finamore, Dario Rossi, Maurizio Filippone, and Pietro Michiardi. How much is enough? a study on diffusion times in score-based generative models. arXiv preprint arXiv:2206.05173, 2022.

[19] Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio. Generative adversarial nets. Advances in neural information processing systems, 27, 2014.

[20] Ishaan Gulrajani and David Lopez-Paz. In search of lost domain generalization. arXiv preprint arXiv:2007.01434, 2020.

[21] William Harvey, Saeid Naderiparizi, Vaden Masrani, Christian Weilbach, and Frank Wood. Flexible diffusion modeling of long videos. arXiv preprint arXiv:2205.11495, 2022.

[22] Ulrich G Haussmann and Etienne Pardoux. Time reversal of diffusions. The Annals of Probability, pages 1188–1205, 1986.

[23] Jonathan Ho, Ajay Jain, and Pieter Abbeel. Denoising diffusion probabilistic models. Advances in Neural Information Processing Systems, 33:6840–6851, 2020.

[24] Jonathan Ho, Tim Salimans, Alexey Gritsenko, William Chan, Mohammad Norouzi, and David J Fleet. Video diffusion models. arXiv preprint arXiv:2204.03458, 2022.

[25] Phillip Isola, Jun-Yan Zhu, Tinghui Zhou, and Alexei A Efros. Image-t o-image translation with conditional adversarial networks. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 1125–1134, 2017.

[26] Yifan Jiang, Shiyu Chang, and Zhangyang Wang. TransGAN: Two pure transformers can make one strong GAN, and that can scale u p. Advances in Neural Information Processing Systems, 34, 2021.

[27] Tero Karras, Timo Aila, Samuli Laine, and Jaakko Lehtinen. Progressive growing of GANs for improved quality, stability, and variation. In International Conference on Learning Representations, 2018.

[28] Tero Karras, Miika Aittala, Janne Hellsten, Samuli Laine, Jaakko Lehtinen, and Timo Aila. Training generative adversarial networks with limited data. Advances in Neural Information Processing Systems, 33:12104–12114, 2020.

[29] Tero Karras, Miika Aittala, Timo Aila, and Samuli Laine. Elucidating the design space of diffusionbased generative models. arXiv preprint arXiv:2206.00364, 2022.

[30] Valentin Khrulkov and Ivan Oseledets. Understanding DDPM latent codes through optimal transport. arXiv preprint arXiv:2202.07477, 2022.

[31] Diederik P Kingma and Jimmy Ba. Adam: A method for stochastic optimization. arXiv preprint arXiv:1412.6980, 2014. 31[32] Diederik P Kingma and Max Welling. Auto-encoding variational bayes. arXiv preprint arXiv:1312.6114, 2013.

[33] Zhifeng Kong, Wei Ping, Jiaji Huang, Kexin Zhao, and Bryan Catanzaro. Diffwave: A versatile diffusion model for audio synthesis. In International Conference on Learning Representations, 2020.

[34] Alexander Korotin, Lingxiao Li, Aude Genevay, Justin M Solomon, Alexander Filippov, and Evgeny Burnaev. Do neural optimal transport solvers work? a continuous wasserstein-2 benchmark. Advances in Neural Information Processing Systems, 34:14593–14605, 2021.

[35] Alexander Korotin, Daniil Selikhanovych, and Evgeny Burnaev. Neural optimal transport. arXiv preprint arXiv:2201.12220, 2022.

[36] Alex Krizhevsky, Geoffrey Hinton, et a l. Learning multiple layers of features from tiny images. 2009.

[37] Thomas G Kurtz. Equivalence of stochastic equations and martingale problems. In Stochastic analysis

## 2010, pages 113–130. Springer, 2011.

[38] Tuomas Kynk¨a¨anniemi, Tero Karras, Samuli Laine, Jaakko Lehtinen, and Timo Aila. Improved precision and recall metric for assessing generative models. Advances in Neural Information Processing Systems, 32, 2019.

[39] Hugo Lavenant and Filippo Santambrogio. The ﬂow map of the fokker–planck equation does not provide optimal transport. Applied Mathematics Letters, page 108225, 2022.

[40] Junhyeok Lee and Seungu Han. Nu-wave: A diffusion probabilistic model for neural audio upsampling. arXiv preprint arXiv:2104.02321, 2021.

[41] Xiang Lisa Li, John Thickstun, Ishaan Gulrajani, Percy Liang, and Tatsunori B Hashimoto. Diffusionlm improves controllable text generation. arXiv preprint arXiv:2205.14217, 2022.

[42] Qiang Liu. On rectiﬁed ﬂow and optimal coupling. preprint, 2022.

[43] Xingchao Liu, Chengyue Gong, Lemeng Wu, Shujian Zhang, Hao Su, and Qiang Liu. Fusedream: Training-free text-t o-image generation with improved clip+ gan space optimization. arXiv preprint arXiv:2112.01573, 2021.

[44] Xingchao Liu, Lemeng Wu, Mao Ye, and Qiang Liu. Let us build bridges: Understanding and extending diffusion generative models. arXiv preprint arXiv:2208.14699, 2022.

[45] Ilya Loshchilov and Frank Hutter. Decoupled weight decay regularization. arXiv preprint arXiv:1711.05101, 2017.

[46] Cheng Lu, Yuhao Zhou, Fan Bao, Jianfei Chen, Chongxuan Li, and Jun Zhu. DPM-solver: A fast ODE solver for diffusion probabilistic model sampling in around 10 steps. arXiv preprint arXiv:2206.00927, 2022.

[47] Eric Luhman and Troy Luhman. Knowledge distillation in iterative generative models for improved sampling speed. arXiv preprint arXiv:2101.02388, 2021.

[48] Zhaoyang Lyu, Xudong Xu, Ceyuan Yang, Dahua Lin, and Bo Dai. Accelerating diffusion models via early stop of the diffusion process. arXiv preprint arXiv:2205.12524, 2022.

32[49] Ashok Makkuva, Amirhossein Taghvaei, Sewoong Oh, and Jason Lee. Optimal transport mapping via input convex neural networks. In International Conference on Machine Learning, pages 6672–6681. PMLR, 2020.

[50] Chenlin Meng, Yang Song, Jiaming Song, Jiajun Wu, Jun-Yan Zhu, and Stefano Ermon. Sdedit: Image synthesis and editing with stochastic differential equations. arXiv preprint arXiv:2108.01073, 2021.

[51] Gautam Mittal, Jesse Engel, Curtis Hawthorne, and Ian Simon. Symbolic music generation with diffusion models. arXiv preprint arXiv:2103.16091, 2021.

[52] Takeru Miyato, Toshiki Kataoka, Masanori Koyama, and Yuichi Yoshida. Spectral normalization for generative adversarial networks. In International Conference on Learning Representations, 2018.

[53] Alex Nichol, Prafulla Dhariwal, Aditya Ramesh, Pranav Shyam, Pamela Mishkin, Bob McGrew, Ilya Sutskever, and Mark Chen. Glide: Towards photorealistic image generation and editing with text-guided diffusion models. arXiv preprint arXiv:2112.10741, 2021.

[54] Alexander Quinn Nichol and Prafulla Dhariwal. Improved denoising diffusion probabilistic models. In International Conference on Machine Learning, pages 8162–8171. PMLR, 2021.

[55] Derek Onken, Samy Wu Fung, Xingjian Li, and Lars Ruthotto. Ot-ﬂow: Fast and accurate continuous normalizing ﬂows via optimal transport. In Proceedings of the AAAI Conference on Artiﬁcial Intelligence, volume 35, pages 9223–9232, 2021.

[56] George Papamakarios, Eric T Nalisnick, Danilo Jimenez Rezende, Shakir Mohamed, and Balaji Lakshminarayanan. Normalizing ﬂows for probabilistic modeling and inference. J. Mach. Learn. Res.,

## 22(57):1–64, 2021.

[57] Stefano Peluchetti. Non-denoising forward-time diffusions. 2021.

[58] Xingchao Peng, Qinxun Bai, Xide Xia, Zijun Huang, Kate Saenko, and Bo Wang. Moment matching for multi-source domain adaptation. In Proceedings of the IEEE/CVF international conference on computer vision, pages 1406–1415, 2019.

[59] Gabriel Peyr´e, Marco Cuturi, et a l. Computational optimal transport: With applications to data science. Foundations and Trends® in Machine Learning, 11(5-6):355–607, 2019.

[60] Vadim Popov, Ivan Vovk, Vladimir Gogoryan, Tasnima Sadekova, and Mikhail Kudinov. Grad-tts: A diffusion probabilistic model for text-t o-speech. In International Conference on Machine Learning, pages 8599–8608. PMLR, 2021.

[61] Aditya Ramesh, Prafulla Dhariwal, Alex Nichol, Casey Chu, and Mark Chen. Hierarchical textconditional image generation with clip latents. arXiv preprint arXiv:2204.06125, 2022.

[62] Danilo Rezende and Shakir Mohamed. Variational inference with normalizing ﬂows. In International conference on machine learning, pages 1530–1538. PMLR, 2015.

[63] Litu Rout, Alexander Korotin, and Evgeny Burnaev. Generative modeling with optimal transport maps. arXiv preprint arXiv:2110.02999, 2021.

33[64] Chitwan Saharia, William Chan, Saurabh Saxena, Lala Li, Jay Whang, Emily Denton, Seyed Kamyar Seyed Ghasemipour, Burcu Karagol Ayan, S Sara Mahdavi, Rapha Gontijo Lopes, et a l. Photorealistic text-t o-image diffusion models with deep language understanding. arXiv preprint arXiv:2205.11487, 2022.

[65] Filippo Santambrogio. Optimal transport for applied mathematicians. Birk¨auser, NY, 55(58-63):94, 2015.

[66] Axel Sauer, Katja Schwarz, and Andreas Geiger. StyleGAN-XL: Scaling StyleGAN to large diverse datasets. In Special Interest Group on Computer Graphics and Interactive Techniques Conference Proceedings, pages 1–10, 2022.

[67] Vivien Seguy, Bharath Bhushan Damodaran, R´emi Flamary, Nicolas Courty, Antoine Rolet, and Mathieu Blondel. Large-scale optimal transport and mapping estimation. arXiv preprint arXiv:1711.02283, 2017.

[68] Abhishek Sinha, Jiaming Song, Chenlin Meng, and Stefano Ermon. D2C: Diffusion-decoding models for few-shot conditional generation. Advances in Neural Information Processing Systems, 34:12533–

## 12548, 2021.

[69] Leslie N Smith and Nicholay Topin. Super-convergence: Very fast training of neural networks using large learning rates. In Artiﬁcial intelligence and machine learning for multi-domain operations applications, volume 11006, pages 369–386. SPIE, 2019.

[70] Jiaming Song, Chenlin Meng, and Stefano Ermon. Denoising diffusion implicit models. In International Conference on Learning Representations, 2020.

[71] Yang Song and Stefano Ermon. Generative modeling by estimating gradients of the data distribution. Advances in Neural Information Processing Systems, 32, 2019.

[72] Yang Song and Stefano Ermon. Improved techniques for training score-based generative models. Advances in neural information processing systems, 33:12438–12448, 2020.

[73] Yang Song, Jascha Sohl-Dickstein, Diederik P Kingma, Abhishek Kumar, Stefano Ermon, and Ben Poole. Score-based generative modeling through stochastic differential equations. In International Conference on Learning Representations, 2020.

[74] Yang Song, Conor Durkan, Iain Murray, and Stefano Ermon. Maximum likelihood training of scorebased diffusion models. Advances in Neural Information Processing Systems, 34, 2021.

[75] Xuan Su, Jiaming Song, Chenlin Meng, and Stefano Ermon. Dual diffusion implicit bridges for image-t o-image translation. arXiv preprint arXiv:2203.08382, 2022.

[76] Baochen Sun and Kate Saenko. Deep coral: Correlation alignment for deep domain adaptation. In European conference on computer vision, pages 443–450. Springer, 2016.

[77] Mingxing Tan and Quoc Le. Efﬁcientnet: Rethinking model scaling for convolutional neural networks. In International conference on machine learning, pages 6105–6114. PMLR, 2019.

[78] Anastasiya Tanana. Comparison of transport map generated by heat ﬂow interpolation and the optimal transport brenier map. Communications in Contemporary Mathematics, 23(06):2050025, 2021.

34[79] Giulio Trigila and Esteban G Tabak. Data-driven optimal transport. Communications on Pure and Applied Mathematics, 69(4):613–648, 2016.

[80] Belinda Tzen and Maxim Raginsky. Theoretical guarantees for sampling and inference in generative models with latent diffusions. In Conference on Learning Theory, pages 3084–3114. PMLR, 2019.

[81] Arash Vahdat, Karsten Kreis, and Jan Kautz. Score-based generative modeling in latent space. Advances in Neural Information Processing Systems, 34:11287–11302, 2021.

[82] Francisco Vargas, Pierre Thodoroff, Austen Lamacraft, and Neil Lawrence. Solving Schr¨odinger bridges via maximum likelihood. Entropy, 23(9):1134, 2021.

[83] Hemanth Venkateswara, Jose Eusebio, Shayok Chakraborty, and Sethuraman Panchanathan. Deep hashing network for unsupervised domain adaptation. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 5018–5027, 2017.

[84] C´edric Villani. Optimal transport: old and new, volume 338. Springer, 2009.

[85] C´edric Villani. Topics in optimal transportation, volume 58. American Mathematical Soc., 2021.

[86] Pauli Virtanen, Ralf Gommers, Travis E. Oliphant, Matt Haberland, Tyler Reddy, David Cournapeau, Evgeni Burovski, Pearu Peterson, Warren Weckesser, Jonathan Bright, St´efan J. van der Walt, Matthew Brett, Joshua Wilson, K. Jarrod Millman, Nikolay Mayorov, Andrew R. J. Nelson, Eric Jones, Robert Kern, Eric Larson, C J Carey, ˙Ilhan Polat, Yu Feng, Eric W. Moore, Jake VanderPlas, Denis Laxalde, Josef Perktold, Robert Cimrman, Ian Henriksen, E. A. Quintero, Charles R. Harris, Anne M. Archibald, Antˆonio H. Ribeiro, Fabian Pedregosa, Paul van Mulbregt, and SciPy 1.0 Contributors. SciPy 1.0: Fundamental Algorithms for Scientiﬁc Computing in Python. Nature Methods,

## 17:261–272, 2020. doi: 10.1038/s41592-019-0686-2.

[87] Gefei Wang, Yuling Jiao, Qian Xu, Yang Wang, and Can Yang. Deep generative learning via Schr¨odinger bridge. In International Conference on Machine Learning, pages 10794–10804. PMLR, 2021.

[88] Rose E Wang, Esin Durmus, Noah Goodman, and Tatsunori Hashimoto. Language modeling via stochastic processes. arXiv preprint arXiv:2203.11370, 2022.

[89] Antoine Wehenkel and Gilles Louppe. Diffusion priors in variational autoencoders. arXiv preprint arXiv:2106.15671, 2021.

[90] Lemeng Wu, Chengyue Gong, Xingchao Liu, Mao Ye, and Qiang Liu. Diffusion-based molecule generation with informative prior bridges. arXiv preprint, 2022.

[91] Zhisheng Xiao, Karsten Kreis, and Arash Vahdat. Tackling the generative learning trilemma with denoising diffusion GANs. arXiv preprint arXiv:2112.07804, 2021.

[92] Ruihan Yang, Prakhar Srivastava, and Stephan Mandt. Diffusion probabilistic modeling for video generation. arXiv preprint arXiv:2203.09481, 2022.

[93] Fisher Yu, Ari Seff, Yinda Zhang, Shuran Song, Thomas Funkhouser, and Jianxiong Xiao. Lsun: Construction of a large-scale image dataset using deep learning with humans in the loop. arXiv preprint arXiv:1506.03365, 2015. 35[94] Qinsheng Zhang and Yongxin Chen. Fast sampling of diffusion models with exponential integrator. arXiv preprint arXiv:2204.13902, 2022.

[95] Qinsheng Zhang, Molei Tao, and Yongxin Chen. gDDIM: Generalized denoising diffusion implicit models. arXiv preprint arXiv:2206.05564, 2022.

[96] Richard Zhang, Phillip Isola, Alexei A Efros, Eli Shechtman, and Oliver Wang. The unreasonable effectiveness of deep features as a perceptual metric. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 586–595, 2018.

[97] Min Zhao, Fan Bao, Chongxuan Li, and Jun Zhu. EGSDE: Unpaired image-t o-image translation via energy-guided stochastic differential equations. arXiv preprint arXiv:2207.06635, 2022.

[98] Shengyu Zhao, Zhijian Liu, Ji Lin, Jun-Yan Zhu, and Song Han. Differentiable augmentation for data-efﬁcient GAN training. Advances in Neural Information Processing Systems, 33:7559–7570, 2020.

[99] Huangjie Zheng, Pengcheng He, Weizhu Chen, and Mingyuan Zhou. Truncated diffusion probabilistic models. arXiv preprint arXiv:2202.09671, 2022.

[100] Jun-Yan Zhu, Taesung Park, Phillip Isola, and Alexei A Efros. Unpaired image-t o-image translation using cycle-consistent adversarial networks. In Proceedings of the IEEE international conference on computer vision, pages 2223–2232, 2017. 36Algorithm 2 Train(Data) # Input: Data={x 0, x 1} # Output: Model v( x, t) for the rectified flow initialize Model for x 0, x 1 in Data: # x 0, x 1: samples from π0, π1 Optimizer.zero grad() t = torch.rand( batchsize) # Randomly sample t ∈ [0,1] Loss = ( Model( t*x 1+(1-t)*x 0, t) - (x 1-x 0) ).pow(2).mean() Loss.backward() Optimizer.step() return ModelAlgorithm 3 Sample(Model, Data) # Input: Model v( x, t) of the rectified flow # Output: draws of the rectified coupling (Z0, Z1) coupling = [] for x 0, in Data: # x 0: samples from π0 (batchsize×dim) x 1 = model.ODE solver( x 0) coupling.append((x 0, x 1)) return couplingAlgorithm 4 Reflow(Data) # Input: Data={x 0, x 1} # Output: draws of the K-t h rectified coupling Coupling = Data for k = 1, . . . , K: Model = Train(Coupling) Coupling = sample(Model, Data) return CouplingA Additional Experiment DetailsExperiment Conﬁguration on CIFAR10 We conduct unconditional image generation with the CIFAR10 dataset [36]. The resolution of the images are set to 32 × 32. For rectiﬁed ﬂow, we adopt the same network structure as DDPM++ in [73]. The training of the network is smoothed by exponential moving average as in [73], with a ratio of 0.999999. We adopt Adam [31] optimizer with a learning rate of 2e − 4 and a dropout rate of 0.15.

For reﬂow, we ﬁrst generate 4 million pairs of (z 0, z 1) to get a new dataset D, then ﬁne-tune the i-rectiﬁed ﬂow model for 300, 000 steps to get the (i + 1)-rectiﬁed ﬂow model. We further distill these rectiﬁed ﬂow models for few-step generation. To get a k-step image generator from the i-rectiﬁed ﬂow, we randomly sample t ∈ {0, 1/k, · · · , (k − 1)/k} during ﬁne-tuning, instead of randomly sampling t ∈ [0, 1]. Speciﬁcally, for k = 1, we replace the L2 loss function with the LPIPS similarity [96] since it empirically brings better performance. 

Figure 16: Few-step generation with different ODEs. Compared with VE,VP,sub-VP ODE, 1-rectiﬁed ﬂow can generate blurry images using only 1,2,3 steps. After one time of rectiﬁcation, 2-rectiﬁed ﬂow can generate clear images with 1,2,3 steps.

Expreiment Conﬁguration on Image-t o-Image Translation In this experiment, we also adopt the same U-Net structure of DDPM++ [73] for representing the drift vX . We follow the procedure in Algorithm 1. For the purpose of generative modeling, we set π0 to be one domain dataset and π1 the other domain dataset. For optimization, we use AdamW [45] optimizer with β (0.9, 0.999), weight decay 0.1 and dropout rate 0.1. We train the model with a batch size of 4 for 1, 000 epochs. We further apply exponential moving average (EMA) optimizer with coefﬁcient 0.9999. We perform grid-search on the learning rate from {5 × 10−4, 2 ×

## 10−4, 5 × 10−5, 2 × 10−5, 5 × 10−6} and pick the model with the lowest training loss.

We use the AFHQ [9], MetFace [28] and CelebA-HQ [27] dataset. Animal Faces HQ (AFHQ) is an animalface dataset consisting of 15,000 high-quality images at 512 × 512 resolution. The dataset includes three domains of cat, dog, and wild animals, each providing 5000 images. MetFace consists of 1,336 high-quality PNG human-face images at 1024 × 1024 resolution, extracted from works of art. CelebA-HQ is a humanface dataset which consists of 30,000 images at 1024 × 1024 resolution. We randomly select 80% as the training data and regard the rest as the test data, and resize the image to 512 × 512.

Experiment Conﬁguration on Domain Adaptation For training the model, we apply AdamW [45] optimizer with batch size 16, number of iterations 50k, learning rate 10−4, weight decay 0.1 and OneCycle [69] learning rate schedule. 

Figure 17: To visualize the latent space, we randomly sample z 0 and z 1 from N (0, I), and show the generated images of √αz0 + √1 − αz1 for α ∈ [0, 1].

Figure 18: (a) We compare the latent space between Rectiﬁed Flow (0) and (1) using different sampling strategies with the same random seeds. We observe that (i) both 1-Rectiﬁed Flow and 2-Rectiﬁed Flow can provide a smooth latent interpolation, and their latent spaces look similar; (i i) when using one-step sampling (N = 1), 2-Rectiﬁed Flow can still provide visually recognizable interpolation, while 1-Rectiﬁed Flow cannot; (iii) Distilled one-step models can also continuously interpolate between the images, and their latent spaces have little difference with the original ﬂow. (b) We composite the latent codes of two images by replacing the boundary of a black cat with a white cat, then visualize the variation along the trajectory. The black cat turns into a grey cat at ﬁrst, then a cat with mixing colors, and ﬁnally a white cat. (c) We randomly sample ξ ∼ N (0, I), then generate images with αξ to examine the inﬂuence of α on the generated images. We ﬁnd α < 1 results in overly smooth images, while α > 1 leads to noisy images.

39t0 1

## 0 1 t

## 2-Rectified Flow

## 0.001 0.002 0.1 0.3 0.5 0.8

tsubVP-ODE

## 0 10.001 0.002 0.1 0.3 0.5 0.8

## 0 1 t

## 1-Rectified Flow

## 0.001 0.002 0.1 0.3 0.5 0.8

Figure 19: Sample trajectories zt of different ﬂows on the CIFAR10 dataset, and the extrapolation ˆzt

## 1 = zt + (1 −

t)v( z t, t) from different z t. The same random seed is adopted for all three methods. The ˆzt

## 1 of 2-rectiﬁed ﬂow i s

almost independent with t, indicating that its trajectory is almost straight.

Figure 20: We perform latent space embedding / image reconstruction here. Given an image z 1, we use an reverse ODE solver to get a latent code ˆz0, then use a forward ODE solver to get a reconstruction ˆz1 of the image. The columns in the ﬁgure are reverse ODE solver (forward ODE solver). (i) Thanks to the‘straightening’ effect, 2-rectiﬁed ﬂow can get meaningful latent code with only one reverse step. It can also generate recognizable images using one forward step. (i i) With the help of distilled models, one-step embedding and reconstruction is signiﬁcantly improved.



Figure 21: More results for image-t o-image translation between different domains. The images in each row are timeuniformly sampled from the trajectory of 1-rectiﬁed ﬂow solved N = 100 Euler steps with constant step size.

41