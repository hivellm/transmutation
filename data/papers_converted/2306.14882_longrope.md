## Citadel: Simple Spectre-Safe Isolation For Real-World Programs

## That Share Memory

Jules Drean MIT CSAIL Miguel Gomez-Garcia MIT CSAIL Fisher Jepsen MIT CSAIL Thomas Bourgeat EPFL Srinivas Devadas MIT CSAIL

## Abstract

Transient execution side-channel attacks, such as Spectre, have been shown to break almost all isolation primitives. We introduce a new security property we call relaxed microarchitectural isolation (RMI) that allows sensitive programs that are not-constant-time to share memory with an attacker while restricting the information leakage to that of non-speculative execution. Although this type of speculative security property is typically challenging to enforce, we show that we can leverage the enclave setup to achieve i t. In particular, we use microarchitectural isolation to restrict attacker’s observations in conjunction with straightforward hardware mechanisms to limit speculation. This new design point presents a compelling trade-off between security, usability, and performance, making it possible to efficiently enforce RMI for any program. We demonstrate our approach by implementing and evaluating two simple defense mechanisms that satisfy RMI: (1) Safe mode, which disables speculative accesses to shared memory, and (2) Burst mode, a localized performance optimization that requires simple program analysis on small code snippets. Our end-t o-end prototype, Citadel, consists of an FPGA-based multicore processor that boots Linux and runs secure applications, including cryptographic libraries and private inference, with less than 5% performance overhead.

## 1 Introduction

Citadel proposes a simple and efficient solution to an important problem: “How to defend against transient execution side channels for a program that 1) touches secrets, 2) is not written in constant-time, and 3) shares some memory with an attacker”. We call this problem P . It represents a common case for security-sensitive programs in the real world which do not aim for leakage-free execution times. For example, consider a private inference service [7] that needs to isolate the machine learning model and private user requests from the rest of the system, while still accessing the network, a GPU, and communicating with other processes in charge of access control and business logic. Secure BootloaderOther Enclave User-Level App EnclaveOS - LinuxSecurity MonitorShared MemoryO-O-O ProcessorSM-Kernel ModulePrivilege LevelTrustedUntrustedImplemented in this paperUSM Secure Shared Memory + Speculative DefensesLLC Reconfigurable Partitioning + Flushing Figure 1: Citadel’s Computing Stack.

Transient execution side channel (TES) attacks such as Spectre [59] combine speculative execution and microarchitectural side channels to exfiltrate secrets. Among the numerous Spectre variants, those exploiting cache side channels are some of the most powerful. These attacks only require an attacker and the victim to share any address space (e.g., through shared memory) to make it possible to construct “universal read gadgets,” exposing all the victim’s private memory. They are also particularly challenging to mitigate and circumvent almost all hardware and software isolation mechanisms. For example, in a scenario like serverless computing, these attacks can compromise the isolation between containers and virtual machines, or enable privilege escalation [113]. Trusted execution environments (TEEs) or secure enclaves [5, 11, 19, 27, 29, 30, 38, 39, 65, 68, 72, 86, 97] are some of the most ambitious isolation primitives. These hardware mechanisms aim to completely isolate sensitive processes even in the presence of a privileged software attacker, such as a malicious operating system (OS) or hypervisor (for example, see Figure 1). However, most of these platforms have been proven vulnerable to TES attacks [1, 20, 26, 37, 42, 43, 60, 60,

## 90, 101–103, 108]. On commercial enclave platforms such a s

Intel SGX [29] or AMD SEV [97], defending against TES is still an open problem, and all responsibility is pushed to program developers. Countermeasures rely on the placement

## 1arXiv:2306.14882v5  [c s.CR]  7 Feb 2025

o f fences and special instructions in the binary (see Section

## 9), a challenging process that needs to balance preservation o f

performance and complexity of code analysis, often achieving unclear security guarantees. One academic work, MI6 [18], looks at securing enclave programs in the presence of TES through complete microarchitectural isolation. However, they took the approach to the extreme by disabling shared memory altogether. This significantly reduces the usability and applicability of enclaves, in contrast to commercial enclave platforms and other isolation primitives such as containers or trusted VMs, which all rely heavily on shared memory to implement many important functionalities, such as input passing, I/O, device virtualization, or micro-services chaining (see Section 3.1). Beyond enclave-specific solutions, other works have explored software and hardware defense mechanisms against TES attacks (see Section 9). Each of these mechanisms addresses a slightly different trade-off between security, performance, and use cases (see Sections 3.3). Within that design space, Citadel and its simple mechanisms stand out as well equipped to efficiently address P .

This paper. We start by defining a new speculative security property—relaxed microarchitectural isolation (RMI)—that allows non-constant-time programs that touch secrets to share memory (i.e. to address P ) while providing precise guarantees on information leaked to an attacker. For a given defense scheme, RMI is achieved if information leakage through the microarchitecture is equivalent to the trace of shared memory accesses when executing the program non-speculatively (inorder, one instruction at a time). We use the formalism from hardware-software contracts for security [24, 45, 46, 74] to compare and relate RMI with other existing speculative security properties (see Figure 3. We show that RMI is equivalent to a weak/simple contract, which makes it possible to secure a very large class of programs despite enforcing a very strong security property under a strong threat model. We describe RMI in the context of shared memory between an enclave and the OS. However, our work also applies to private shared memory between programs and can help compose code following other non-interference properties such as speculative constant time [45]. Our work also extends to other types of isolation mechanisms and TEEs, such as containers or trusted VMs. To enforce RMI, we design Citadel using two strategies:

## 1) we use microarchitectural isolation to weaken attacker

capabilities and satisfy a weaker leakage model. 2) we use simple hardware mechanisms to constrain speculation in order to enforce simple execution models. Because we focus on programs that are not implemented using constant time and do not aim for leakage-free execution times, our threat model allows for some leakage of coarse grain timing information (see Section 4.2). This offers a compelling trade-off between security and enabling simpler and more efficient mechanisms that can secure a large class of enclave programs against Spectre-like attacks. Starting from a design that enforces strong microarchitectural isolation, we show how to enable shared memory while limiting the attacker observations to the trace of (speculative) accesses to shared memory. This requires being careful with the core-private state that can now be shared between private and shared memory. For example, we highlight how an attacker can observe the private state of L1 by exploiting a new side channel that leverages the cache coherence protocol. Once attacker observations have been restricted, we present two simple approaches to limit speculative leakage: (1) Safe mode is our default execution mode and prevents speculative shared memory accesses entirely, making it possible to enforce RMI for any program, (2) Burst mode can be enabled locally to allow some speculation on shared memory accesses and improve overall performance. The Burst mode microarchitecture enforces a slightly stronger contract compared to Safe mode (more speculative control flows are considered public). As a result, Burst needs to be supplemented by a static analysis tool that identifies programs that satisfy the correct relative non-interference property. Nevertheless, the property is simple enough that programmers can easily reason about it and can be checked automatically using some simple tool. We use a contract formalism to show that the resulting hardware-software defense satisfies RMI. We show how code analysis can be simplified by restricting it to small code snippets, circumventing the usual limitations of automated tools. Note that code annotation and analysis are only required to improve performance and that all programs are secure as is without manual annotation. Code can be written to use the two modes simultaneously and can be safely composed or reused without the need for additional analysis.

Our prototype. Citadel, is an out-o f-order RISC-V 2-core processor synthesized for an AWS F1 FPGA. We apply our design principles and implement all mechanisms at the microarchitectural level. We restrict the attacker’s observations through L1-cache bypass and TLB / translation cache tagging. We also implement a configurable cache partitioning mechanism, improving performance for both enclaves and unprotected processes. We implement Safe mode and Burst modes with minimal hardware overhead (<+1% LUTs and FFs). To evaluate our prototype, we implement a comprehensive software infrastructure that includes a bootloader, a security monitor, a kernel module, and an end-t o-end attestation mechanism. Citadel boots (untrusted) Linux and enables user-level applications to interact safely with secure enclaves. For unprotected software, we measure negligible overhead (≃ 0.1%). To demonstrate the platform’s versatility, we port three securitysensitive programs: a lightweight Python runtime, a cryptographic library, and a private ML inference program. We show that very little implementation effort is required to port the2applications to Citadel: Less than 200 new LOC and minimal automated code analysis for performance overheads under 5%. Figure 1 provides an overview of our implementation work. We open source our hardware and software infrastructure at https://github.com/mit-enclaves/citadel.

In summary, our contributions include the following: • We present the first microarchitecturally-isolated TEE with Spectre-safe shared memory;• We introduce the notion of relaxed microarchitectural isolation, a new security property that allows non-constant-time, sensitive programs to share memory while thwarting TES attacks;• We demonstrate that microarchitectural isolation and simple hardware mechanisms for controlled speculation make it possible to effectively defend against most TES attacks;• We implement and evaluate two simple mechanisms—Safe mode and Burst mode—that achieve RMI for any program while offering the option to balance performance and the need for simple program analysis;• We show how to compose code with different speculative security properties and that program analysis can be constrained to small code snippets, circumventing the usual scaling issues of automated tools;• We use formalism from hardware-software contracts for security to compare RMI with other security property and show that Citadel enforces i t;• We show that our approach allows for minimal hardware overhead (<1% for Safe and Burst mode) and minimal performance overhead (<5% on our benchmarks);Disclaimer. Citadel is a simple and efficient solution to an important problem. We do not claim the invention of the simple hardware mechanisms we compose to achieve security. On the contrary, we aim to highlight that complex mechanisms are not necessary here. Similarly, most of the insights we present might be considered folklore by some readers. We show how all these elements are tightly integrated to create a novel point in the design space at the intersection of TEEs and TES defense mechanisms, presenting a compelling trade-off between performance, usability, and security.

## 2 Background

Security Monitor: In many enclave platforms, the security monitor (SM) [30, 63] is a small (9K LOC in our prototype), trusted piece of software running at a higher privilege mode than the hypervisor or the OS (see Figure 1). Its role is to link low-level invariants exposed by the hardware (e.g., if a specific memory access is authorized), to the high-level security policies defined by the platform (e.g., which enclave can access which memory regions) and to invoke the right microarchitectural cleanup routine.

Microarchitectural Timing Side Channels: Microarchitectural side channels enable information leakage between security domains by exploiting shared microarchitectural structures. These include memory caches [20, 42], translation look-aside buffers (TLBs) [43], branch predictors [1, 37], DRAM controllers [108], or any other shared microarchitecture. Attackers typically rely on event timing to indirectly observe microarchitectural state, as it cannot be directly accessed through the instruction set architecture (ISA). For example, cached data access is faster than main memory access. By manipulating shared microarchitectural state and observing changes due to victim activity, attackers can infer sensitive information about the victim’s execution, such as accessed addresses or branch directions.

Transient Execution Side Channels (TES): Speculative or transient execution, a key performance feature in modern processors, complicates security boundary reasoning. Attackers can manipulate microarchitectural structures that orchestrate speculation (like branch predictors) to trigger speculative execution of code snippets that bypass normal security checks. Although these erroneous executions are eventually squashed, they alter microarchitectural state (e.g., cache states), potentially leaking sensitive information through side channels. This class of attacks, known as Spectre, was introduced in Kocher et a l. [59] and has since spawned numerous variants.

Hardware Software Contract for Security: Recent work [24, 46, 74] has focused on defining formal foundations for speculative security properties using hardware-software contracts. Contract semantics consist of two components: a leakage model (leak) and an execution model (exec) and are represented using the notation J · Kexec leak. The leakage model describes what architectural state is made public by the software (e.g. execution trace and trace of memory accesses for the ct model). The execution model, on the other hand, models the “safe” speculative behavior i.e. which speculative control flows are considered public by the software. A defense mechanism, represented by the attacker model {| · |} (formally a projection of the microarchitectural state), satisfies a contract J · K if it does not leak more information than what the contract specifies as public. We write {| · |} ⊢ J · K. Although the software does not directly satisfy contracts per say, it can verify non-interference properties with respect to contracts. For a program p, direct non-interference with respect to contract J · K means the program will not make any secret information public under that contract. We write this as p ⊢ NI(J · K) and say p satisfies J · K for simplicity. Additionally, relative noninterference from J · KA to J · KB, means that it will not expose more information under J · KB than what is made public by J · KA. We write p ⊢ NI(J · KA ⇒ J · KB). Detailed definitions3 EnclaveL1 L1MSHR MSHROSLLCDRAM

## 1 2

* Location in cache depends on the secretSlow to resolve if i < 10: s  =  private [ i ]d =  shared[ s ]Executes speculatively Spectre Pseudocode

Figure 2: Universal Read Gadget Through Shared Memoryare recalled in appendix A.

## 3 Motivation

## 3.1 Utility of Shared Memory

In all commercial enclave platforms, shared memory serves as the primary communication primitive for crucial mechanisms including input/output/message passing, networking [29, 55], or access to large public data structures that exceed private memory capacity (e.g., public neural network for private inference as in Section 8.2). Other isolation primitives like containers and trusted VMs also dependent on shared memory to efficiently chain micro-services [87, 91] or to implement mechanisms like VirtIO [50]. Alternative approaches such as message passing or DMA copy mechanisms are limited to passing small inputs or to sequential memory accesses, making it overly complex to do tasks such as accessing a linked list of inputs or doing random memory accesses, for example, accessing a database using ORAM [76]. For instance, MI6 briefly mentions a mailbox mechanism which demands application rewrites, limits message sizes to a few bytes, and incurs substantial overheads due to two data copies and two full microarchitectural context switches for each message.

## 3.2 Universal Read Gadget Through Shared

MemoryShared memory enables LLC side channels and Spectre-like attacks. We demonstrate a proof-o f-concept variant SpectrePHT or v 1 [59] attack on our insecure FPGA baseline, exfiltrating arbitrary private enclave memory via the shared LLC side channel (see Figure 2). Note that this insecure baseline is also vulnerable to other Spectre variants like BTB, RSB or STL [13, 21, 48, 60, 71, 114]. The victim enclave exposes an API allowing access to a public array, with outof-bounds accesses protected by a branch. The value fetched from the first array is used to access a second array located in shared memory, effectively leaking the first value through the cache side channel. This creates a “universal read gadget,” commonly found in code [21, 54, 88, 114]. By training the branch predictor, a malicious OS can perform speculative out-o f-bounds accesses, leaking arbitrary enclave secrets. In particular, shared-memory content (encrypted or not) is irrelevant, as information is leaked through which address is accessed. The code for our attack is available in our repository. We were unable to successfully mount the attack on our final secure design.

## 3.3 Going Beyond the Sandboxing and

Constant-Time ScenarioSandboxing Scenario Many existing defense mechanisms against TES attacks such as STT [52, 120] or SpecShield [12] try to enforce “speculative memory safety” or “speculative isolation”, that i s, to enforce the sandbox isolation model [16, 25, 53, 58, 77, 78, 80, 88, 98, 119]. Sandboxing is an isolation primitive that aims to protect the rest of a system from a malicious program. This is a much weaker threat model than enclaves that aim to also protect the isolated program. Specifically, the mechanisms in this scenario often assume that the architectural state of the isolated program is public and is not protected against TES attacks. As a result, these mechanisms are not the best candidate building blocks for isolating sensitive programs that touch secrets, therefore to address P .

Constant Time Scenario Other proposals, such as Prospect [33] or SPT [28] and others [15,23,32,44,45,85,105] only target constant-time programs. This is a very important problem to solve but only concerns a subset of programs, namely cryptographic algorithms written in a very specific constant time fashion [4]. This also makes these mechanisms overkill to specifically address P . No programmer will rewrite operating systems (i n the case of trusted VM), Python libraries, data analysis pipelines, or business logic using constant-time programming. Citadel focuses on defining a speculative security property and building defense mechanisms for the majority of security-sensitive programs, which are not implemented using constant time and do not aim for leakage-free execution times (see Section 4.2).

Speculative Non-Interference is Too Restrictive Existing hardware defenses studied under the hardware-contract framework only target the two above scenarios. They use one of two strong leakage models, each defining a lot of architectural state as public. The constant-time model (c t for short) makes public the trace of the pc (i.e. the control flow) and the trace of all memory accesses (but not their values). The architectural or sandboxing model (arch) extends the ct model to include the values of elements loaded from memory. Figure 3 shows how the resulting contracts relate to each other. Working with these strong leakage models strongly restricts the class of programs that can be run without exposing secrets (i.e., programs that satisfy those contracts), and only works in the abovementioned scenarios. This makes these leakage models, along with any associated speculative security properties, too strong4to address P efficiently. This includes properties such as speculative constant time, (weak) speculative non-interference, and others. A summary of all these properties can be found in the SoK by Cauligi e t. a l. [24].

## 4 Threat Model and Security Property

## 4.1 Attacker Capabilities

We follow the usual attacker model for TEEs. We assume a privileged software attacker c o-located on the same machine as the victim enclave. The attacker has compromised the majority of the software stack, including other enclaves and the OS, except for a limited trusted code base (TCB) including the secure bootloader, the SM (together 15K lines of code (LOC)) and the victim program running inside the enclave (see Figure 1). Note that the TCB may contain Spectre gadgets. The attacker also has control over the contents of shared memory and may control some of the enclave’s inputs. For the rest of this paper, we refer to any code outside the TCB as the OS. Attackers can exploit the timing of shared microarchitectural events to mount TES attacks.

## 4.2 Attacks Considered Out-o f-Scope

Execution-Time Side Channel The time an enclave takes to execute might depend on a secret which can be exploited by an attacker. This includes the timing between any observable (micro)architectural events like syscalls or accesses to shared memory. We refer to these attacks as exploiting "execution time". These attacks can only be addressed for constant-time programs [28, 32, 33, 95, 120]. To defend against executiontime attacks for this restricted class of programs, Citadel offers the option to disable speculation as w ed o in the SM (w e evaluate a +882% overhead on a crypto library – see Section

## 8.2). However, because we mostly want to protect programs

that are not constant time, we follow previous work [3, 18,

## 56, 57, 67, 93, 94, 107] and consider execution-time attacks

out of scope. These attacks are generally considered lower risk due to lower bandwidth, higher susceptibility to noise, and increased difficulty compared to other side channels. For example, NetSpectre [96] can only extract 15 bits per hour using methods applicable to Citadel compared to rates more than 1MB/s for LLC-based side channels [69]. Others We do not consider physical attacks (e.g., noise, electromagnetic field) or side channels that exploit the physical layer (e.g. power side channels). We do not consider Rowhammer attacks. We are concerned about the privacy of the enclave and do not consider denial-o f-service. As expressed by our contract, we also do not protect enclave programs that explicitly leak their own secrets, including through shared memory.

## 4.3 New Building Blocks for Contracts

Leakage Models We define shm, a new weak leakage model that only represents the trace of accesses to shared memory. Execution Models The weakest execution model is seq, which represents non-speculative, or sequential execution (one instruction at a time and i n-order). We also have the strongest execution model spec which models speculative execution with the following predictors: the pattern history table (PHT), the branch target buffer (BTB) and the return stack buffer (RSB). We also define stl that models straightline speculation [8] where branches are always speculated as non-taken (static branch predictor).

## 4.4 Relaxed Microarchitectural Isolation

(RMI)Given our threat model, we propose a new security property that allow programs to safely share memory.

For a given program, relaxed microarchitectural isolation is achieved if information leakage through the microarchitecture is equivalent to the trace of shared memory accesses when running the program non-speculatively (oneinstruction-a t-a-time and i n-order). That means, for a defense mechanism {| · |}, enforcing RMI is exactly equivalent to satisfying J · Kseq shm. Figure 3, represents how RMI relates to contracts referenced in previous work.

Our goal is to design microarchitecture that enforces RMI for a large class of programs. Our design strategy is two-fold.

## 1. Restricting Attacker Observations (HW): we use microar-

chitectural isolation to restrict the attacker observations to the trace of (speculative) accesses to shared memory.

## 2. Restricting Speculative Leakage (HW+SW): we use a

combination of mechanisms for controlled speculation and program analysis to ensure these observation traces do not leak more information than if the program was run non-speculatively.

## 5 Restricting Attacker Observations

To achieve RMI, we first restrict the attacker’s observations using microarchitectural isolation to satisfy shm. We describe our baseline microarchitecture, and how it enforces strong isolation between security domains with shared memory disabled. From there, we show how we have enabled shared memory while carefully constraining what an attacker can observe to (speculative) accesses to shared memory i.e. shm.

5{| · |}pro {| · |}t t {| · |}s af e/{| · |}sta burst{| · |}⊤ burst{| · |}mi6J · K seq ctJ · K spec archJ · K seq arch J · K spec ct J · K seq mem J · K seq shmJ · K spec shmJ · Kstl shm J · K⊥Figure 3: Security guarantees of secure-speculation mechanisms. Hardware semantics of Citadel’ defense modes, Safe ({| · |}s af e) and Burst ({| · |}sta burst), both satisfy RMI (J · K seq shm). We also represented other relevant hardware semantics such as {| · |}⊤ burst which represents the hardware mechanisms of Burst without the associated static code analysis (see Section

## 6.4), and some previous works such as {| · |}pro for ProSpeCT

[33] or {| · |}t t for taint-tracking sandboxing schemes such as STT [120].

## 5.1 Strong Microarchitectural Isolation

Memory Isolation Physical Memory Protection (PMP) [109] is the official RISC-V mechanism to partition physical memory and prevent unauthorized access between security domains (OS, enclaves, and SM). However, it relies on accessing a series of registers, making it difficult to identify memory regions outside of the cores. This makes it difficult to integrate features such as fine-grained LLC partitioning (see Section 7). To allow for easy determination of a memory region from a physical address, we revive a mechanism from the Sanctum paper [30]. At its core, the mechanism divides memory into fixed-size physical memory regions (i n our case 64 regions of 32MB) allocated by the SM to different security domains. Each core uses two 64-bit registers as memory bitmaps, storing access rights for private and shared memory of the running security domain. Citadel adopts this mechanism, enforcing checks on all memory accesses, including speculative and page-walk operations. Figure 4 illustrates this isolation, showing that only currently running security domains can access their corresponding DRAM regions.

Microarchitectural Isolation We base our design on MI6 [18], which enforces strong microarchitectural isolation through partitioning, flushing, and disabling speculation in the SM. First, all spatially shared microarchitecture is partitioned, including the LLC, the LLC pipeline, Miss Status Handling Registers (MSHR) and other resources as illustrated in Figure 4. In particular, the LLC is statically partitioned into 64 regions to match the 64 DRAM memory regions – we will improve this scheme in Section 7. We pad DRAM request timing to a fixed duration that matches the slowest request. This slightly increases latency, but masks side chan-Core  0L1 LLCDRAM L1MSHR MSHR Core  1SD 1SD 2SD 3Security Domains Figure 4: Resource Partitioning Between Security DomainsOS SM Encl SM OSSecurity DomainPrivilege Level U/S M MU/S U/SSpeculation yes NO NOyes yes: µarch-flush Figure 5: Context Switching Between Security DomainsEnclave App∈ Private Mem ?

VA N User Level App TrustedUntrustedYEnclave OS & UntrustedPT PT User Level Mem Controlled by the OSFigure 6: The Dual Page Table Mechanismnels from opened rows and contention in the DRAM controller. We also pad requests coinciding with memory refresh (periodic and independent of any secrets) to a fixed duration. We leverage interrupt logic to interpose the SM when context switching between security domains and enforce the flushing of temporally-shared microarchitecture such as all cores’ pipeline state, L1 caches, TLBs, Translation Caches and MSHRs (see Figure 5). The processor does not support hyper-threading and therefore is not vulnerable to related side channels such as port contention. The processor does not include a prefetcher or SIMD units so we are not susceptible to Spectre variants exploiting them. Finally, Citadel is not susceptible to Meltdown-style attacks, as the processor does not speculate across privilege levels (switching to a different privilege mode flushes the r e-order buffer, making sure it never contains two instructions from different privilege levels). The exhaustive list of side channels and defense mechanisms covered by MI6 can be found in [18]. Disabling Speculation in the SM The SM executes in machine mode (see Figure 5) which gives it access to all physical memory. Following MI6 [18], speculation in the SM is disabled to prevent TES attacks.

6

## 5.2 Enabling Shared Memory

Existing mechanisms like MMIO or non-cacheable memory [29, 95] are insufficient to prevent TES attacks. They prevent some speculative memory accesses, but rely on physical addresses or page table entry bits, requiring speculative accesses to page table entries that leak address information. Instead, we decide to adopt Sanctum’s dual-page-table mechanism (Figure 6) as it makes it possible to differentiate between private and shared memory based solely on virtual addresses. Two new registers define the enclave’s private virtual memory range. When setting up the enclave, the SM ensures that physical memory mapped as private is owned by the corresponding security domain. Memory access translation uses one of the two page tables: Enclave page table: For virtual addresses within the enclave memory range. The SM ensures that this table is stored in enclave private memory. Shared page table: For virtual addresses outside the private range (shared memory). This table is stored in shared memory. During address translation, additional bound checks ensure that all memory addresses that are accessed belong to the same security domain (enclave or shared memory) as the translated address. This mechanism can also be used to enable private shared memory between enclaves (not visible to the OS). The SM simply needs to ensure that the root page table and shared memory region( s) are not accessible to the OS. If shared memory with the OS is also required, some page tables can be located in the OS memory.

## 5.3 Disentangling Private and Shared State

We now need to carefully constrain what the attacker can observe on (speculative) accesses to shared memory. As a design principle, read-only state used by both shared and private memory needs to be tagged to prevent aliasing while core-private microarchitectural state entangled with adversary state through a coherence protocol need to be partitioned. We highlight examples relevant to our design. Tagged ATC and TLB for Correct Address Translations Both the Address Translation Cache (ATC) and Translation Lookaside Buffer (TLB) are susceptible to cross-domain aliasing. The ATC, which caches intermediate page walker results, relies on a few upper virtual address bits, while TLB aliasing can occur with large pages if the private virtual memory range is smaller than the page granularity. To prevent mistranslations, we tag ATC and TLB entries to indicate their association with private or shared memory. Speculative Transmitters in the L1-D Cache While shared memory cannot be accessed speculatively, private memory can, potentially leading to speculative eviction of shared memory. Unfortunately, the cache coherency protocol makes some private L1 microarchitectural state observable to an attacker, as writing to a memory location cached by another core takes longer than writing to an uncached location, effectively creating a side channel. This vulnerability enables Spectre-style attacks through coherency in the L1-D cache. In our case, partitioning the L1 would significantly impact overall system performance, including non-protected programs, due to the cache’s latency sensitivity. Instead, we opted to bypass the L1-D cache for enclave accesses to shared memory. Because LLC is only reconfigured when no enclaves are running and the L1-D is flushed on context switch, we avoid issues related to cache coherency. This decision is further justified by the limited temporal reuse of shared memory accesses and the observed impact on performance (see Section 8.1).

Security Analysis As we tagged read-only shared resources and the L1 is the only core-private state entangled with adversary state through a coherence protocol, we do not need to worry about other core-private structures. Consequently, the attacker is only able to observe state of the shared LLC. This effectively limits the attacker’s observations to the trace of accesses, and addresses of accesses, to shared memory i.e. shm.

## 6 Restricting Speculative Leakage

With attacker observations restricted to shm, we can now focus on enforcing the execution model. Observable traces when running a given program on our design should not leak more information than when running the same program nonspeculatively i.e. using seq. This can be achieved through a combination of mechanisms for controlled speculation and program analysis. We show two different approaches: preventing speculative shared-memory accesses altogether or ensuring that their addresses do not leak secrets. We illustrate these approaches by building two minimal hardware mechanisms to enforce RMI for our enclave programs. Safe mode achieves RMI without requiring any program analysis and Burst mode enables better performance on specific code snippets at the cost or requiring minimal code analysis.

## 6.1 Safe mode: Preventing Speculative Shared

MemoryOur first approach consists of preventing speculative shared memory accesses altogether, effectively removing any speculative transmitters that can reach the attacker. This approach enforces RMI for any program without extra program analysis, making it a great foundational mode to use by default. We illustrate this principle by building a simple mechanism. Safe mode identifies unsafe shared memory accesses early in the memory execution pipeline, delaying their translation and processing until they become non-speculative (i.e., reach the head of the reorder buffer (ROB)). This is similar in spirit to delay-o n-miss [94] but only delays shared memory accesses and cannot leverage7RS Trusted OR NonspeculativeROB + Reg Filedispatch TranslationTLBYN Send ReqMemory Hierarchy (LSQ, L1, ...)MemExePipelineShared μ-arch beyond that pointdequeueset r e-dispatchFigure 7: Changes to the Memory Execution Pipeline in Citadel to enable Safe mode. New elements are shown in blue.

PC FetchTLB DecodeFetchPipelineBTB L1-I RAS BHT+4 SPEC CSR Rename StageFigure 8: Changes to the Fetch Pipeline in Citadel to enable Burst mode. New elements are shown in blue.

the L1 cache for reasons expressed in section 5.3. A primer on out-o f-order processors can be found in Appendix C and microarchitectural details for Safe mode implementation can be found in Appendix D.1. Because the private memory range is defined in virtual memory, we can perform this check without any address translation, preventing information leakage through shared microarchitecture. Safe instructions proceed to the next MemExePipeline stage; unsafe ones are squashed and signaled to the reservation station so they are r e-dispatched once they become non-speculative.

Security Analysis An attacker is only able to observe the trace of non-speculative accesses to shared memory. As a result, under our threat model, {| · |}s af e ⊢ J · Kseq shm i.e. Safe mode satisfies RMI.

## 6.2 Burst mode: Eliminating Information

LeakageOur second approach, called Burst mode, is a hardwaresoftware c o-design that can improve performance for specific code snippets. It allows some speculative accesses to shared memory (i.e. {| · |}burst ⊢ J · Kstl shm) but ensures that it only runs programs that will not leak secrets (i.e. only runs pi fp ⊢ NI(J · K seq shm ⇒ J · Kstl shm)). This last step requires some static code analysis, a sometimes difficult problem (see Section 9). In order to simplify this analysis, we apply two simple design principles: 1) we ensure the (speculative) control flow of our code snippet is self-contained 2) we constrain speculation to a simple model where it is not attacker-controlled. The first principle indicates that we should deactivate any predictors that enable speculative jumps to arbitrary locations and guard our code snippets with speculative barriers. The second stems from the fact that disabling more predictors helps simplify program analysis. Following these principles, we implement a simple static branch predictor, which enables shared memory pipelining on Citadel (disabled in Safe mode). According to our first guidelines, we disable the branch target buffer (BTB), and the return address stack (RAS) (Figure 8). This is done on demand by writing to a new CSR, using a write instruction that also doubles as a speculation barrier. Following our second principle, we also disable the branch history table (BHT), effectively implementing straight-line speculation [8, 46] where the only prediction is the hardcoded “p c+4”, predicting the next instruction without a change in control flow.

## 6.3 Code Analysis for Burst mode

Not all programs satisfy RMI when run in Burst mode. Take the following pathological code:

jal far_away_function lw a 0 , 0( secret_address ) Here the secret addressmight be leaked under Burst mode while it would never be accessed during non-speculative execution. To use Burst mode safely, we must perform code analysis to ensure snippets are:

## 1) self-contained to bound the analysis and 2) leak no secrets

under straight-line speculation. Self-containment is verified by checking that control flow remains confined between the instructions turning Burst mode on and off, i.e. no indirect branch and all branch destinations are valid and within the code snippet. This constraint simplifies our analysis by limiting its scope to the code snippet. We then verify that the code does not leak secrets under straight-line speculation. Load, store, and branch instructions are considered potential speculative transmitters and the accessed register are marked as leaked. For each transmitter, we perform a backward pass to determine dependencies of the leaked value and marking them as leaked. This pass explores all possible earlier execution paths, including speculative and non-speculative paths when control flow deviates from p c+4. Our simple speculation model prevents an explosion in possibilities, making this analysis tractable. If a leaked value depends on another memory value, verification conservatively fails to prevent Spectre-like gadgets. On each path, dependencies are declassified as public if their values are leaked through a non-speculative load or store (w e conservatively assume no declassification through branches). We also prune paths that have been already explored if the set of leaked registers has not changed, and execution is not speculative, as we are not at risk of missing new leakage. The backward pass yields a set8of registers whose initial values could potentially be leaked, along with the corresponding speculative execution paths. We can then identify conditions under which these paths are incorrect (i.e., not followed in non-speculative execution). A code snippet fails verification if any non-public value can be leaked. We developed a Python tool to automate this analysis.

## 1 csrwi MSPEC , BURST_ON

## 2 add a 2 ,a 0 , a 2

## 3 bgeu a 0 ,a 2 , .end # len!=0

## 4 .loop :

## 5 lbu a 4 ,0( a 1 ) # leaks src

## 6 add a 1 ,a 1 ,1

## 7 add a 0 ,a 0 ,1

## 8 sb a 4 , -1( a 0 ) # leaks dest

## 9 bne a 1 ,a 2 , .loop #leaks len

## 10 .end :

## 11 csrwi MSPEC , BURST_OFF

## 1 add a 2 ,a 0 , a 2

## 2 bgeu a 0 ,a 2 , .end # len!=0

## 3 csrwi MSPEC , BURST_ON

## 4 .loop :

## 5 lbu a 4 ,0( a 1 )

## 6 add a 1 ,a 1 ,1

## 7 add a 0 ,a 0 ,1

## 8 sb a 4 , -1( a 0 )

## 9 bne a 1 ,a 2 , .loop

## 10 csrwi MSPEC , BURST_OFF

## 11 .end :

Figure 9: RISC-V Assembly code for memcpy( a 0=dest,a 1 =src,a 2=len). Left hand-side does not satisfy RMI under Burst mode while the right-hand side does.

memcpy example The default assembly can be seen on the left-hand side of Figure 9. Here our tool identifies 3 potential transmitters line 5, 8 and 9. Let’s perform the backward pass for the branch on line 9 initially marking registers a 1 and a 2 as leaked. We roll-back execution through line 8 t o

## 6. Line 6 overwrites a 1 which is declassified but replaced

b y its dependencies i.e. a 1. On line 5, a transmitter accesses a 1 but non-speculatively so i ti s not declassified. At line 5, we encounter two possible paths: one from line 9 (which we prune as i ti s already explored), and another speculative path from line 3. The analysis reveals a potential straight-line execution path from line 1 to 9 where the initial values of a 1 and a 2 (i.e., src and len) could be leaked. This vulnerability occurs as Burst mode incorrectly speculates past the branch on line 3, which happens when len==0. Our tool also reveals other leaks for dest and src under the same conditions. We add a guard before entering Burst mode to check len!=0 which generates safe assembly (right hand side). The tool also detected self-containment issues with over-optimized compiler output (loop unrolling and rogue code block placements) where Burst mode would have been insecure. More Complex Analysis Tools The conditions we check on our code snippets are sufficient but conservative. To support more complex code patterns or speculation modes, more sophisticated tools like Kasper [54], KleeSpectre [106], and Spectector [45] could potentially be adapted. These tools usually do not scale well to large code bases and assume simplified speculation models. These two limitations are circumvented by the design principles we presented.

## 6.4 Burst Mode Security Analysis

The attacker observations are limited to shm. Burst mode only allows for straight-line speculation, and control flow is selfcontained. That means that all reachable speculative paths are described by stl. Under our threat model, {|·|}burst ⊢ J·Kstl shm.

Extending Hardware Semantic With Static Software Analysis We extend hardware semantics to capture a staticsoftware-analysis step. Let’s consider a static analysis tool tool that takes any program pa s an input and returns true if the program passes the static analysis and false otherwise. Given a static analysis program tool, and a hardware semantic {| · |}, for all program p, we define{|p|} tool = { {|p|} if tool( p) = true ∅ otherwiseWhere ∅ represents the hardware semantic that only returns empty traces. This can be easily implemented by adding a condition in the SM that verifies the (precomputed) result of tool( p) before starting the enclave. An interesting special static analysis program is ⊤ which returns true for any program.

Qualifying Our Static Analysis We call the static analysis used for Burst mode sta. Our tool assumes the shm leakage model and only accepts programs that will not leak more secrets under straight-line speculation stl than under sequential execution seq. That i s, for a program p, sta returns true if p ⊢ NI(J · K seq shm ⇒ J · Kstl shm), and false otherwise.

This gives us {|p|}sta burst ⊢ J · Kseq shm (see proof in appendix B). In summary, Burst mode satisfies RMI.

Secure Composability Because our code snippets (speculative) control flows are self-contained, they can be safely reused and composed with code using other execution modes. Developers can leverage pre-analyzed performance libraries (e.g., memcpy) without additional instrumentation or analysis. In our design, we show that Burst mode on key code snippets significantly improves overall performance (see Section 8.1).

## 7 Building and End-t o-end Platform

Integrating a Reconfigurable LLC Partitioning Scheme We build a fine-grain set-partitioning scheme similar to [92, 100] to support our 64 memory partitions. Thanks to some of Citadel design choices, we are able to circumvent challenges in end-t o-end integration ignored in previous work. For instance, our memory region IDs are directly accessible through physical memory address (Section 5.1) which makes it possible to support shared memory between cores without extending every structure or buses in the memory hierarchy to support security domain ID. Additionally, we can leverage hardware software c o-desing to ensure the LLC will not be put in an incoherent state during reconfiguration. A request for reconfiguration always goes through the SM which will check that the mapping is correct and fits within the LLC.

9Frontend 2-way superscalar, 256 entries BTB, 8 entries RAS, tournament predictor ROB 64 entries, 2-way insert/commit Reservation Stations 2 stations for ALU (16 entries), 1 for FPU (16 entry), 1 for memory (16 entries) L1 (I/D) 32KB, 8 ways, 8 outstanding requests Ld-St Unit 24 LdQ entries, 14 StQ entries, 4 SB entriesLLC (L2) 1MB, 10 cycles latency, 16 ways, max 16 outstanding req. Memory 120 cycles latency (24 outstanding reqs)Table 1: Citadel’s microarchitectural configuration.

The SM will check that no enclaves are running and preempt other cores to ensure no requests will be sent to the affected memory regions during the operation. Implementation details can be found in Appendix D.2. To our knowledge, we are the first to implement such a scheme in RTL and to integrate it i na system.

Fine-grained LLC Flushing We also implement a hardwaresoftware fine-grain flushing mechanism. We add a simple piece of logic connected to the cache hierarchy at the same level than the DRAM, which always sends back zeroes. It is mapped to a physical address space the size of the DRAM making it possible to easily build and access eviction sets in software. This means that flushing a small LLC partition is much faster than flushing a big one. Implementation details can be found in Appendix D.3.

Building the Software Infrastructure Our software architecture, illustrated early in the paper in Figure 1, comprises several key components. We implement the SM at RISC-V’s highest privilege level using assembler and C, alongside a Mini-SM - a downsized, enclave-private copy of the global SM. A Linux Kernel module enables user programs to request SM calls and set up enclaves, with Linux managing resources. Additionally, we develop a Secure Bootloader and an end-t o-end attestation mechanism, enabling unique enclave identification, shared secret establishment, and encrypted private data exchange. Implementation details regarding our entire software infrastructure can be found in Appendix E.

## 8 Evaluation

Experimental Setup Citadel’s processor is a modified out-o f-order, superscalar, 2-core based on Riscy-OOO [121] and MI6 [18]. The parameters used for the cores and the memory subsystem are given in Figure 1, and kept small to keep the synthesis and simulation time small. Citadel runs on an AWS EC2 F1 instance, equipped with a Virtex UltraScale+ FPGA. On this FPGA board, Citadel can be clocked at 30 MHz, which is similar to the baseline design. Component LOC Size Processor [18] (+mod) ∼ 60 KLOC (+ 350) N/ABootloader 5236 55KB Security Monitor 9287 97KB Mini-SM 2301 5.6KB Linux ∼ 20M 157MB SM Kernel Mod. 507 505KB TCB Software 14523 152KBTable 2: Software Component Size and TCB Breakdown. Mini-SM is a subset of the SM code. Lines in red correspond to elements excluded from the TCB. Modules LUTs FFsTop 410K (+3.0% | +1.8%) 251K (+4.4% | +2.6%) Core 169K (+1.6% | +0.3%) 91K (+3.4% | +1.0%)Table 3: Hardware overhead for the top module and the core, lookup tables (LUTs) and flip flops (FFs). First comparison is to Riscy-OOO while second is to MI6 with the parameters of Table 1.

We use the RISC-V tool chain with GCC 12.2.0. We compile all software with the -O3 flag. We run Linux Kernel 6.2.0. All numbers are collected by running the benchmarks on the FPGA using performance counters on an average of ten runs.

Implementation Data, TCB and Surface Overhead Number of lines of code (LOC) and binary size of Citadel’s components are presented in Table 2. Due to their limited functions, the SM and the Bootloader can be kept small and the total software Trusted Code Base (TCB) is less than 15K LOC. This helps minimize potential bugs and reduce the software attack surface. It can also help make future formal verification efforts tractable. The final TCB size needs to include the enclave’s binary, which depends on the application. Table

## 3 shows the area overhead for Citadel compared to Riscy-

OOO [121] and MI6 [18]. Most of the overhead comes from enforcing microarchitectural isolation (i.e. MI6) or from the modifications in the LLC with, compared to Mi6, the addition of an arbiter, a fine-grained partitioning mechanism and the L1 bypass mechanism. The overhead for the core compared to MI6 is minimal (+0.3% LUTs and +1.0% FFs), which gives us an upper bound for Safe mode and Burst mode. This is significantly lower than other mechanisms for secure speculation (see Section 9).

## 8.1 Microbenchmarks

We evaluate two pathological microbenchmarks with distinct but shared memory access patterns: Memcpy (sequential access, copying 128KB from shared to enclave private memory) and Random (10,240 random accesses within a 128KB r e-10Memcpy Random Baseline 343928 273164 Safe 595362 (+73%) 1447543 (+430%) Safe +Burst 343291 (+0%) 270394 (-1%) Safe +Burst +L1 344163 (+0%) 277969 (+2%)Table 4: Microbenchmarks for memcpy and random accesses to shared memory. memcpy copies 128MB from shared memory to private memory. Baseline is memcpy from an to private memory with speculation enabled. Random accesses 10240 elements in a 128MB memory region. We experiment with insecurely enabling the L1 for shared memory accesses. ECC ML ML EXT

## 98599278 406765555 406765555

102433204 (+4%) 419853901 (+3.2%) 1119486865 (+175%) 100411982 (+1.8%) 421332976 (+3.5%) 426527197 (+4.8%)BaselineSafe OnlyCitadel (Safe +Burst)Table 5: Performance overheads for applications that access shared memory. Our elliptic curve cryptography (ECC) benchmark signs a total of 1MB of data split in 3000 packets. Our ML benchmark evaluate private inference over 1024 encrypted requests. ML EXT is the same but the public model weights are in shared memory. Requests are sent by an untrusted app using message passing through shared memory. Insecure Baseline is the same application directly linked into the untrusted app.

gion). Results can be found in Table 4. We compare these with a baseline of private memory accesses. For all tests, we disable LLC partitioning and use 4KB page mapping. Safe mode alone significantly increases overhead (+73% for Memcpy, +430% for Random) due to disabling the pipelining of shared memory accesses. Activating Burst mode for both access types (after verifying security with our code analysis tool) dramatically reduces this overhead, approaching baseline performance. Note that verification is a one-time task and that Burst-enable memcopy can now be used by other code without further program analysis. We also experiment with (insecurely) disabling the L1 bypass for shared memory accesses, which, for these benchmarks, has negligible performance impact. Indeed, for memcpy, adjacent pipelined loads will always be resolved on the next cycle (i n the L1 or the LLC) and similarly than for Random, data is not r e-accessed. For Random, these results show that polluting the L1-D with random memory accesses slightly degrades performance.

## 8.2 Evaluating the End-t o-End Platform

We evaluate the platform usability by porting existing applications, showing how Burst mode can be easily leveraged to gain performance at the cost of minimal code annotation and analysis. Our shared memory mechanisms only incur performance overheads when the enclave program accesses shared memory, making evaluation mostly relevant for programs with private and shared memory (e.i. not SPEC). Note that for non-enclave programs, the only overhead is due to the LLC arbiter and is minimal on our two-cores prototype. We measure ≈0.1% overhead compared to Riscy-OOO [121] on our different benchmarks when run as insecure baselines.

Securing a Crypto Library (ECC) We write a wrapper around an ED25519 RISC-V library [82]. We add a queue to shared memory, so untrusted applications can send requests to the library to generate keys (that will stay in enclave memory), or to sign messages using previously generated keys. In total, we need to implement 334 LOC of C, which is t ob e compared to the 4,514 LOC of the crypto library (7% overhead). With the enclave’s code added, the total TCB is now 19,231 LOC. The final crypto-enclave binary is 71KB. As shown in Table 5, we see minimal overhead mainly due to message passing and copying inputs inside the enclave. We instrument the SHA256 macro that performs the input copy to leverage Burst mode. We successfully verify that the code snippet is secure using our analysis tool we reduce the overhead to 1.8%. For completeness, and because the ECC benchmark is implemented using constant-time programming [4, 89], we also evaluate the performance overhead of disabling speculation completely in order to defend against "execution time" attacks (see Section 4.2). We observe a +882% overhead, orders of magnitude above our other mechanisms, which clearly highlights the trade-off Citadel offers between security and performance.

Private Inference (ML and ML EXT) We convert a handwritten digit recognition model (trained on MNIST) to standard C code [61] and run private inference inside our enclave. A user uses our remote attestation mechanism to verify the enclave identity and establish a secure communication channel. When receiving requests through shared memory, the enclave decrypts the ciphertext, performs the inference task on the private input and sends back an encrypted output. We also experiment with placing the model weights in shared memory (ML EXT). This scenario is especially relevant as some models might be too big to fit in DRAM and require to leverage demand paging. Note that this type of access patterns would be hard to reproduce using message-passing primitives (e.g. DMA accesses). In this scenario, the integrity of the model weights is not protected. In total, we need to implement 227 lines of straightforward C, which is t ob e compared to the 1536 LOC of the neural network, the 410 LOC of the AES library and the 4386 LOC of ED25519 we also include for encryption and key exchange. The TCB is now 21K LOC and the final enclave binary measures

## 54KB. Setting up the enclave, represents a (one-time) cost

similar to performing 235 inferences. For a given request, runtime is split 55% and 45% between AES and inference.



Table 5 show that overheads are reasonable but can get up to +175% when placing the model in shared memory. We use our Burst-instrumented memcpy function but see no performance improvement as only small messages are copies. Nevertheless, on ML EXT, we instrument the inference code to leverage Burst (+2 LOC). Our code analysis tool revealed a Spectre-like gadget as the pointer to the tensor is first dereferenced before the tensor values are accessed. We made sure to deference the first pointer before turning on Burst mode (+1 LOC), enough to pass program analysis. We observe performance overhead drops down to 4.8%. These results highlight the versatility of shared memory and the tradeoff between performance and requiring program analysis. Finally, insecurely disabling L1-bypass for shared memory on ML EXT only show modest performance gains (+4.3% down from 4.8% ).

MicroPython Runtime We port MicroPython [73] inside an enclave which serves as a small benchmark to demonstrate the expressivity and flexibility of the platform. We redirect the console to shared memory and a hash of the standard output is extended on each character print. The hash of the console transcript is signed on the enclave exit using ECC and the enclave’s own private keys (obtained through the local attestation mechanism). In total, we modify 128 LOC of MicroPython. With the enclave’s code added, the TCB is now 65K LOC, most of it (70%) being MicroPython. We successfully run our attested runtime on a simple primality test written in Python.

## 8.3 Evaluating LLC Dynamic Partitioning

We evaluate dynamically partitioning the LLC on our cryptographic enclave benchmark. We compare 1) an insecure baseline where the LLC is not partitioned, 2) a secure configuration where the LLC is uniformly statically partitioned (MI6 scheme) and 3) a non-uniform partitioning set up dynamically using our scheme. For the non-uniform configuration, we split the 1MB of LLC as follows: we give 256KB to the enclave,

## 16KB to the SM, 128KB to the OS, 128KB to the region used

for shared memory, 128KB to the region storing page tables, and 1KB each to every other region. We observe a 67.8% overhead for the uniform partitioning and 0.08% overhead for the non-uniform partitioning. This is especially important as untrusted applications also benefit from i t. Modifying LLC partitioning (infrequent) takes on average 500K cycles. Among these, 98% of the cycles are spent flushing the LLC. Resizing fewer regions is faster: we measure an average of 93 cycles to flush a single LLC set containing 16 ways.

## 9 Related Work

Security of Enclave Platforms Table 6 illustrates the landscape of existing enclave platforms. All commercial platforms [5, 27, 29, 68, 72, 86, 97] have proven vulnerable to TES attacks [20, 26, 42, 90, 101–103, 112, 115]. Despite this, most commercial platforms and academic works on TEEs [10, 19, 34, 38, 39, 64, 66, 84, 99, 104, 104, 110] do not include these attacks in their threat models, shifting the burden to developers and deferring defense to software analysis tools (see lower). Although some academic proposals such as Sanctum [30], KeyStone [65], and Cure [11] incorporate some defenses against cache side channels, only MI6 [18] formally addresses TES attacks but disables shared memory, failing to address P comprehensively. Citadel builds on the open source code provided in MI6 [18] and reuses many of its microarchitectural isolation mechanisms. The MI6 paper focused on evaluating the performance of these mechanisms on an FPGA by running SPEC benchmarks with no security guarantees by using Linux system calls as hooks to project the cost of a potential context switch to the SM. Citadel’s performance numbers for SPEC would be similar to MI6’s evaluation. Citadel stands out as the only platform that offers protection against TES attacks while maintaining shared memory usability and providing a complete implementation with hardware, software infrastructure, and applications.

Software Analysis Tools Commercial TEEs provide speculation barriers and other flushing instructions for manual placement in software [6, 9, 51]. However, these countermeasures [24, 36, 44, 75] incur significant overhead, might not be sufficient [13], and their reliable automated application remains an open challenge [22, 49, 83, 107]. Other tools aim to target more precise speculative security policies [24, 46], but mostly target constant-time crypto [15, 23, 32, 44, 45, 85, 105] or the sandboxing scenario [25, 53, 58, 77, 80, 88, 98] which makes them difficult to adapt to address P (see Section 3.3). It is also unclear how pieces of code analyzed with these tools and satisfying stronger speculative properties than RMI should be composed, or how they should communicate with each other. In fact, introducing any universal read gadget in the code base would break security, even for the carefully analyzed speculative constant-time [23] cryptographic library. Citadel presents one strategy to compose different speculative policies. It can even compose programs that guarantee the “pre-Spectre” noninterference properties [14], without worrying about speculation, as we can guarantee that predictors are independent of any secrets through isolation. Finally, analysis tools struggle to scale to entire codebases, especially when trying to prove complex properties, further complicating this composition problem [45, 54, 106, 107]. Citadel addresses these limitations by isolating execution modes, enabling secure shared memory, and limiting software analysis to small code snippets. Other tools like Revizor [41, 79] make it possible to fuzz CPUs for speculative leaks. To our knowledge, current available implementations only support X86. Adapting Revizor to RISC-V and RMI is left for future work.

12Enclave Platforms Security Usability ImplementationSCLLCSCOthersTESExec-TimeSharedMemoryHWSW.Infra.Apps Commercial [5, 27,

## 29, 68, 72, 86, 97] V V V V Yes TO Yes Yes

Academic [10, 19,

## 34, 38, 39, 104, 110] V V V V Yes R/S Some Some

Sanctum [30] P V V V Yes Sim No No KeyStone [65], CURE [11], Hybrid [35] P V V V Yes RTL Yes YesMI6 [18] P P P V No RTL* No No Citadel P P P V Yes RTL Yes YesTable 6: Comparison with Other Enclave Platforms. SC: Side Channel, TES: Transient Execution SC, Exec-Time: Execution-Time SC, P: Protected, V: Vulnerable, TO: Tapedout, Sim: Simulator, R/S: RTL or Sim, RTL*: Incomplete Defense Mechanism Security Usability OverheadTESCacheTESOthersRegisterValuesTESExec-TimeAnnotationSecretsCodeAnalysisHardwarePerformance ProSpeCT [33] P P P P Yes CT High 0-45% SPT [28] P P P P No CT Sim 45% STT [52, 120] P P V P No No High 46% SpecShield [12] P P V P No No Sim 21-73% NDA [111] P P S P No No Sim 100% SpectreGuard [40] P P P P Yes No Sim 8-20% ConTExT [95] P P P V Yes No Sim 0-338% InvisiSpec [116] + [3, 56, 67, 93, 94] P V P V No No Sim 21-72%DOLMA [70] P P P P No No Sim 42.2% Sequential P P P P No No Negl 882% Citadel P P P V No Min Small 0% - 5%Table 7: Comparison with Hardware Defense Mechanisms for Transient Execution Side Channels (TES), P: Protected, V: Vulnerable, S: Some, CT: Constant Time, Sim: Simulator

## 9.1 Hardware Mitigations for TES attacks

Numerous academic proposals [2, 3, 12, 21, 25, 28, 33, 40, 45,

## 46, 56, 57, 67, 74, 78, 93, 94, 111, 116, 120] leverage hardware

mechanisms to counter TES attacks. Why not use some of these mechanisms as primitive and combine them with, say, MI6 [18] to address P ? As shown in Table 7, each mechanism offers a different trade-off between security, usability, and performance. Within that design space, Citadel and its simple mechanisms can efficiently address P . As explained in Section 3.3, mechanisms that focus on the constant-time [28, 33] and sandboxing [12, 52, 119, 120] scenarios are not the best building blocks to address P efficiently. Similarly, NDA [111] ignores Specter-BTB and does not prevent leakage of register secrets through single transient micro-o p. Other Hardware Mechanisms such as Context [95], OISA [118] and SpecterGuard [40] require extensive manual and error-prone secret annotations, on which security depends. In contrast, Citadel’ code annotation is only required for performance and any manual error would be caught by our static analysis tool. Many other mechanisms could be a good fit to be used as primitives to build a platform such as Citadel. Invisible speculation schemes such as InvisiSpec [116] and others [2, 3, 56, 57, 67, 93, 94] only address cache side channels. Similarly, DOLMA [70] could be used to address P and even provide guarantees against the execution time SC (see Section 4.2), if augmented with micro-architectural isolation similar to MI6.

Hardware and Performance Overhead However, even when considered as primitives, existing hardware mechanisms are complex and incur significant overheads. Few of these mechanisms have been implemented in hardware (FPGAs or silicon), and many attacks that break these defenses [117] exploit details that are often overlooked in simulation, such as faithful memory hierarchy representation. The two mechanisms that have been implemented incur significant hardware overhead. STT on BOOM [52] adds +15.7% LUTs and 6.2% FFs, while ProSpeCT [33] adds +17% LUTs and +6% FFs, an overhead potentially prohibitive for commercial deployment, especially given that they would require extra isolation mechanisms to address the TEE threat model (i.e., privilege attacker). In that sense, these overheads should be compared with the minimal surface overhead of implementing Safe mode and Burst mode on top of MI6: +0.3% LUTs and +1.0% FFs. These complex mechanisms also incur significant performance overhead. DOLMA presents an overhead of +42.2% on average, while NDA + 100% and STT + 46% for their most conservative threat models (but closest to our). In contrast, Citadel shows a modest 0-5% overhead on our benchmarks.

## 10 Conclusion

We define relaxed microarchitectural isolation (RMI), a new security property allowing programs to share memory while restricting information leakage to that of non-speculative execution. To enforce this type of secure speculation, we propose that processors use microarchitectural isolation to restrict the attacker’s observations, and a combination of simple mechanisms for controlled speculation and program analysis. We demonstrate our approach by building an end-t o-end FPGAbased prototype running enclave programs with low performance overheads on a multicore out-o f-order processor. Our final platform, Citadel, is a novel design point at the intersection of TEEs and TES defense mechanisms, and a compelling trade-off between performance, usability, and security.

13

## References

[1] Onur Acıiçmez, Çetin Kaya Koç, and Jean-Pierre Seifert. Predicting secret keys via branch prediction. In Topics in Cryptology–CT-RSA 2007: The Cryptographers’ Track at the RSA Conference 2007, San Francisco, CA, USA, February 5-9, 2007. Proceedings, pages 225–242. Springer, 2006.

[2] Sam Ainsworth. Ghostminion: A strictness-ordered cache system for spectre mitigation. In MICRO-54:

## 54th Annual IEEE/ACM International Symposium o n

Microarchitecture, pages 592–606, 2021.

[3] Sam Ainsworth and Timothy M Jones. Muontrap: Preventing cross-domain spectre-like attacks by capturing speculative state. In 2020 ACM/IEEE 47th Annual International Symposium on Computer Architecture (ISCA), pages 132–144. IEEE, 2020.

[4] José Bacelar Almeida, Manuel Barbosa, Gilles Barthe, François Dupressoir, and Michael Emmi. Verifying {Constant-Time} implementations. In 25th USENIX Security Symposium (USENIX Security 16), pages 53–

## 70, 2016.

[5] Tiago Alves and Don Felton. Trustzone: Integrated hardware and software security. ARM white paper, July 2004.

[6] AMD. Software techniques for managing speculation on amd processors. https: //www.amd.com/system/files/documents/ software-techniques-for-managing-speculation. pdf, 2023.

[7] Apple. Private cloud compute: A new frontier for ai privacy in the cloud. https://security.apple. com/blog/private-cloud-compute/, 2024.

[8] ARM. Whitepaper: Straight-line speculation. https://developer.arm.com/documentation/

## 102825/0100, 2020.

[9] ARM. Speculative processor vulnerability frequently asked questions. https://developer.arm.com/ documentation/102587/0103/?lang=e n, 2024.

[10] Ahmed M Azab, Peng Ning, and Xiaolan Zhang. Sice: a hardware-level strongly isolated computing environment for x86 multi-core platforms. In Proceedings of the 18th ACM conference on Computer and communications security, pages 375–388, 2011.

[11] Raad Bahmani, Ferdinand Brasser, Ghada Dessouky, Patrick Jauernig, Matthias Klimmek, Ahmad-Reza Sadeghi, and Emmanuel Stapf. Cure: A security architecture with customizable and resilient enclaves. In USENIX Security Symposium, pages 1073–1090, 2021. [12] Kristin Barber, Anys Bacha, Li Zhou, Yinqian Zhang, and Radu Teodorescu. Specshield: Shielding speculative data from microarchitectural covert channels. In

## 2019 28th International Conference on Parallel Archi-

tectures and Compilation Techniques (PACT), pages

## 151–164. IEEE, 2019.

[13] Enrico Barberis, Pietro Frigo, Marius Muench, Herbert Bos, and Cristiano Giuffrida. Branch history injection: On the effectiveness of hardware mitigations against {Cross-Privilege} spectre-v 2 attacks. In 31st USENIX Security Symposium (USENIX Security 22), pages 971–

## 988, 2022.

[14] Gilles Barthe, Gustavo Betarte, Juan Campo, Carlos Luna, and David Pichardie. System-level noninterference for constant-time cryptography. In Proceedings of the 2014 ACM SIGSAC Conference on Computer and Communications Security, pages 1267–

## 1279, 2014.

[15] Gilles Barthe, Sunjay Cauligi, Benjamin Grégoire, Adrien Koutsos, Kevin Liao, Tiago Oliveira, Swarn Priya, Tamara Rezk, and Peter Schwabe. Highassurance cryptography in the spectre era. In 2021 IEEE Symposium on Security and Privacy (SP), pages

## 1884–1901. IEEE, 2021.

[16] Jonathan Behrens, Anton Cao, Cel Skeggs, Adam Belay, M Frans Kaashoek, and Nickolai Zeldovich. Efficiently mitigating transient execution attacks using the unmapped speculation contract. In 14th USENIX Symposium on Operating Systems Design and Implementation (OSDI 20), pages 1139–1154, 2020.

[17] Daniel J Bernstein, Niels Duif, Tanja Lange, Peter Schwabe, and Bo-Yin Yang. High-speed high-security signatures. Journal of cryptographic engineering,

## 2(2):77–89, 2012.

[18] Thomas Bourgeat, Ilia Lebedev, Andrew Wright, Sizhuo Zhang, and Srinivas Devadas. Mi6: Secure enclaves in a speculative out-o f-order processor. In Proceedings of the 52nd Annual IEEE/ACM International Symposium on Microarchitecture, pages 42–56, 2019.

[19] Ferdinand Brasser, David Gens, Patrick Jauernig, Ahmad-Reza Sadeghi, and Emmanuel Stapf. Sanctuary: Arming trustzone with user-space enclaves. In NDSS, 2019.

[20] Ferdinand Brasser, Urs Müller, Alexandra Dmitrienko, Kari Kostiainen, Srdjan Capkun, and Ahmad-Reza Sadeghi. Software grand exposure:{SGX} cache attacks are practical. In 11th USENIX workshop on offensive technologies (WOOT 17), 2017.

14[21] Claudio Canella, Jo Van Bulck, Michael Schwarz, Moritz Lipp, Benjamin Von Berg, Philipp Ortner, Frank Piessens, Dmitry Evtyushkin, and Daniel Gruss. A systematic evaluation of transient execution attacks and defenses. In USENIX Security Symposium, pages 249–

## 266, 2019.

[22] Chandler Carruth. Rfc: Speculative load hardening (a spectre variant #1 mitigation). https://lists.llvm.org/pipermail/llvm-dev/

## 2018-March/122085.html, 2018.

[23] Sunjay Cauligi, Craig Disselkoen, Klaus v Gleissenthall, Dean Tullsen, Deian Stefan, Tamara Rezk, and Gilles Barthe. Constant-time foundations for the new spectre era. In Proceedings of the 41st ACM SIGPLAN Conference on Programming Language Design and Implementation, pages 913–926, 2020.

[24] Sunjay Cauligi, Craig Disselkoen, Daniel Moghimi, Gilles Barthe, and Deian Stefan. Sok: Practical foundations for software spectre defenses. In 2022 IEEE Symposium on Security and Privacy (SP), pages 666–

## 680. IEEE, 2022.

[25] Kevin Cheang, Cameron Rasmussen, Sanjit Seshia, and Pramod Subramanyan. A formal approach to secure speculation. In 2019 IEEE 32nd Computer Security Foundations Symposium (CSF), pages 288–28815. IEEE, 2019.

[26] Guoxing Chen, Sanchuan Chen, Yuan Xiao, Yinqian Zhang, Zhiqiang Lin, and Ten H Lai. Sgxpectre: Stealing intel secrets from sgx enclaves via speculative execution. In 2019 IEEE European Symposium on Security and Privacy (EuroS&P), pages 142–157. IEEE, 2019.

[27] Pau-Chen Cheng, Wojciech Ozga, Enriquillo Valdez, Salman Ahmed, Zhongshu Gu, Hani Jamjoom, Hubertus Franke, and James Bottomley. Intel tdx demystified: A top-down approach. ACM Computing Surveys,

## 56(9):1–33, 2024.

[28] Rutvik Choudhary, Jiyong Yu, Christopher Fletcher, and Adam Morrison. Speculative privacy tracking (spt): Leaking information from speculative execution without compromising privacy. In MICRO-54: 54th Annual IEEE/ACM International Symposium on Microarchitecture, pages 607–622, 2021.

[29] Victor Costan and Srinivas Devadas. Intel sgx explained. Cryptology ePrint Archive, 2016.

[30] Victor Costan, Ilia Lebedev, and Srinivas Devadas. Sanctum: Minimal hardware extensions for strong software isolation. In 25th USENIX Security Symposium (USENIX Security 16), pages 857–874, 2016. [31] Palmer Dabbelt. All aboard, part 6: Booting a riscv linux kernel. URl: https://www.sifive.com/blog/allaboard-part-6-booting-a-risc-v-linux-kernel, 2017.

[32] Lesly-Ann Daniel, Sébastien Bardin, and Tamara Rezk. Hunting the haunter-efficient relational symbolic execution for spectre with haunted relse. In NDSS 2021Network and Distributed Systems Security, 2021.

[33] Lesly-Ann Daniel, Marton Bognar, Job Noorman, Sébastien Bardin, Tamara Rezk, and Frank Piessens. {ProSpeCT}: Provably secure speculation for the {Constant-Time} policy. In 32nd USENIX Security Symposium (USENIX Security 23), pages 7161–7178, 2023.

[34] Liang Deng, Qingkai Zeng, Weiguang Wang, and Yao Liu. Equalvisor: Providing memory protection in an untrusted commodity hypervisor. In 2014 IEEE 13th International Conference on Trust, Security and Privacy in Computing and Communications, pages 300–

## 309. IEEE, 2014.

[35] Ghada Dessouky, Tommaso Frassetto, and AhmadReza Sadeghi. Hybcache: Hybrid side-channelresilient caches for trusted execution environments. In Proceedings of the 29th USENIX Conference on Security Symposium, SEC’20, USA, 2020. USENIX Association.

[36] Craig Disselkoen, Sunjay Cauligi, Dean Tullsen, and Deian Stefan. Finding and eliminating timing sidechannels in crypto code with pitchfork. In TECHCON, 2020.

[37] Dmitry Evtyushkin, Ryan Riley, Nael CSE AbuGhazaleh, ECE, and Dmitry Ponomarev. Branchscope: A new side-channel attack on directional branch predictor. ACM SIGPLAN Notices, 53(2):693–707, 2018.

[38] Erhu Feng, Xu Lu, Dong Du, Bicheng Yang, Xueqiang Jiang, Yubin Xia, Binyu Zang, and Haibo Chen. Scalable memory protection in the {PENGLAI} enclave. In 15th {USENIX} Symposium on Operating Systems Design and Implementation ({OSDI} 21), pages 275–

## 294, 2021.

[39] Andrew Ferraiuolo, Andrew Baumann, Chris Hawblitzel, and Bryan Parno. Komodo: Using verification to disentangle secure-enclave hardware from software. In Proceedings of the 26th Symposium on Operating Systems Principles, pages 287–305, 2017.

[40] Jacob Fustos, Farzad Farshchi, and Heechul Yun. Spectreguard: An efficient data-centric defense mechanism against spectre attacks. In Proceedings of the 56th Annual Design Automation Conference 2019, pages 1–6, 2019.

15[41] Eric García Arribas. Fuzzing risc-v processors for speculative leaks. 2023.

[42] Johannes Götzfried, Moritz Eckert, Sebastian Schinzel, and Tilo Müller. Cache attacks on intel sgx. In Proceedings of the 10th European Workshop on Systems Security, pages 1–6, 2017.

[43] Ben Gras, Kaveh Razavi, Herbert Bos, Cristiano Giuffrida, et a l. Translation leak-aside buffer: Defeating cache side-channel protections with tlb attacks. In USENIX Security Symposium, volume 216, 2018.

[44] Roberto Guanciale, Musard Balliu, and Mads Dam. Inspectre: Breaking and fixing microarchitectural vulnerabilities by formal analysis. In Proceedings of the

## 2020 ACM SIGSAC Conference on Computer and Com-

munications Security, pages 1853–1869, 2020.

[45] Marco Guarnieri, Boris Köpf, José F Morales, Jan Reineke, and Andrés Sánchez. Spectector: Principled detection of speculative information flows. In 2020 IEEE Symposium on Security and Privacy (SP), pages

## 1–19. IEEE, 2020.

[46] Marco Guarnieri, Boris Köpf, Jan Reineke, and Pepe Vila. Hardware-software contracts for secure speculation. In 2021 IEEE Symposium on Security and Privacy (SP), pages 1868–1883. IEEE, 2021.

[47] Charles Herder, Meng-Day Yu, Farinaz Koushanfar, and Srinivas Devadas. Physical unclonable functions and applications: A tutorial. Proceedings of the IEEE,

## 102(8):1126–1141, 2014.

[48] Jann Horn. speculative execution, variant 4: speculative store bypass. 2018.

[49] Intel. Intel analysis of speculative execution side channels. https://www.intel.com/ content/www/u s/e n/developer/articles/ technical/software-security-guidance/ technical-documentation/ analysis-speculative-execution-side-channels. html, 2018.

[50] Intel. Intel trust domain extension linux guest kernel security specification - virtio and shared memory. https://intel.github. i o/ccc-linux-guest-hardening-docs/ security-spec.html# virtio-and-shared-memory, 2024.

[51] Intel. Trust domain security guidance for developers. https://www.intel.com/ content/www/u s/e n/developer/articles/ technical/software-security-guidance/ best-practices/trusted-domain-security-guidance-for-developers. html, 2024. [52] Tobias Jauch, Alex Wezel, Mohammad R Fadiheh, Philipp Schmitz, Sayak Ray, Jason M Fung, Christopher W Fletcher, Dominik Stoffel, and Wolfgang Kunz. Secure-b y-construction design methodology for cpus: Implementing secure speculation on the rtl. In 2023 IEEE/ACM International Conference on Computer Aided Design (ICCAD), pages 1–9. IEEE, 2023.

[53] Ira Ray Jenkins, Prashant Anantharaman, Rebecca Shapiro, J Peter Brady, Sergey Bratus, and Sean W Smith. Ghostbusting: Mitigating spectre with intraprocess memory isolation. In Proceedings of the 7th Symposium on Hot Topics in the Science of Security, pages

## 1–11, 2020.

[54] Brian Johannesmeyer, Jakob Koschel, Kaveh Razavi, Herbert Bos, and Cristiano Giuffrida. Kasper: scanning for generalized transient execution gadgets in the linux kernel. In NDSS Symposium, volume 2022, 2022.

[55] David Kaplan. AMD x86 memory encryption technologies. In 25st USENIX Security Symposium (USENIX Security 16), Austin, TX, August 2016. USENIX Association.

[56] Khaled N Khasawneh, Esmaeil Mohammadian Koruyeh, Chengyu Song, Dmitry Evtyushkin, Dmitry Ponomarev, and Nael Abu-Ghazaleh. Safespec: Banishing the spectre of a meltdown with leakage-free speculation. In 2019 56th ACM/IEEE Design Automation Conference (DAC), pages 1–6. IEEE, 2019.

[57] Vladimir Kiriansky, Ilia Lebedev, Saman Amarasinghe, Srinivas Devadas, and Joel Emer. Dawg: A defense against cache timing attacks in speculative execution processors. In 2018 51st Annual IEEE/ACM International Symposium on Microarchitecture (MICRO), pages 974–987. IEEE, 2018.

[58] Ofek Kirzner and Adam Morrison. An analysis of speculative type confusion vulnerabilities in the wild. In

## 30th USENIX Security Symposium (USENIX Security

## 21), pages 2399–2416, 2021.

[59] Paul Kocher, Jann Horn, Anders Fogh, Daniel Genkin, Daniel Gruss, Werner Haas, Mike Hamburg, Moritz Lipp, Stefan Mangard, Thomas Prescher, et a l. Spectre attacks: Exploiting speculative execution. Communications of the ACM, 63(7):93–101, 2020.

[60] Esmaeil Mohammadian Koruyeh, Khaled N Khasawneh, Chengyu Song, and Nael B Abu-Ghazaleh. Spectre returns! speculation attacks using the return stack buffer. In WOOT@ USENIX Security Symposium, 2018.

16[61] kraiskil e t. a l. Onnx2c github repository. https:// github.com/kraiskil/onnx2c, 2022. Accessed on 09.30.2023.

[62] Ilia Lebedev, Kyle Hogan, and Srinivas Devadas. Secure boot and remote attestation in the sanctum processor. In 2018 IEEE 31st Computer Security Foundations Symposium (CSF), pages 46–60. IEEE, 2018.

[63] Ilia Lebedev, Kyle Hogan, Jules Drean, David Kohlbrenner, Dayeol Lee, Krste Asanovi´c, Dawn Song, and Srinivas Devadas. Sanctorum: A lightweight security monitor for secure enclaves. In 2019 Design, Automation & Test in Europe Conference & Exhibition (DATE), pages 1142–1147. IEEE, 2019.

[64] Dayeol Lee, Kevin Cheang, Alexander Thomas, Catherine Lu, Pranav Gaddamadugu, Anjo VahldiekOberwagner, Mona Vij, Dawn Song, Sanjit A Seshia, and Krste Asanovic. Cerberus: A formal approach to secure and efficient enclave memory sharing. In Proceedings of the 2022 ACM SIGSAC Conference on Computer and Communications Security, pages 1871–

## 1885, 2022.

[65] Dayeol Lee, David Kohlbrenner, Shweta Shinde, Krste Asanovi´c, and Dawn Song. Keystone: An open framework for architecting trusted execution environments. In Proceedings of the Fifteenth European Conference on Computer Systems, pages 1–16, 2020.

[66] Mingyu Li, Yubin Xia, and Haibo Chen. Confidential serverless made efficient with plug-i n enclaves. In 2021 ACM/IEEE 48th Annual International Symposium on Computer Architecture (ISCA), pages 306–318. IEEE, 2021.

[67] Peinan Li, Lutan Zhao, Rui Hou, Lixin Zhang, and Dan Meng. Conditional speculation: An effective approach to safeguard out-o f-order execution against spectre attacks. In 2019 IEEE international symposium on high performance computer architecture (HPCA), pages 264–276. IEEE, 2019.

[68] Xupeng Li, Xuheng Li, Christoffer Dall, Ronghui Gu, Jason Nieh, Yousuf Sait, and Gareth Stockwell. Design and verification of the arm confidential compute architecture. In 16th USENIX Symposium on Operating Systems Design and Implementation (OSDI 22), pages

## 465–484, 2022.

[69] Fangfei Liu, Yuval Yarom, Qian Ge, Gernot Heiser, and Ruby B Lee. Last-level cache side-channel attacks are practical. In 2015 IEEE symposium on security and privacy, pages 605–622. IEEE, 2015. [70] Kevin Loughlin, Ian Neal, Jiacheng Ma, Elisa Tsai, Ofir Weisse, Satish Narayanasamy, and Baris Kasikci. {DOLMA}: Securing speculation with the principle of transient {Non-Observability}. In 30th USENIX Security Symposium (USENIX Security 21), pages 1397–

## 1414, 2021.

[71] Giorgi Maisuradze and Christian Rossow. ret2spec: Speculative execution using return stack buffers. In Proceedings of the 2018 ACM SIGSAC Conference on Computer and Communications Security, pages 2109–

## 2122, 2018.

[72] Frank McKeen, Ilya Alexandrovich, Alex Berenzon, Carlos V Rozas, Hisham Shafi, Vedvyas Shanbhogue, and Uday R Savagaonkar. Innovative instructions and software model for isolated execution. HASP, 2013.

[73] micropython. The micropython project. https: //github.com/micropython/micropython, 2023. Accessed on 07.02.2023.

[74] Nicholas Mosier, Hanna Lachnitt, Hamed Nemati, and Caroline Trippel. Axiomatic hardware-software contracts for security. In Proceedings of the 49th Annual International Symposium on Computer Architecture, pages 72–86, 2022.

[75] Nicholas Mosier, Hamed Nemati, John C Mitchell, and Caroline Trippel. Serberus: Protecting cryptographic code from spectres at compile-time. In 2024 IEEE Symposium on Security and Privacy (SP), pages 4200–

## 4219. IEEE, 2024.

[76] moxie0. Technology preview: Private contact discovery for signal. https://signal.org/blog/ private-contact-discovery/, 2017. Accessed on 28.04.2023.

[77] Shravan Narayan, Craig Disselkoen, Daniel Moghimi, Sunjay Cauligi, Evan Johnson, Zhao Gang, Anjo Vahldiek-Oberwagner, Ravi Sahita, Hovav Shacham, Dean Tullsen, et a l. Swivel: Hardening {WebAssembly} against spectre. In 30th USENIX Security Symposium (USENIX Security 21), pages

## 1433–1450, 2021.

[78] Shravan Narayan, Tal Garfinkel, Mohammadkazem Taram, Joey Rudek, Daniel Moghimi, Evan Johnson, Chris Fallin, Anjo Vahldiek-Oberwagner, Michael LeMay, Ravi Sahita, et a l. Going beyond the limits of sfi: Flexible and secure hardware-assisted i n-process isolation with hfi. In Proceedings of the 28th ACM International Conference on Architectural Support for Programming Languages and Operating Systems, Volume 3, pages 266–281, 2023.

17[79] Oleksii Oleksenko, Christof Fetzer, Boris Köpf, and Mark Silberstein. Revizor: Testing black-box cpus against speculation contracts. In Proceedings of the

## 27th ACM International Conference on Architectural

Support for Programming Languages and Operating Systems, pages 226–239, 2022.

[80] Oleksii Oleksenko, Bohdan Trach, Mark Silberstein, and Christof Fetzer. {SpecFuzz}: Bringing spectretype vulnerabilities to the surface. In 29th USENIX Security Symposium (USENIX Security 20), pages 1481–

## 1498, 2020.

[81] Hamza Omar and Omer Khan. Ironhide: A secure multicore that efficiently mitigates microarchitecture state attacks for interactive applications. In IEEE International Symposium on High Performance Computer Architecture, HPCA 2020, San Diego, CA, USA, February 22-26, 2020, pages 111–122. IEEE, 2020.

[82] orlp. Ed25519 github repository. https://github. com/orlp/ed25519, 2017. Accessed on 07.02.2023.

[83] Andrew Pardoe. Spectre mitigations in msvc. https://devblogs.microsoft.com/cppblog/ spectre-mitigations-i n-msvc/, 2018.

[84] Joongun Park, Naegyeong Kang, Taehoon Kim, Youngjin Kwon, and Jaehyuk Huh. Nested enclave: Supporting fine-grained hierarchical isolation with sgx. In 2020 ACM/IEEE 47th annual international symposium on computer architecture (ISCA), pages 776–789. IEEE, 2020.

[85] Marco Patrignani and Marco Guarnieri. Exorcising spectres with secure compilers. In Proceedings of the 2021 ACM SIGSAC Conference on Computer and Communications Security, pages 445–461, 2021.

[86] Sandro Pinto and Nuno Santos. Demystifying arm trustzone: A comprehensive survey. ACM Computing Surveys (CSUR), 51(6):1–36, 2019.

[87] Shixiong Qi, Leslie Monis, Ziteng Zeng, Ian-chin Wang, and KK Ramakrishnan. Spright: Extracting the server from serverless computing! high-performance ebpf-based event-driven, shared-memory processing. In Proceedings of the ACM SIGCOMM 2022 Conference, pages 780–794, 2022.

[88] Zhenxiao Qi, Qian Feng, Yueqiang Cheng, Mengjia Yan, Peng Li, Heng Yin, and Tao Wei. Spectaint: Speculative taint analysis for discovering spectre gadgets. In NDSS, pages 1–14, 2021.

[89] Oscar Reparaz, Josep Balasch, and Ingrid Verbauwhede. Dude, is my code constant time? In Design, Automation & Test in Europe Conference & Exhibition (DATE), 2017, pages 1697–1702. IEEE, 2017. [90] Keegan Ryan. Hardware-backed heist: Extracting ecdsa keys from qualcomm’s trustzone. In Proceedings of the 2019 ACM SIGSAC Conference on Computer and Communications Security, pages 181–194, 2019.

[91] Andrea Sabbioni, Lorenzo Rosa, Armir Bujari, Luca Foschini, and Antonio Corradi. A shared memory approach for function chaining in serverless platforms. In 2021 IEEE Symposium on Computers and Communications (ISCC), pages 1–6. IEEE, 2021.

[92] Gururaj Saileshwar, Sanjay Kariyappa, and Moinuddin Qureshi. Bespoke cache enclaves: Fine-grained and scalable isolation from cache side-channels via flexible set-partitioning. In 2021 International Symposium on Secure and Private Execution Environment Design (SEED), pages 37–49. IEEE, 2021.

[93] Gururaj Saileshwar and Moinuddin K Qureshi. Cleanupspec: An" undo" approach to safe speculation. In Proceedings of the 52nd Annual IEEE/ACM International Symposium on Microarchitecture, pages 73–86, 2019.

[94] Christos Sakalis, Stefanos Kaxiras, Alberto Ros, Alexandra Jimborean, and Magnus Själander. Efficient invisible speculative execution through selective delay and value prediction. In Proceedings of the 46th International Symposium on Computer Architecture, pages 723–735, 2019.

[95] Michael Schwarz, Moritz Lipp, Claudio Alberto Canella, Robert Schilling, Florian Kargl, and Daniel Gruss. Context: A generic approach for mitigating spectre. In Network and Distributed System Security Symposium 2020, 2020.

[96] Michael Schwarz, Martin Schwarzl, Moritz Lipp, Jon Masters, and Daniel Gruss. Netspectre: Read arbitrary memory over network. In Computer Security– ESORICS 2019: 24th European Symposium on Research in Computer Security, Luxembourg, September

## 23–27, 2019, Proceedings, Part I 24, pages 279–299.

Springer, 2019.

[97] AMD SEV-SNP. Strengthening vm isolation with integrity protection and more. White Paper, January, 2020.

[98] Zhuojia Shen, Jie Zhou, Divya Ojha, and John Criswell. Restricting control flow during speculative execution. In Proceedings of the 2018 ACM SIGSAC Conference on Computer and Communications Security, pages

## 2297–2299, 2018.

[99] Stefan Steinegger, David Schrammel, Samuel Weiser, Pascal Nasahl, and Stefan Mangard. Servas! secure18enclaves via risc-v authenticryption shield. In Computer Security–ESORICS 2021: 26th European Symposium on Research in Computer Security, Darmstadt, Germany, October 4–8, 2021, Proceedings, Part II 26, pages 370–391. Springer, 2021.

[100] Daniel Townley, Kerem Arıkan, Yu David Liu, Dmitry Ponomarev, and O˘guz Ergin. Composable cachelets: Protecting enclaves from cache {Side-Channel} attacks. In 31st USENIX Security Symposium (USENIX Security 22), pages 2839–2856, 2022.

[101] Jo Van Bulck, Marina Minkin, Ofir Weisse, Daniel Genkin, Baris Kasikci, Frank Piessens, Mark Silberstein, Thomas F Wenisch, Yuval Yarom, and Raoul Strackx. Foreshadow: Extracting the keys to the intel {SGX} kingdom with transient out-o f-order execution. In 27th {USENIX} Security Symposium ({USENIX} Security 18), pages 991–1008, 2018.

[102] Jo Van Bulck, Daniel Moghimi, Michael Schwarz, Moritz Lippi, Marina Minkin, Daniel Genkin, Yuval Yarom, Berk Sunar, Daniel Gruss, and Frank Piessens. Lvi: Hijacking transient execution through microarchitectural load value injection. In 2020 IEEE Symposium on Security and Privacy (SP), pages 54–72. IEEE, 2020.

[103] Stephan van Schaik, Andrew Kwong, Daniel Genkin, and Yuval Yarom. Sgaxe: How sgx fails in practice, 2020.

[104] Thomas Van Strydonck, Job Noorman, Jennifer Jackson, Leonardo Alves Dias, Robin Vanderstraeten, David Oswald, Frank Piessens, and Dominique Devriese. Cheri-tree: Flexible enclaves on capability machines. In 2023 IEEE 8th European Symposium on Security and Privacy (EuroS&P), pages 1143–1159. IEEE, 2023.

[105] Marco Vassena, Craig Disselkoen, Klaus von Gleissenthall, Sunjay Cauligi, Rami Gökhan Kıcı, Ranjit Jhala, Dean Tullsen, and Deian Stefan. Automatically eliminating speculative leaks from cryptographic code with blade. Proceedings of the ACM on Programming Languages, 5(POPL):1–30, 2021.

[106] Guanhua Wang, Sudipta Chattopadhyay, Arnab Kumar Biswas, Tulika Mitra, and Abhik Roychoudhury. Kleespectre: Detecting information leakage through speculative cache attacks via symbolic execution. ACM Transactions on Software Engineering and Methodology (TOSEM), 29(3):1–31, 2020.

[107] Guanhua Wang, Sudipta Chattopadhyay, Ivan Gotovchits, Tulika Mitra, and Abhik Roychoudhury. oo7: Low-overhead defense against spectre attacks via program analysis. IEEE Transactions on Software Engineering, 47(11):2504–2519, 2019.

[108] Yao Wang, Andrew Ferraiuolo, and G Edward Suh. Timing channel protection for a shared memory controller. In 2014 IEEE 20th International Symposium on High Performance Computer Architecture (HPCA), pages 225–236. IEEE, 2014.

[109] Andrew Waterman, Yunsup Lee, Rimas Avizienis, David A Patterson, and Krste Asanovic. The risc-v instruction set manual volume 2: Privileged architecture version 1.7. Technical report, University of California at Berkeley Berkeley United States, 2015.

[110] Samuel Weiser, Mario Werner, Ferdinand Brasser, Maja Malenko, Stefan Mangard, and Ahmad-Reza Sadeghi. Timber-v: Tag-isolated memory bringing fine-grained enclaves to risc-v. In NDSS, 2019.

[111] Ofir Weisse, Ian Neal, Kevin Loughlin, Thomas F Wenisch, and Baris Kasikci. Nda: Preventing speculative execution attacks at their source. In Proceedings of the 52nd Annual IEEE/ACM International Symposium on Microarchitecture, pages 572–586, 2019.

[112] Ofir Weisse, Jo Van Bulck, Marina Minkin, Daniel Genkin, Baris Kasikci, Frank Piessens, Mark Silberstein, Raoul Strackx, Thomas F Wenisch, and Yuval Yarom. Foreshadow-n g: Breaking the virtual memory abstraction with transient out-o f-order execution. 2018.

[113] Zane Weissman, Thore Tiemann, Thomas Eisenbarth, and Berk Sunar. Microarchitectural security of aws firecracker vmm for serverless cloud platforms. arXiv preprint arXiv:2311.15999, 2023.

[114] Sander Wiebing, Alvise de Faveri Tron, Herbert Bos, and Cristiano Giuffrida. Inspectre gadget: Inspecting the residual attack surface of cross-privilege spectre v 2. In USENIX Security, 2024.

[115] Tianhong Xu, Aidong Adam Ding, and Yunsi Fei. Trustzonetunnel: A cross-world pattern history tablebased microarchitectural side-channel attack. In 2024 IEEE International Symposium on Hardware Oriented Security and Trust (HOST), pages 01–11. IEEE, 2024.

[116] Mengjia Yan, Jiho Choi, Dimitrios Skarlatos, Adam Morrison, Christopher Fletcher, and Josep Torrellas. Invisispec: Making speculative execution invisible in the cache hierarchy. In 2018 51st Annual IEEE/ACM International Symposium on Microarchitecture (MICRO), pages 428–441. IEEE, 2018.

19[117] Yuheng Yang, Thomas Bourgeat, Stella Lau, and Mengjia Yan. Pensieve: Microarchitectural modeling for security evaluation. In Proceedings of the 50th Annual International Symposium on Computer Architecture, pages 1–15, 2023.

[118] Jiyong Yu, Lucas Hsiung, Mohamad El Hajj, and Christopher W Fletcher. Data oblivious isa extensions for side channel-resistant and high performance computing. Cryptology ePrint Archive, 2018.

[119] Jiyong Yu, Namrata Mantri, Josep Torrellas, Adam Morrison, and Christopher W Fletcher. Speculative data-oblivious execution: Mobilizing safe prediction for safe and efficient speculative execution. In 2020 ACM/IEEE 47th Annual International Symposium on Computer Architecture (ISCA), pages 707–720. IEEE, 2020.

[120] Jiyong Yu, Mengjia Yan, Artem Khyzha, Adam Morrison, Josep Torrellas, and Christopher W Fletcher. Speculative taint tracking (stt) a comprehensive protection for speculatively accessed data. In Proceedings of the

## 52nd Annual IEEE/ACM International Symposium o n

Microarchitecture, pages 954–968, 2019.

[121] Sizhuo Zhang, Andrew Wright, Thomas Bourgeat, and Arvind. Composable building blocks to open up processor design. In Proceedings of the 51st Annual IEEE/ACM International Symposium on Microarchitecture, 2018. 20A Hardware Software ContractsWe succinctly repeat the definitions and framework for Guarnieri e t. a l.. Full details can be found in [46].

Hardware-Software Contracts Contracts define public or exposed states with respect to programs. For a given program p and an initial architectural state σ0, JpK(σ0) is the traces of architectural state when the program is run given the corresponding semantic. The traces of a contract JpK) capture which architectural state is public and at risk of being exposed by the software when run.

A.1 Hardware SemanticsThe adversary model is modeled as projections of parts of the microarchitectural state. Given a program p, and an architectural state σ, {|p|}(σ) denotes the trace of hardware observations produced in the run of the program on the given microarchitecture. The hardware semantic of a program pi s denoted as σ, {|p|}.

Definition 1 ({| · |} ⊢ J · K) A hardware semantics {| · |} satisfies a contract J·K i f, for all programs p and all initial architectural states σ, σ′, if JpK(σ) = JpK(σ′) then {|p|}(σ) = {|p|}(σ′).

A.2 Building Blocks for ContractsContracts for secure speculation are defined two fold. They are composed of a leakage model and an execution model. The leakage model describes what is observable by the attacker (e.g. execution trace and trace of memory accesses). The execution model, on the other hand, models the speculative behavior of the underlying semantic.

Existing Leakage Models Several leakage models have been defined and used in previous work. The constant-time model (c t for short) leaks the trace of the pc (i.e. the control flow) and the trace all memory accesses (but not their values). The architectural or sanboxing model (arch) extends the ct model to include the values of elements loaded from memory. arch effectively exposes the value of all registers during execution. The memory model (mem) only exposes the trace of memory accesses but not the control flow of the program and is sometimes used to model an attacker exploiting cache side-channels. The more states are exposed to an attacker by a leakage model, the stronger it is considered to be (i.e. challenging to defend by software-only measures). Hence arch being the strongest leakage model followed by ct and finally mem.

Existing Execution Models The weaker execution model is seq, which represents non-speculative, or sequential execution (one instruction at a time and i n-order). We also have the strongest execution model spec which models speculative execution with the following predictors: the pattern history table (PHT), the branch target buffer (BTB) and the return stack buffer (RSB).

A.3 SW side: Non-Interference PropertiesWork by Cauligi e t. a l. [24] defines direct and relative non-interference properties. We repeat these definitions here as a reminder.

Direct Non-Interference. Program p satisfies direct non interference with respect to a given contract J · K and policy π i f, for all pair of π-equivalent initial states σ and σ′, executing p with each initial trace produces the same trace. That i s, p ⊢ NI(π, J · K) is defined a s∀σ, σ ′ : σ ≃π σ′ ⇒ JpK(σ) = JpK(σ ′)We elide π for brevity and write p ⊢ NI(J · K).

Removing Security Policy π. In Cauligi e t. a l. [24]’s definitions of relative non-interference properties all contain a security policy π, which is used to qualify which part of the initial states σ and σ′ are public or private. This is redundant for the definition or relative non-interference as what is public is already defined by what is leaked in the first contract. As a result, we elide π for brevity.

Relative Non-Interference. Program p satisfies relative non interference from contract J · Kseq at o J · K β ai f: for all pair of initial state σ and σ′, if executing p under J · Kseq a produces equal traces, then executing p under J · Kβ a produces equal traces. That i s, p ⊢ NI(J · K seq a ⇒ J · K β a) is defined a s∀σ, σ ′ : J · Kseq a (σ) = J · K seq a (σ′)⇒ J · K β a(σ) = J · Kβ a(σ ′)B Burst Mode Security AnalysisGiven that {| · |}burst ⊢ J · Kstl shm. Given that our static program analysis tool sta returns true on a program pi fp ⊢ NI(J · Kseq shm ⇒ J · Kstl shm), and false otherwise. Let us prove {|p|}sta burst ⊢ (J · Kseq shm.

Let us take pa program, σ and σ′ some initial state so that (JpKseq shm(σ) = JpK seq shm(σ′)) We have two cases:

If sta( p) = true, p ⊢ NI(J · Kseq shm ⇒ J · Kstl shm) and {|p|}burst =21{|p|}sta burst s o:

(JpKseq shm(σ) = JpK seq shm(σ′))⇒(JpKstl shm(σ) = JpKstl shm(σ ′))⇒{|p|}burst (σ) = {|p|}burst (σ′)⇒{|p|} sta burst (σ) = {|p|} sta burst (σ′)If sta( p) = false, {|p|}sta burst = ∅ and:

{|p|} sta burst (σ) = {|p|} sta burst (σ′) is always true.

As a result, under our threat model, {|p|}sta burst ⊢ J · Kseq shm.

C Primer on Out-o f-Order ProcessorsThe out-o f-order design we consider is split between a frontend (responsible for speculatively fetching new instructions) and a back-end (responsible for executing out-o f-order those instructions, emitting the corresponding memory operations, and correcting wrong predictions to redirect the front-end). An overview of the Riscy-OOO pipeline is provided in Figure 10. The front-end is irrelevant to this paper. The backend starts when an instruction is enqueued both into the reorder buffer (see below) and the correct ALU/FPU/Memory execution pipeline, via each pipeline’s reservation station (see below). Morally, the reorder buffer tracks when an instruction is ready to commit, while the reservation stations track when an instruction is ready to execute. Together, the reorder buffer and the reservation stations ensure that instructions are executed when their operands become available, as long as it does not contradict the program order. They are also responsible for killing mispredicted instructions and committing right-path instructions.

Reorder Buffer Every cycle, the different execution pipelines notify the ROB when an instruction has finished executing, and the instructions’ statuses are updated in the ROB when done with execution. To guarantee correctness, the effect of an instruction is permanently committed only once it reaches the head of the ROB (guaranteeing that all previous instructions in the program have committed). When an instruction is required to execute non-speculatively, the scheduler waits until that instruction reaches the head of the ROB before notifying the reservation station (see below) that this instruction, which is now the oldest i n-flight instruction, is ready for execution.

Reservation Station There are multiple reservation stations for different kinds of instruction: ALU, FPU, and the memory instructions. At each cycle, the entries in the reservation stations are updated to reflect if their operands are ready (that Figure 10: Overview of the Riscy-OOO pipeline.

i s, if the dependent register values have been computed by previous instructions). Following this, the scheduler selects, for each reservation station, the oldest instruction that is ready to execute (has all of its required operands and is not), and issues it for execution to its corresponding execution pipeline. OverviewD Hardware Implementation DetailsD.1 Safe ModeIn the baseline out-o f-order processor we are hardening, memory instructions are decoded, renamed, and then simultaneously queued in the reorder buffer (ROB) and the memory reservation station (MemRS) (see Appendix C). When an instruction’s operands are ready, it is dispatched to the memory execution pipeline (MemExePipeline). Safe mode identifies instructions that access untrusted memory early in the MemExePipeline and delay the translation and processing of the memory accesses until the instruction is no longer speculative, i.e., when it reaches the head of the ROB. These changes require modification of MemRS and MemExePipeline.

Modifying the Memory Execution Pipeline Upon entry into MemExePipeline, checks are performed on memory instructions to decide if the memory operation is safe to translate and then issue or not. It is important to perform these checks very early as the next steps in the MemExePipeline touch shared microarchitecture (through address translation and cache hierarchy, for instance) potentially transmitting information to an attacker. A memory access is deemed safe if it accesses trusted memory OR if i ti s non-speculative. Because the enclave trusted memory range is defined in virtual memory, this check can be performed as soon as operands (i.e. virtual address) are available. If an instruction tries to access untrusted or shared memory, we check that it is non-speculative by conservatively checking if it has reached the head of the ROB. If the instruction is safe, it is dispatched22to the next stage of the MemExePipeline. If it is not safe, the instruction is squashed and a signal is sent to the MemRS indicating that it should r e-dispatch it once it reaches the head of the ROB.

Decorrelating Request Dispatching and Request Dequeuing Safe mode requires the MemRS to retain the accesses to shared memory in order to r e-dispatch them once they become non-speculative. The original design performs a MemRS data dispatch and dequeue simultaneously once the request enters the MemExePipeline. These two operations now need to occur at different stages in the pipeline: data is first dispatched from the MemRS and is dequeued in the translation execution stage if and only if the request is determined to be secure. We modify the interface between MemRS and MemExePipeline to provide the correct interfaces and logic. This includes augmenting the request data with the corresponding MemRS entry index.

Modifying the Memory Reservation Station Our mechanism requires MemRS being able to r e-dispatch some instructions once they become non-speculative: untrusted memory loads will indeed typically need to get dispatched twice. First, several new status bits are added for each MemRS entry, specifically to track if a) a given request is still to be dispatched for the first time, and b) if a given request needs to b er e-dispatched. The first bit (to_dispatch) is necessary since the entries can now still reside in the MemRS in the time between being dispatched and dequeued (o r signaled for redispatch) and should not be selected for dispatch again. The second bit (to_redispatch) is set by MemExePipeline when it squashes a speculative insecure request. We additionally add logic to compare each MemRS entry to the entry at the head of the ROB, and raise the entry’s dispatch_ready signal on a match. Finally, the dispatch logic is modified to use the new status bits. Rather than simply checking for the oldest valid entry whose arguments are ready, an additional condition is added to check if either to_dispatch is set for the entry or to_redispatch and redispatch_ready are set for the given entry.

Disabling the Mechanism for the OS Blocking speculation on memory access can have a significant performance impact. We want to make sure that the OS is still allowed to speculate on its own memory if it chooses not to use our trusted memory mechanism. As a result, we disable our mechanism when the enclave virtual address range is set to a specific empty range. Note that the OS could always be modified to take advantage of our trusted memory mechanism and protect itself from speculative side-channel attacks.

D.2 Reconfigurable LLC PartitioningStatic partitioning (a s proposed in MI6) is impractical as each of the 64 DRAM regions would be allocated a 16KB cache Figure 11: LLC set indexing scheme. The function takes an address as an input and output a set index in the LLC slice allocated to its memory region.

slice in our 1MB LLC. This is even smaller than the 64KB necessary for the inclusion of the cores’ private L1 caches (D1 and I1), which is dramatic for performance. Using way partitioning [57] is not possible as we need to instantiate 64 regions in the cache, but the LLC has only 16 ways, and Ironhide’s [81] strategy assumes limited reconfiguration.

Hardware-Software Co-Design The key is to rely on the (trusted) SM to do most of the heavy lifting in terms of bookkeeping and checking for correct configuration and security. At the hardware level, we can now design a new, simple, and practical reconfigurable LLC partitioning scheme that only requires minimal hardware changes.

Configuration Protocol We build a mechanism for the OS to reconfigure the LLC partitions to improve enclave and other program’s performance. This costly operation is only required when changing the LLC layout, which happens only before launching an application or an enclave with an important memory footprint. The OS requests a reconfiguration through an SM call while no enclaves are running. The SM will first check that the new partitioning is valid, doesn’t affect regions assigned to the SM. It then waits for other cores to flush their L1 caches and to enter a blocked state in the SM, making sure no requests will be sent to the modified regions during reconfiguration (which could put the cache in an incoherent state). The SM will then interact with the hardware to flush the LLC slices that are modified and set the LLC in its new configuration.

Microarchitectural Implementation The configuration for each LLC slice (base and bound of the set-index range) is stored in a big register (1216 bits) called the set-index range table. The SM can modify the entries of the set-index range table by sending MMIO requests to the cache, which is seen as a new device. When the LLC receives a request, it will compute the new set index for the corresponding address. We represent the transformation used in Figure 11. First, we extract a region ID from the address upper bits and obtain23the corresponding index range base and size by looking up the set-index range table 1 . We then extract the original set index of the address, located in the middle of the address, and tweak i t. We compute the original set-index value modulo the size of the index range 2 and add the base index 3 . This effectively restricts the new set index to the corresponding index range, partitioning the LLC 4 . Note that we must extend the length of the tags used by the LLC to include the entire original index in case an index range is of size 1 and all addresses from the same region map to the same set.

D.3 LLC fine-grain flushTo go hand-i n-hand with our reconfigurable LLC partitioning, we also want to be able to selectively flush parts of the LLC. We create a Zero Device in the upper physical address space. It is implemented as a simple piece of logic connected to the cache hierarchy at the same level as the DRAM, but that always sends back zeros. The trick is that the address space covered by the zero device has the same size as the DRAM and is located at addresses that will collide with DRAM addresses in the cache. Once the SM has placed the machine in a correct waiting state (where all the cores have flushed their L1 and are waiting in the SM), it only needs to access an eviction set in the zero-device address space to flush the cache slice. This means that flushing a small LLC slice is much faster than flushing a big one. We look at the performance of our flushing mechanism in the evaluation section (see 8.3).

D.4 Relaxed Flushing PoliciesThe enclave and some parts of the mini-SM do not have secrets to keep from each other. Specifically, the mini-SM never manipulates sensitive data. As a result, the mini-SM does not need to flush microarchitectural state when context switching to enclaves. This reduces the cost of mini-SM calls and opens the door to the use of frequent software or timer interrupts. To disable flushing selectively, we modify the hardware to deactivate systematic flushing and exposed the SM a register to trigger the flush. We write the SM to trigger the flushing mechanism on required context switches, but not on most traps and SM-calls from the enclave.

Evaluation To evaluate the performance of the relaxed flushing policy, we run Coremark while triggering periodic timer interrupts at different time intervals to model frequent traps. We do not perform any computation inside the trap handler and only measure the overhead due to context switching. The results are provided in Figure 12. By testing a range of interrupt periods, we confirm that flushing on each trap like in MI6 results in significant overheads. However, the cost is greatly reduced when using the relaxed flushing policy, with Figure 12: Normalized Execution Time for Coremark in the presence of periodic timer interrupts. MI6 flushed on every interrupt; Citadel does not.

a maximum of 7% overhead measured for interrupts every

## 0.4 m s.

D.5 MiscellaneousWe statically partition MSHRs between two cores and place a fair round-robin arbiter at the entry of the LLC. Because these two mechanisms only marginally affect the latency of the LLC for a 2-core design, we observe negligible (≈ 0.1%) performance impact. We also expose controls for speculation and predictors to the software through Control Status Registers (CSRs). Specifically, a program is able to deactivate speculation all together (every instruction waits to reach the head of the ROB), delay the issuing of shared memory accesses to the head of the ROB, deactivate the training of predictors (branch predictors and return address stack) and/o r their use (and then it falls back to the predictor pc + 4, or straightline speculation).

E Software InfrastructureE.1 Security MonitorThe SM does not allocate any resources, this task is left to the OS, but it will interpose between each security-sensitive operation (like a resource allocation) and check that the operating system performed the task without violating the high-level security policies (e.g., it is allocating a memory region to an existing enclave). Its API is called by the OS or an enclave to request ownership of new memory regions, create enclaves, or perform any other operations where it is needed. As a result, the SM is mostly responsible for bookkeeping operations, performing security checks, and setting up the hardware mechanisms to enforce isolation between the running security domains. It will not only systematically intervene on any security-sensitive operations, but will also play the role of a small kernel and build the bridge between the OS and the hardware on some non-security-sensitive operations like sending inter-process interrupts (IPI). The OS and the enclaves interact with the SM through ecalls. A more detailed description of the SM data structures and API, can be found in [63].

24E.2 Boot SequenceSecure Bootloader To boot an OS such as Linux on top of our SM, several steps are necessary. First, our Secure Bootloader will be in charge of the first booting stage. While other cores are waiting, core 0 will load, measure (hash) the SM binary, and use the SM measurement to generate the SM key pair. Once this is done, the Bootloader will use its private keys to sign the SM measurement and endorse the SM public key, creating the first certificate used for secure boot or remote attestation. Finally, it will copy the SM key pair to SM memory along with the endorsing certificate. For more details on secure boot, see [62]. It will then wake up the other cores using interprocess interrupts and have them all jump to the SM entry point.

SM Boot Now that the SM has been attested and is running, it can start initializing the hardware, set up the data structures required to later perform its duties, and set up the machine is in such a state so that Linux can properly boot in the next stage. The SM proceeds as follows: each core will clean up its register file and set up a stack. They will all initialize some of their special registers. In particular, they will immediately set up a trap handler to be able to catch exceptions and enable software interrupts. From there, all cores go to sleep except core 0. Core 0 will set up all private SM data structures that keep track of the ownership of resources. It will also walk the device tree and set up kernel-related mechanisms such as the clock and interprocess interrupts. The other cores will then be awakened. The SM will set up memory protection through the specific registers. In particular, some memory checks are performed during address translation. However, Linux uses physical addresses to boot. To solve this issue, the SM sets up an identity page table, so the virtual address space exposed to Linux is a direct mapping to the physical address space. Each OS memory access will then go through address translation and memory security checks. Finally, the SM will have all the cores jumping to the payload entry point at a similar time; in our case, the payload is the Linux image.

Linux Booting and SM Kernel Module We boot Linux using the Spinwait method [31]. Once Linux boots, an SM Kernel Module will be loaded. The SM kernel module is registered as a device in Linux that is accessible to applications through a pseudo-file /dev/security_monitor.

E.3 Running an EnclaveE.3.1 Key Software ElementsThe SM Kernel Module The main SM should not possibly be made unavailable to the OS by a user-level program. Furthermore, no resource should be allocated to a user-level program without the OS approval. As a result, to create an enclave or perform other operations, a user application needs to interact with the SM through the SM Kernel Module. Because the SM Kernel Module is part of the OS, it can then refuse requests if needed.

Mini-SM Because the SM is a shared resource, its might leak sensitive information. For instance, an enclave might call the SM at particular times and in a pattern that might leak sensitive information regarding the enclave’s secrets. As a result, each enclave uses its own private copy of the SM. This "mini-SM" is smaller than the one accessible to the OS and only contains the code corresponding to the subset of the SM API accessible by the enclave. It also uses its own private stack. This mini-SM is located in private enclave memory (not accessible nor visible by the OS) and protected using physical memory isolation (hence it is neither modifiable nor accessible by the enclave). The enclave interacts with its mini-SM through the ecall API. Note that some of these ecalls might touch on shared global SM state and locks. As a result, an enclave should be careful when interacting with the SM and be aware that it might still leak timing information to other programs. We emphasize that an enclave binary does not go through the SM Kernel Module and directly interacts with its mini-SM through ecalls.

User-Level Application The user-level application runs on top of the OS. It does not benefit from any integrity or privacy guarantees, unlike its enclave counterpart. On the other hand, it has access to a rich interface with the outside world (like the file system or the network) through all the usual OS services implemented through system calls. Even if not required for an enclave to work, this makes the user-level application a good ally for an enclave program. It can, for instance, fetch encrypted private data and forward it to the enclave or perform many other non-security-sensitive tasks.

E.3.2 Launching An EnclaveAllocating Memory The user-level application first loads the enclave binary from the file system to user memory. It will also ask the OS to map the virtual addresses used by the enclave for shared memory to physical memory. The application should also make sure not to allocate any shared objects within the enclave’s virtual memory range. The application then opens the kernel module device and sends a request through an iotcl system call to request the SM Kernel Module to launch the enclave binary.

Setting Up the Enclave Once called, the SM Kernel Module launches a series of ecalls to the SM to setup the enclave. First, it moves the enclave binary from user memory to kernel memory. It then allocates two physical memory regions and performs several SM calls so the SM can use one of the regions to store metadata and the second region can be given to the enclave. After the SM has set up the metadata25region, the enclave’s metadata can be created and populated. During the enclave setup process, the SM makes sure to add several arguments used to set up the enclave to the enclave’s measurement (see Section E.4 for more details). The kernel module then asks the SM to copy a version of the mini-SM in enclave memory, initializes the enclave’s page table, and loads the enclave’s binary while populating the enclave’s page table with entries. The kernel module asks the SM to create one or several threads and gives them to the enclave. The threads are set up to start executing at the right location and with the right stack pointer.

Timer Limit We also added a new value timer_limit to each thread. This value is used to avoid timing attacks on enclaves, especially ones exploiting malicious inputs to leak enclave secrets through the enclave completion time. timer_limit will represent the maximum amount of time the enclave’s thread is allowed to execute. During enclave launch, the hardware timers are set so the enclave will be exited after the corresponding amount of time has elapsed. This way, if an unrecoverable exception occurs, the enclave will not immediately exit, but will simply wait for its timer to expire. This prevents the enclave from leaking the timing at which exceptions occurred.

Sealing the Enclave The enclave can now be sealed, its measurement is finalized and used to generate a key pair. The SM commits to the enclave’s measurement and public key using its own signing key. The enclave is now ready and the module can send a final ecall to the SM to enter the enclave.

Enclave Execution The enclave now executes on its dedicated cores and can communicate with its parent-level userapplication using shared memory. When the enclave wants to exit, it does so by sending a ecall directly to the mini-SM. Upon return, the kernel module asks the SM to delete the threads and the enclave’s metadata; it then reclaims the memory regions and gives them back to the OS. Finally, the kernel module returns and forwards the enclave’s return value to the user-level application.

E.4 Enclave’s Attestation MechanismRemote attestation makes it possible for a remote user to receive and check a proof that convinces them of the integrity of an enclave’s initial state, given trust in the Secure Bootloader and the SM’s code. Our remote attestation protocol is based on [62]. The attestation proof is composed of two certificates, one ensuring the integrity of the SM and one ensuring the integrity of the secure enclave.

SM Attestation First, during secure boot, our (trusted) Secure Bootloader will measure the SM binary using a cryptographic hash function (SHA3) along with the device’s secret, to derive the SM signing keys. It will then generate a certificate using a public-key signature algorithm (Ed25519) with a key pair generated from a root device secret (generated o n-chip, for example, using a PUF [47]) by signing the SM’s measurement and its public key. The SM certificate, the SM keys and the Bootloader public key are copied to SM memory by the Bootloader. The SM certificate and the Bootloader public key are made available to the OS and to enclaves through the SM API. The bootloader is then responsible for setting up the SM stack correctly and entering the SM at the right address.

Enclave Attestation During the enclave’s setup, the SM will create the enclave’s unique measurement by hashing (with SHA3) several arguments used to set up the enclave initial state. In particular, it will include the enclave’s trusted virtual address range, the enclave’s binary along with its virtual memory mapping, the mini-SM binary and for each thread, the entry PC and SP, the value of timer_limit, and a representation of which exceptions and interrupts are enabled and which ones are directly delegated to the enclave. Because our SM is trusted, and the Ed25519 algorithms are implemented in constant time and protected against speculative and nonspeculative side-channel attacks (speculation is disabled inside of our SM), we modify the original Sanctum scheme [30] and do not rely on an attestation enclave to sign the enclave’s measurement and generate the enclave’s certificate. Instead, after the enclave’s measurement has been completed, the SM will use i t, along with a hash of its secret key, to derive a Ed25519 key pair for the enclave following a similar process to the Bootloader (see Figure

## 13). It will then generate an attestation certificate by signing

the enclave’s measurement and the enclave public key. The enclave measurement, certificate and keys are copied to the enclave’s metadata region, which is private to the SM.

Extending the SM Attestation API We introduce two new SM API calls. One so an enclave can retrieve its own keys and attestation certificate (n o one else can retrieve its private key). And a second so anyone can retrieve any enclave attestation certificate (which contains its public key). The enclave key pair can then be used to sign messages or to perform key exchanges and create secure communication channels [17]. This solution has several advantages compared to the Sanctum attestation enclave scheme. The enclave does not need to rely on another enclave to perform its attestation. This avoids several communication, concurrency and availability issues, for instance, how an enclave finds or wakes up the attestation enclave. This also means we don’t need to share the attestation enclave with other potentially untrusted enclaves. Additionally, the key-derivation scheme is now deterministic. This means that the same enclave on the same machine will be endorsed with the same keys given an identical SM and a fixed device secret. This makes it possible

Figure 13: Key Derivation and Endorsementfor a remote user to process shared secrets with the enclave and prepare and encrypt data for the enclave without the enclave actively running. This also makes it possible for an enclave to derive deterministic keys for long-term secure data storage that can be recovered even after being offline.

Position-Independent Enclave Measurement For our attestation mechanism to be practical and our enclave’s key derivation to be deterministic, it is important for an enclave’s measurement to be independent of the enclave’s location in physical memory. It would be impractical for a remote verifier to keep a copy of a hash for each possible enclave’s placement in physical memory (given that an enclave could own any subset of the 64 physical memory regions, which would be at worst 264 elements). We need to tweak Sanctum’s mechanism to properly enforce that property. This property is enforced two ways. Position-Independent Mini-SM First, for the mini-SM, its code must be completely position-independent. This is achieved at compilation time by using specific flags. Additionally, the mini-SM is only accessed through traps. The entry into the trap handler and the mini-SM stack must be fixed relative to the mini-SM binary. Because these values are physical addresses and cannot be added to the enclave’s measurement, the SM is trusted to set up the trap handler and the stack correctly.

Mapping Virtual Addresses to Bytes Second, for the enclave’s binary, we can rely on virtual memory to enforce that the enclave’s code will always use the same addresses independently of its position in physical memory. The only challenge left is how to provide a measurement that reflects the virtual address mapping without including any physical addresses. Instead of measuring the two mappings virtual-address-t o-physical-address and physical-address-tobyte-content (for instance, by measuring the page table and measuring the physical memory content and its addresses), we will directly enforce and measure the mapping from virtual-addresses-t o-byte-content. When loading a page from the enclave’s binary, the SM will be given, by the OS, the physical address at which the enclave page should be copied, the virtual address at which the page should be mapped and a pointer to the enclave’s binary page in OS memory. It will then 1) copy the page to the destination physical address, 2) set up the enclave’s page table to enforce the right mapping, and 3) only add to the enclave’s measurement the hash of the page content, the hash of the virtual address it was mapped t o, and the hash of the page table entry flags used. As a result, it is enough for a remote verifier that trusts the SM to 1) check the SM certificate and 2) check the enclave’s measurement to correctly identify the enclave.

Extension to Trusted VMs Note that for an enclave that manages its own virtual memory, we would need to play other tricks to make its measurement position independent. Indeed, the enclave would have somehow to learn about its position in physical memory, by hardcoding it (and hence fixing i t) it o rb y reverse-engineering the page table provided by the SM. Hence, porting a complete operating system inside an enclave would require modifications to achieve a realistic end-t o-end attestation solution.

E.5 Building an Enclave ApplicationEnclave Runtime The enclave binary or enclave application is the code that will run inside the enclave. In should really be seen as a binary a s, at first, the execution environment made available to the enclave is close to bare metal. Indeed, to enforce the integrity and privacy of the enclave, its private memory and its execution cores are architecturally and microarchitecturally isolated from the OS. This means, for instance, that the enclave cannot directly interact with the OS through the usual syscalls. As a result, an enclave binary needs to include its own libraries. Recall also that the OS does not have access to the enclave’s private memory. That means the enclave doesn’t have access to the OS resource management and needs to manage resources (e.g., memory, threads, etc.) on its own. However, the enclave has access to its mini-SM through the ecall interface and can perform operations such as freeing a memory region, setting up timer interrupts, or exiting. The enclave also has access to shared memory: it can read and write the data that is made available to i tb y the OS. In our implementation, the enclave can access the address space of the user-level application that launched i t. This makes our enclaves expressive and allows them to run rich applications such as cryptographic libraries, language run-times, or ML inference. Inputs can be shipped directly with the enclave binary or communicated to the enclave using shared memory. To protect the integrity and privacy of the input data sent to an enclave, a remote user can establish a shared secret with the enclave using the enclave’s public key and encrypt the data before sending them to the enclave (see Section E.4).

E.6 Debugging InfrastructureDebugging an Application For early software development and debugging, we developed a QEMU target that matches27our processor. A programmer can easily run their applications on several cores on top of QEMU without requiring to run the enclave from within Linux. From there, the application can be easily debugged using GDB. We also make it possible to compile the mini-SM with specific debugging flags to allow an enclave to (insecurely) access the console and to have the SM printing extra debugging messages, such as information regarding enclave exceptions. Once Linux has been booted, applications can be debugged on FPGA using standard Linux debugging tools.

Debugging the Enclave Platform Our QEMU simulator can also be used to debug other elements of the software stack including the Secure Bootloader, the Security Monitor, Linux itself, but also the SM Kernel Module, enclave binaries, and user-level applications. In addition, the hardware can be compiled to run in Verilator, a cycle-accurate simulator. This can be especially handy for debugging new hardware features or bugs that arise only on the FPGA. We also developed a series of low-level hardware tests to check the memory protection primitives such as the dual-page-table mechanism. To conclude, the debugging infrastructure makes it possible to efficiently implement new mechanisms whether they are implemented in hardware, software or a combination of both. 28