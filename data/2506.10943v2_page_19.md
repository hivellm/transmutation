You are conguring a model training pipeline by selecting from predened tools. You must make two decisions: 1.


## Data Generation Tools

� For each of the following, choose true or false: - use_basic_augmentations - use_size_augmentations - use_chain_augmentations - use_repeat_augmentations 2. Training Conguration � Choose one o f: "train_using_all_tokens" "train_using_output_tokens" Also specify: - learning_rate (oat) - num_train_epochs (integer) Output Format Respond with a valid JSON object. Do not include any explanation, markdown, or extra text. Use lowercase true / false for booleans and ensure correct JSON syntax. Example output: { "data_generation": { "use_basic_augmentations": ..., "use_size_augmentations": ..., "use_chain_augmentations": ..., "use_repeat_augmentations": ... }, "training": { "strategy": ..., "learning_rate": ..., "num_train_epochs": ... } } A.3 Evaluation Details For each of the 8 held-out evaluation tasks, the model generated 5 self-edit congurations, yielding a total of 40 congurations. Success was measured as the percentage of congurations that led to correct outputs after adaptation. We followed the evaluation protocol from Aky�rek et a l. [36]. For the Oracle TTT we used the following cong s: Parameter Value lora_rank 128 lora_alpha 16 num_train_epochs 2 batch_size 2 learning_rate 1e-4 A.4 Compute Resources We performed all training runs on a single A100, H100, or H200. Each TTT per problem requires between half a minute to a few minutes, which is also why we limited the number of samples for ReST EM and additionally limited the number of gradient steps allowed per self-edit TTT. Overall ReST EM took around 2-3 hours. 19